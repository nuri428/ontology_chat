"""
ìƒìš© ì„œë¹„ìŠ¤ ì¤€ë¹„ë„ í‰ê°€
ì• ë“œì„¼ìŠ¤ ì•± ë˜ëŠ” ìœ ë£Œ ì„œë¹„ìŠ¤ë¡œ ì œê³µ ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
"""

import asyncio
import time
from dataclasses import dataclass
from typing import List, Dict, Any
from api.services.chat_service import ChatService
from api.services.langgraph_report_service import LangGraphReportEngine
from api.services.query_router import QueryRouter
from api.services.response_formatter import ResponseFormatter


@dataclass
class CommercialCriteria:
    """ìƒìš© ì„œë¹„ìŠ¤ í‰ê°€ ê¸°ì¤€"""
    name: str
    weight: float  # ê°€ì¤‘ì¹˜ (0.0-1.0)
    min_score: float  # ìµœì†Œ í•©ê²© ì ìˆ˜
    description: str


# ìƒìš© ì„œë¹„ìŠ¤ í‰ê°€ ê¸°ì¤€
COMMERCIAL_CRITERIA = [
    CommercialCriteria("ì‘ë‹µ ì†ë„", 0.25, 0.7, "ë‹¨ìˆœ ì§ˆë¬¸ 2ì´ˆ ì´ë‚´, ë³µì¡í•œ ì§ˆë¬¸ 10ì´ˆ ì´ë‚´"),
    CommercialCriteria("ë‹µë³€ í’ˆì§ˆ", 0.30, 0.8, "ì •í™•ì„±, ê´€ë ¨ì„±, ì™„ì„±ë„"),
    CommercialCriteria("ì‚¬ìš©ì ê²½í—˜", 0.20, 0.7, "ì§ê´€ì„±, ì¼ê´€ì„±, ì˜¤ë¥˜ ì²˜ë¦¬"),
    CommercialCriteria("ì•ˆì •ì„±", 0.15, 0.9, "ì˜¤ë¥˜ìœ¨ 5% ì´í•˜"),
    CommercialCriteria("í™•ì¥ì„±", 0.10, 0.6, "ë™ì‹œ ì‚¬ìš©ì ì²˜ë¦¬ ëŠ¥ë ¥"),
]


# ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
REAL_WORLD_SCENARIOS = [
    {
        "scenario": "ì§ì¥ì¸ ì ì‹¬ì‹œê°„ ë¹ ë¥¸ ì¡°íšŒ",
        "queries": [
            "ì‚¼ì„±ì „ì ì˜¤ëŠ˜ ë‰´ìŠ¤",
            "ë°©ì‚°ì£¼ ì¶”ì²œ",
            "2ì°¨ì „ì§€ ê´€ë ¨ ì¢…ëª©",
        ],
        "max_time": 2.0,  # 2ì´ˆ ì´ë‚´
        "expected_quality": 0.8,
    },
    {
        "scenario": "íˆ¬ìì ì¢…ëª© ë¶„ì„",
        "queries": [
            "SKí•˜ì´ë‹‰ìŠ¤ ìµœê·¼ ì‹¤ì ì€?",
            "í˜„ëŒ€ì°¨ ì „ê¸°ì°¨ ì‚¬ì—… ì „ë§",
            "ì—ì½”í”„ë¡œ íˆ¬ì ì˜ê²¬",
        ],
        "max_time": 3.0,
        "expected_quality": 0.85,
    },
    {
        "scenario": "ì „ë¬¸ê°€ ì‹¬ì¸µ ë¶„ì„",
        "queries": [
            "ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ HBM ì‹œì¥ ë¹„êµ",
            "2ì°¨ì „ì§€ ì‚°ì—… íˆ¬ì ë³´ê³ ì„œ",
            "AI ë°˜ë„ì²´ ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„",
        ],
        "max_time": 15.0,
        "expected_quality": 0.9,
    },
    {
        "scenario": "ì´ˆë³´ íˆ¬ìì í•™ìŠµ",
        "queries": [
            "PERì´ ë­ì•¼?",
            "ë°°ë‹¹ìˆ˜ìµë¥  ê³„ì‚°ë²•",
            "ROEê°€ ë†’ìœ¼ë©´ ì¢‹ì€ê±°ì•¼?",
        ],
        "max_time": 2.0,
        "expected_quality": 0.85,
    },
]


class CommercialReadinessEvaluator:
    """ìƒìš© ì„œë¹„ìŠ¤ ì¤€ë¹„ë„ í‰ê°€ê¸°"""

    def __init__(self):
        self.chat_service = None
        self.router = None
        self.results = []

    async def initialize(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        print("ğŸ”§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        self.chat_service = ChatService()
        langgraph_engine = LangGraphReportEngine()
        self.router = QueryRouter(self.chat_service, ResponseFormatter(), langgraph_engine)
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ\n")

    async def evaluate_response_speed(self) -> Dict[str, Any]:
        """1. ì‘ë‹µ ì†ë„ í‰ê°€"""
        print("\n" + "=" * 80)
        print("âš¡ 1. ì‘ë‹µ ì†ë„ í‰ê°€")
        print("=" * 80)

        test_cases = [
            ("ì‚¼ì„±ì „ì ë‰´ìŠ¤", "fast", 2.0),
            ("2ì°¨ì „ì§€", "fast", 2.0),
            ("ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ ë¹„êµ", "langgraph", 15.0),
        ]

        results = []
        for query, expected_type, max_time in test_cases:
            start = time.time()
            try:
                result = await self.router.process_query(query)
                elapsed = time.time() - start

                processing_method = result.get("meta", {}).get("processing_method", "legacy")
                is_fast = elapsed <= max_time

                status = "âœ…" if is_fast else "âŒ"
                print(f"{status} '{query[:30]}...' - {elapsed:.1f}ì´ˆ (ìµœëŒ€: {max_time}ì´ˆ)")

                results.append({
                    "query": query,
                    "time": elapsed,
                    "max_time": max_time,
                    "passed": is_fast,
                })
            except Exception as e:
                print(f"âŒ '{query}' - ì˜¤ë¥˜: {e}")
                results.append({"query": query, "passed": False, "error": str(e)})

        passed = sum(1 for r in results if r.get("passed", False))
        total = len(results)
        score = passed / total if total > 0 else 0

        print(f"\nğŸ“Š ì‘ë‹µ ì†ë„ ì ìˆ˜: {score:.1%} ({passed}/{total})")

        return {
            "criterion": "ì‘ë‹µ ì†ë„",
            "score": score,
            "passed": passed,
            "total": total,
            "details": results,
        }

    async def evaluate_answer_quality(self) -> Dict[str, Any]:
        """2. ë‹µë³€ í’ˆì§ˆ í‰ê°€"""
        print("\n" + "=" * 80)
        print("ğŸ“ 2. ë‹µë³€ í’ˆì§ˆ í‰ê°€")
        print("=" * 80)

        quality_checks = [
            ("ì‚¼ì„±ì „ì ë‰´ìŠ¤", ["ì‚¼ì„±ì „ì", "ë‰´ìŠ¤"], 50),  # ìµœì†Œ 50ì
            ("SKí•˜ì´ë‹‰ìŠ¤ ì‹¤ì ", ["SKí•˜ì´ë‹‰ìŠ¤", "ì‹¤ì "], 50),
            ("2ì°¨ì „ì§€ ê´€ë ¨ ì¢…ëª©", ["2ì°¨ì „ì§€", "ì¢…ëª©"], 50),
        ]

        results = []
        for query, must_contain, min_length in quality_checks:
            try:
                result = await self.router.process_query(query)
                answer = result.get("markdown", "")

                # í’ˆì§ˆ ì²´í¬
                has_keywords = all(kw in answer for kw in must_contain)
                has_length = len(answer) >= min_length
                is_quality = has_keywords and has_length

                status = "âœ…" if is_quality else "âŒ"
                print(f"{status} '{query}' - ê¸¸ì´: {len(answer)}ì, í‚¤ì›Œë“œ: {has_keywords}")

                results.append({
                    "query": query,
                    "length": len(answer),
                    "has_keywords": has_keywords,
                    "passed": is_quality,
                })
            except Exception as e:
                print(f"âŒ '{query}' - ì˜¤ë¥˜: {e}")
                results.append({"query": query, "passed": False})

        passed = sum(1 for r in results if r.get("passed", False))
        total = len(results)
        score = passed / total if total > 0 else 0

        print(f"\nğŸ“Š ë‹µë³€ í’ˆì§ˆ ì ìˆ˜: {score:.1%} ({passed}/{total})")

        return {
            "criterion": "ë‹µë³€ í’ˆì§ˆ",
            "score": score,
            "passed": passed,
            "total": total,
            "details": results,
        }

    async def evaluate_user_experience(self) -> Dict[str, Any]:
        """3. ì‚¬ìš©ì ê²½í—˜ í‰ê°€"""
        print("\n" + "=" * 80)
        print("ğŸ‘¤ 3. ì‚¬ìš©ì ê²½í—˜ í‰ê°€")
        print("=" * 80)

        ux_checks = []

        # 1) ì˜¤íƒ€ ì²˜ë¦¬
        print("\n[ì˜¤íƒ€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸]")
        typo_queries = [
            ("ì‚¼ì„±ì „ì ë‰´ìŠ¤", True),  # ì •ìƒ
            ("PERì´ ë­ì•¼?", True),  # ì •ìƒ
        ]

        for query, should_work in typo_queries:
            try:
                result = await self.router.process_query(query)
                has_answer = len(result.get("markdown", "")) > 20
                status = "âœ…" if has_answer == should_work else "âŒ"
                print(f"{status} '{query}' - ì‘ë‹µ: {has_answer}")
                ux_checks.append(has_answer == should_work)
            except:
                ux_checks.append(False)

        # 2) ì¼ê´€ì„± (ê°™ì€ ì§ˆë¬¸ 2ë²ˆ)
        print("\n[ì¼ê´€ì„± í…ŒìŠ¤íŠ¸]")
        query = "ì‚¼ì„±ì „ì ë‰´ìŠ¤"
        try:
            result1 = await self.router.process_query(query)
            result2 = await self.router.process_query(query)

            type1 = result1.get("type")
            type2 = result2.get("type")
            is_consistent = type1 == type2

            status = "âœ…" if is_consistent else "âŒ"
            print(f"{status} ì¼ê´€ì„±: {type1} == {type2}")
            ux_checks.append(is_consistent)
        except:
            ux_checks.append(False)

        # 3) ì˜¤ë¥˜ ë©”ì‹œì§€ (ë¹ˆ ì§ˆë¬¸)
        print("\n[ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸]")
        try:
            result = await self.router.process_query("")
            has_error_msg = "markdown" in result or "error" in str(result).lower()
            status = "âœ…" if has_error_msg else "âŒ"
            print(f"{status} ë¹ˆ ì§ˆë¬¸ ì²˜ë¦¬: {has_error_msg}")
            ux_checks.append(has_error_msg)
        except:
            print("âœ… ë¹ˆ ì§ˆë¬¸ ì˜ˆì™¸ ì²˜ë¦¬ë¨")
            ux_checks.append(True)

        passed = sum(ux_checks)
        total = len(ux_checks)
        score = passed / total if total > 0 else 0

        print(f"\nğŸ“Š ì‚¬ìš©ì ê²½í—˜ ì ìˆ˜: {score:.1%} ({passed}/{total})")

        return {
            "criterion": "ì‚¬ìš©ì ê²½í—˜",
            "score": score,
            "passed": passed,
            "total": total,
        }

    async def evaluate_stability(self) -> Dict[str, Any]:
        """4. ì•ˆì •ì„± í‰ê°€"""
        print("\n" + "=" * 80)
        print("ğŸ›¡ï¸ 4. ì•ˆì •ì„± í‰ê°€")
        print("=" * 80)

        test_queries = [
            "ì‚¼ì„±ì „ì ë‰´ìŠ¤",
            "2ì°¨ì „ì§€",
            "ë°©ì‚°ì£¼",
            "SKí•˜ì´ë‹‰ìŠ¤",
            "PERì´ ë­ì•¼?",
            "ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ ë¹„êµ",
            "í˜„ëŒ€ì°¨ ì „ë§",
            "ì—ì½”í”„ë¡œ",
            "ë°°ë‹¹ìˆ˜ìµë¥ ",
            "AI ë°˜ë„ì²´",
        ]

        errors = 0
        for query in test_queries:
            try:
                result = await self.router.process_query(query)
                print(f"âœ… '{query}'")
            except Exception as e:
                print(f"âŒ '{query}' - ì˜¤ë¥˜: {e}")
                errors += 1

        total = len(test_queries)
        success = total - errors
        error_rate = errors / total if total > 0 else 0
        score = 1.0 - error_rate

        print(f"\nğŸ“Š ì•ˆì •ì„± ì ìˆ˜: {score:.1%} (ì˜¤ë¥˜ìœ¨: {error_rate:.1%})")

        return {
            "criterion": "ì•ˆì •ì„±",
            "score": score,
            "success": success,
            "total": total,
            "error_rate": error_rate,
        }

    async def evaluate_scalability(self) -> Dict[str, Any]:
        """5. í™•ì¥ì„± í‰ê°€ (ê°„ë‹¨í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸)"""
        print("\n" + "=" * 80)
        print("ğŸ“ˆ 5. í™•ì¥ì„± í‰ê°€")
        print("=" * 80)

        # ë™ì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜ (3ê°œ)
        queries = ["ì‚¼ì„±ì „ì ë‰´ìŠ¤", "2ì°¨ì „ì§€", "ë°©ì‚°ì£¼"]

        start = time.time()
        try:
            tasks = [self.router.process_query(q) for q in queries]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            elapsed = time.time() - start
            success = sum(1 for r in results if not isinstance(r, Exception))
            total = len(queries)

            # ë™ì‹œ ìš”ì²­ì´ ìˆœì°¨ ìš”ì²­ì˜ 1.5ë°° ì´ë‚´ë©´ í•©ê²©
            max_expected_time = 2.0 * 1.5  # 2ì´ˆ * 1.5ë°°
            is_fast = elapsed <= max_expected_time

            status = "âœ…" if is_fast and success == total else "âŒ"
            print(f"{status} ë™ì‹œ 3ê°œ ìš”ì²­: {elapsed:.1f}ì´ˆ (ìµœëŒ€: {max_expected_time:.1f}ì´ˆ)")
            print(f"   ì„±ê³µ: {success}/{total}")

            score = 1.0 if is_fast and success == total else 0.5

        except Exception as e:
            print(f"âŒ ë™ì‹œ ìš”ì²­ ì‹¤íŒ¨: {e}")
            score = 0.0

        print(f"\nğŸ“Š í™•ì¥ì„± ì ìˆ˜: {score:.1%}")

        return {
            "criterion": "í™•ì¥ì„±",
            "score": score,
        }

    async def run_real_world_scenarios(self) -> Dict[str, Any]:
        """ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n" + "=" * 80)
        print("ğŸ­ ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
        print("=" * 80)

        scenario_results = []

        for scenario_data in REAL_WORLD_SCENARIOS:
            print(f"\nğŸ“Œ ì‹œë‚˜ë¦¬ì˜¤: {scenario_data['scenario']}")
            print("-" * 80)

            passed_queries = 0
            total_time = 0

            for query in scenario_data["queries"]:
                start = time.time()
                try:
                    result = await self.router.process_query(query)
                    elapsed = time.time() - start
                    total_time += elapsed

                    is_fast = elapsed <= scenario_data["max_time"]
                    has_content = len(result.get("markdown", "")) > 30

                    status = "âœ…" if is_fast and has_content else "âŒ"
                    print(f"  {status} {query[:40]:<40} - {elapsed:.1f}ì´ˆ")

                    if is_fast and has_content:
                        passed_queries += 1

                except Exception as e:
                    print(f"  âŒ {query[:40]:<40} - ì˜¤ë¥˜: {e}")

            total_queries = len(scenario_data["queries"])
            avg_time = total_time / total_queries if total_queries > 0 else 0
            pass_rate = passed_queries / total_queries if total_queries > 0 else 0

            print(f"\n  ê²°ê³¼: {passed_queries}/{total_queries} ì„±ê³µ ({pass_rate:.1%})")
            print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.1f}ì´ˆ")

            scenario_results.append({
                "scenario": scenario_data["scenario"],
                "pass_rate": pass_rate,
                "avg_time": avg_time,
            })

        overall_pass_rate = sum(r["pass_rate"] for r in scenario_results) / len(scenario_results)

        return {
            "overall_pass_rate": overall_pass_rate,
            "scenarios": scenario_results,
        }

    async def evaluate_all(self) -> Dict[str, Any]:
        """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
        print("\n" + "=" * 100)
        print("ğŸ’° ìƒìš© ì„œë¹„ìŠ¤ ì¤€ë¹„ë„ ì¢…í•© í‰ê°€")
        print("=" * 100)

        await self.initialize()

        # ê° ê¸°ì¤€ë³„ í‰ê°€
        results = []
        results.append(await self.evaluate_response_speed())
        results.append(await self.evaluate_answer_quality())
        results.append(await self.evaluate_user_experience())
        results.append(await self.evaluate_stability())
        results.append(await self.evaluate_scalability())

        # ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
        scenario_result = await self.run_real_world_scenarios()

        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        print("\n\n" + "=" * 100)
        print("ğŸ“Š ì¢…í•© í‰ê°€ ê²°ê³¼")
        print("=" * 100)

        total_score = 0
        total_weight = 0

        print(f"\n{'ê¸°ì¤€':<20} {'ê°€ì¤‘ì¹˜':<10} {'ì ìˆ˜':<10} {'í•©ê²©ì„ ':<10} {'ê²°ê³¼':<10}")
        print("-" * 80)

        for criterion, result in zip(COMMERCIAL_CRITERIA, results):
            score = result["score"]
            weighted_score = score * criterion.weight
            total_score += weighted_score
            total_weight += criterion.weight

            passed = "âœ… í•©ê²©" if score >= criterion.min_score else "âŒ ë¶ˆí•©ê²©"
            print(f"{criterion.name:<20} {criterion.weight:<10.1%} {score:<10.1%} {criterion.min_score:<10.1%} {passed}")

        final_score = total_score / total_weight if total_weight > 0 else 0

        print("-" * 80)
        print(f"{'ì¢…í•© ì ìˆ˜':<20} {'':<10} {final_score:<10.1%}")

        # ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼
        print(f"\nì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼ìœ¨: {scenario_result['overall_pass_rate']:.1%}")

        # ìµœì¢… íŒì •
        print("\n" + "=" * 100)
        print("ğŸ¯ ìµœì¢… íŒì •")
        print("=" * 100)

        min_criteria_passed = all(
            results[i]["score"] >= COMMERCIAL_CRITERIA[i].min_score
            for i in range(len(results))
        )

        commercial_ready = (
            final_score >= 0.75 and
            min_criteria_passed and
            scenario_result['overall_pass_rate'] >= 0.8
        )

        if commercial_ready:
            if final_score >= 0.9:
                grade = "Aê¸‰ (í”„ë¦¬ë¯¸ì—„ ìœ ë£Œ ì„œë¹„ìŠ¤)"
                recommendation = "âœ… ì›” 9,900ì› ~ 19,900ì› ìˆ˜ì¤€ ìœ ë£Œ êµ¬ë… ê°€ëŠ¥"
            elif final_score >= 0.8:
                grade = "Bê¸‰ (í‘œì¤€ ìœ ë£Œ ì„œë¹„ìŠ¤)"
                recommendation = "âœ… ì›” 4,900ì› ~ 9,900ì› ë˜ëŠ” ì• ë“œì„¼ìŠ¤ ë¬´ë£Œ"
            else:
                grade = "Cê¸‰ (ê¸°ë³¸ ìœ ë£Œ ì„œë¹„ìŠ¤)"
                recommendation = "âœ… ì• ë“œì„¼ìŠ¤ ë¬´ë£Œ ì„œë¹„ìŠ¤ ê¶Œì¥"
        else:
            grade = "Dê¸‰ (ë² íƒ€/ë¬´ë£Œ ì„œë¹„ìŠ¤)"
            recommendation = "âŒ ê°œì„  í•„ìš”, ë² íƒ€ ì„œë¹„ìŠ¤ë¡œë§Œ ìš´ì˜ ê¶Œì¥"

        print(f"\në“±ê¸‰: {grade}")
        print(f"ê¶Œì¥ì‚¬í•­: {recommendation}")

        # ê°œì„  í•„ìš” ì‚¬í•­
        print("\nğŸ“‹ ê°œì„  í•„ìš” ì‚¬í•­:")
        improvements = []
        for criterion, result in zip(COMMERCIAL_CRITERIA, results):
            if result["score"] < criterion.min_score:
                gap = criterion.min_score - result["score"]
                improvements.append(f"  âŒ {criterion.name}: {gap:.1%} ì ìˆ˜ ë¶€ì¡±")

        if improvements:
            for imp in improvements:
                print(imp)
        else:
            print("  âœ… ëª¨ë“  ê¸°ì¤€ ì¶©ì¡±!")

        return {
            "final_score": final_score,
            "grade": grade,
            "commercial_ready": commercial_ready,
            "recommendation": recommendation,
            "criteria_results": results,
            "scenario_results": scenario_result,
        }


async def main():
    evaluator = CommercialReadinessEvaluator()
    result = await evaluator.evaluate_all()

    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    import json
    with open("commercial_readiness_report.json", "w", encoding="utf-8") as f:
        # ì§ë ¬í™” ê°€ëŠ¥í•œ ë°ì´í„°ë§Œ ì €ì¥
        report = {
            "final_score": result["final_score"],
            "grade": result["grade"],
            "commercial_ready": result["commercial_ready"],
            "recommendation": result["recommendation"],
        }
        json.dump(report, f, ensure_ascii=False, indent=2)

    print("\n\nğŸ’¾ í‰ê°€ ê²°ê³¼ê°€ 'commercial_readiness_report.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
