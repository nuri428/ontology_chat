# app/main.py
import os
# import json
import requests
import streamlit as st
from typing import Any, Dict, List

# Enhanced UI components
try:
    from components import (
        display_enhanced_meta_info,
        format_answer_with_quality_indicators,
        display_cache_stats
    )
    ENHANCED_UI_AVAILABLE = True
except ImportError:
    ENHANCED_UI_AVAILABLE = False

# New schema enhanced components
try:
    from enhanced_components import (
        display_listed_company_info,
        display_financial_summary,
        display_investment_summary,
        display_enhanced_graph_metrics,
        create_financial_dashboard,
        display_quality_indicators
    )
    SCHEMA_ENHANCED_UI_AVAILABLE = True
except ImportError:
    SCHEMA_ENHANCED_UI_AVAILABLE = False

# --------- ê¸°ë³¸ ì„¤ì • ---------
st.set_page_config(
    page_title="Enhanced Ontology Chat", 
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --------- ìœ í‹¸: ê³ ìœ  key ìƒì„±ê¸° ----------
def wkey(name: str, prefix: str) -> str:
    """ìœ„ì ¯ í‚¤ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ prefix ë¶€ì—¬"""
    return f"{prefix}__{name}"

def api_base_default() -> str:
    # Docker í™˜ê²½ì—ì„œëŠ” API_BASE_URL, ë¡œì»¬ì—ì„œëŠ” API_BASE ì‚¬ìš©
    return os.getenv("API_BASE_URL") or os.getenv("API_BASE", "http://localhost:8000")


def call_mcp_query_graph_default(params: dict) -> dict:
    url = f"{API_BASE}/mcp/query_graph_default"
    resp = requests.post(url, json=params, timeout=timeout)
    if resp.status_code >= 400:
        raise requests.HTTPError(f"{resp.status_code} {resp.reason}\n{resp.text}", response=resp)
    return resp.json()

# --------- ì‚¬ì´ë“œë°”: ê³µí†µ ì„¤ì • ----------
st.sidebar.header("ì„¤ì •")
API_BASE = st.sidebar.text_input("API Base", value=api_base_default(), key=wkey("api_base", "sidebar"))
timeout = st.sidebar.number_input("API Timeout (s)", value=30, min_value=3, max_value=300, step=5, key=wkey("timeout", "sidebar"))

st.sidebar.markdown("---")
st.sidebar.caption("â€» ë°±ì—”ë“œ(FastAPI) URLì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ì„œ ë°”ê¿”ì£¼ì„¸ìš”.")
st.sidebar.info("ğŸ’¡ ì„œë²„ ì‘ë‹µ ì—†ìœ¼ë©´: íƒ€ì„ì•„ì›ƒì„ 60ì´ˆ ì´ìƒìœ¼ë¡œ ì„¤ì •í•´ë³´ì„¸ìš”")

# --------- ê³µí†µ: ì…ë ¥ ë¸”ë¡ ----------
def query_block(key_prefix: str, defaults: Dict[str, Any] | None = None) -> Dict[str, Any]:
    defaults = defaults or {}
    q = st.text_input(
        "ì§ˆì˜",
        value=defaults.get("q", ""),
        key=wkey("q", key_prefix),
        placeholder="ì˜ˆ) ì‚¼ì„±ì „ì / LGì—ë„ˆì§€ì†”ë£¨ì…˜ / SKí•˜ì´ë‹‰ìŠ¤ / 005930.KS ..."
    )
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        domain = st.text_input(
            "ë„ë©”ì¸(ì„ íƒ)",
            value=defaults.get("domain", "ìƒì¥ì‚¬ íˆ¬ì ì‹¤ì "),
            key=wkey("domain", key_prefix),
            help="ìƒˆ ìŠ¤í‚¤ë§ˆ: ìƒì¥ì‚¬ ì¤‘ì‹¬ ë¶„ì„ ì§€ì› - íˆ¬ì, ì‹¤ì , ì¬ë¬´ì§€í‘œ ë“±"
        )
    with col2:
        lookback = st.number_input(
            "Lookback(ì¼)",
            value=int(defaults.get("lookback_days", 180)),
            min_value=7, max_value=720, step=7,
            key=wkey("lookback", key_prefix),
        )
    with col3:
        limit = st.number_input(
            "Limit",
            value=int(defaults.get("limit", 30)),
            min_value=1, max_value=200, step=1,
            key=wkey("limit", key_prefix),
        )
    return {"q": q, "domain": domain, "lookback_days": int(lookback), "limit": int(limit)}

# --------- API í˜¸ì¶œ í—¬í¼ ----------
def call_chat(query: str) -> Dict[str, Any]:
    url = f"{API_BASE}/chat"
    resp = requests.post(url, json={"query": query}, timeout=timeout)
    resp.raise_for_status()
    return resp.json()

def call_mcp_query_graph(cypher: str|None, params: dict) -> dict:
    url = f"{API_BASE}/mcp/call"
    if not cypher or not cypher.strip():
        # ë¹ˆ cypherëŠ” ì„œë²„ê°€ ê±°ë¶€ â†’ ì—¬ê¸°ì„œ ì˜ˆì™¸ë¥¼ ì¼ìœ¼ì¼œ UIë¡œ ì•ˆë‚´
        raise RuntimeError("Cypherê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì˜ì—­ì— ì‹¤í–‰í•  Cypherë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    payload = {"tool": "query_graph", "args": {"cypher": cypher, "params": params}}
    resp = requests.post(url, json=payload, timeout=timeout)
    # ë””ë²„ê·¸ìš©: ì„œë²„ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
    if resp.status_code >= 400:
        raise requests.HTTPError(f"{resp.status_code} {resp.reason}\n{resp.text}", response=resp)
    return resp.json()

def call_report(payload: Dict[str, Any]) -> Dict[str, Any]:
    """ê¸°ë³¸ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report"
    resp = requests.post(url, json=payload, timeout=timeout)
    resp.raise_for_status()
    return resp.json()

def call_comparative_report(queries: List[str], domain: str = None, lookback_days: int = 180) -> Dict[str, Any]:
    """ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/comparative"
    payload = {
        "queries": queries,
        "domain": domain,
        "lookback_days": lookback_days
    }
    resp = requests.post(url, json=payload, timeout=timeout*2)  # ë¹„êµ ë¶„ì„ì€ ì‹œê°„ì´ ë” ê±¸ë¦¼
    resp.raise_for_status()
    return resp.json()

def call_trend_report(query: str, domain: str = None, periods: List[int] = [30, 90, 180]) -> Dict[str, Any]:
    """íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/trend"
    payload = {
        "query": query,
        "domain": domain,
        "periods": periods
    }
    resp = requests.post(url, json=payload, timeout=timeout*2)  # íŠ¸ë Œë“œ ë¶„ì„ì€ ì‹œê°„ì´ ë” ê±¸ë¦¼
    resp.raise_for_status()
    return resp.json()

def call_executive_report(payload: Dict[str, Any]) -> Dict[str, Any]:
    """ê²½ì˜ì§„ ìš”ì•½ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/executive"
    resp = requests.post(url, json=payload, timeout=timeout)
    resp.raise_for_status()
    return resp.json()

def call_langgraph_report(payload: Dict[str, Any], analysis_depth: str = "standard") -> Dict[str, Any]:
    """LangGraph ê¸°ë°˜ ê³ ê¸‰ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/langgraph"
    payload_with_depth = {**payload, "analysis_depth": analysis_depth}
    resp = requests.post(url, json=payload_with_depth, timeout=timeout*3)  # LangGraphëŠ” ì‹œê°„ì´ ë” ê±¸ë¦¼
    resp.raise_for_status()
    return resp.json()

def call_langgraph_comparative_report(queries: List[str], domain: str = None, lookback_days: int = 180, analysis_depth: str = "standard") -> Dict[str, Any]:
    """LangGraph ê¸°ë°˜ ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/langgraph/comparative"
    payload = {
        "queries": queries,
        "domain": domain,
        "lookback_days": lookback_days,
        "analysis_depth": analysis_depth
    }
    resp = requests.post(url, json=payload, timeout=timeout*5)  # ë¹„êµ ë¶„ì„ì€ ë” ì˜¤ë˜ ê±¸ë¦¼
    resp.raise_for_status()
    return resp.json()

def call_langgraph_trend_report(query: str, domain: str = None, periods: List[int] = [30, 90, 180], analysis_depth: str = "standard") -> Dict[str, Any]:
    """LangGraph ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/report/langgraph/trend"
    payload = {
        "query": query,
        "domain": domain,
        "periods": periods,
        "analysis_depth": analysis_depth
    }
    resp = requests.post(url, json=payload, timeout=timeout*4)  # íŠ¸ë Œë“œ ë¶„ì„ë„ ì˜¤ë˜ ê±¸ë¦¼
    resp.raise_for_status()
    return resp.json()

def call_forecast_report(params: dict) -> dict:
    """ìƒˆë¡œìš´ ì „ë§ ë¦¬í¬íŠ¸ API í˜¸ì¶œ"""
    url = f"{API_BASE}/forecast_report"
    resp = requests.post(url, json=params, timeout=timeout*2)  # ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ
    resp.raise_for_status()
    return resp.json()

# --------- ê·¸ë˜í”„ HTML ë Œë”(pyvis) ----------
def render_pyvis_graph(items: List[Dict[str, Any]], height: str = "680px", key_prefix: str = "graph") -> None:
    """
    items: Neo4j MCP query_graph ê²°ê³¼ì˜ rows(data). ê° ì›ì†Œ ì˜ˆ: {'n': {...}, 'labels': [...], 'r': {...}, 'type': '...'}
    ë…¸ë“œì™€ ê´€ê³„ë¥¼ ëª¨ë‘ ì‹œê°í™”(ë¼ë²¨/íƒ€ì„ìŠ¤íƒ¬í”„ì— ë”°ë¼ ê·¸ë£¹/íˆ´íŒ).
    """
    try:
        from pyvis.network import Network
    except Exception:
        st.warning("pyvisê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install pyvis` í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return

    # pyvis ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™” (Docker í™˜ê²½ì— ìµœì í™”)
    net = Network(
        height=height, 
        width="100%", 
        bgcolor="#111111", 
        font_color="#ffffff", 
        notebook=False, 
        directed=False,
        cdn_resources="remote"  # CDN ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ
    )
    
    # ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • (ì•ˆì •í™” ê°œì„ )
    net.set_options("""
    {
        "physics": {
            "enabled": true,
            "stabilization": {
                "enabled": true,
                "iterations": 200,
                "updateInterval": 50,
                "onlyDynamicEdges": false,
                "fit": true
            },
            "barnesHut": {
                "gravitationalConstant": -2000,
                "centralGravity": 0.3,
                "springLength": 95,
                "springConstant": 0.04,
                "damping": 0.09,
                "avoidOverlap": 0.5
            },
            "maxVelocity": 50,
            "minVelocity": 0.1,
            "solver": "barnesHut",
            "timestep": 0.35
        },
        "nodes": {
            "font": {
                "size": 12,
                "color": "white"
            },
            "borderWidth": 2,
            "borderWidthSelected": 3
        },
        "edges": {
            "font": {
                "size": 10,
                "color": "white"
            },
            "smooth": {
                "type": "continuous"
            }
        }
    }
    """)

    # ë…¸ë“œì™€ ì—ì§€ ì²˜ë¦¬
    seen_nodes = set()
    seen_edges = set()
    
    # 1ë‹¨ê³„: ë…¸ë“œ ì¶”ê°€ (ìµœëŒ€ 20ê°œë¡œ ì œí•œí•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ)
    max_nodes = 20
    for idx, r in enumerate(items[:max_nodes]):
        # ë…¸ë“œ ì •ë³´ ì²˜ë¦¬
        n = r.get("n", {})
        if n:  # ë…¸ë“œê°€ ìˆëŠ” ê²½ìš°
            labels = r.get("labels", [])
            # ê³ ìœ í•œ ë…¸ë“œ ID ìƒì„± (elementIdê°€ ì—†ëŠ” ê²½ìš°)
            nid = n.get("elementId") or n.get("id") or r.get("n_id") or f"node_{idx}"
            if nid in seen_nodes:
                continue
            seen_nodes.add(nid)
            
            # ë…¸ë“œì— ê³ ìœ  ID ì €ì¥ (ê´€ê³„ ì²˜ë¦¬ìš©)
            n["_generated_id"] = nid
            
            title = n.get("title") or n.get("name") or n.get("contractId") or n.get("articleId") or f"Node_{idx}"
            # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            if len(title) > 30:
                title = title[:27] + "..."
            
            group = ",".join(labels) if labels else "Node"
            
            # ë…¸ë“œ ìƒ‰ìƒ ì„¤ì • (ë¼ë²¨ì— ë”°ë¼)
            color = "#97C2FC"  # ê¸°ë³¸ íŒŒë€ìƒ‰
            if "Event" in labels:
                color = "#FFB347"  # ì£¼í™©ìƒ‰
            elif "Company" in labels:
                color = "#98FB98"  # ì—°ë‘ìƒ‰
            elif "Contract" in labels:
                color = "#DDA0DD"  # ìì£¼ìƒ‰
            elif "Product" in labels or "WeaponSystem" in labels:
                color = "#F0E68C"  # ì¹´í‚¤ìƒ‰
            
            tooltip = f"<b>{title}</b><br/>labels={labels}<br/>" + "<br/>".join(f"{k}: {v}" for k, v in n.items() if k not in ("elementId", "_generated_id"))
            net.add_node(nid, label=title, title=tooltip, group=group, color=color, size=20)
    
    # 2ë‹¨ê³„: ì—ì§€ ì¶”ê°€ (ê´€ê³„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°) - ì œí•œëœ ë…¸ë“œì— ëŒ€í•´ì„œë§Œ
    for r in items[:max_nodes]:
        # ìƒˆë¡œìš´ ê´€ê³„ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬ (all_relationships)
        all_relationships = r.get("all_relationships", [])
        if all_relationships:
            current_node = r.get("n", {})
            current_node_id = current_node.get("_generated_id") or current_node.get("elementId") or current_node.get("id")
            
            for rel_list in all_relationships:
                if isinstance(rel_list, list):
                    for rel in rel_list:
                        if isinstance(rel, list) and len(rel) >= 3:
                            # [start_node, rel_type, end_node] í˜•íƒœ
                            start_node_obj, rel_type, end_node_obj = rel[0], rel[1], rel[2]
                            
                            # ì‹œì‘ ë…¸ë“œê°€ ë¹„ì–´ìˆê³  ë ë…¸ë“œì— ì´ë²¤íŠ¸ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°
                            # í˜„ì¬ ë…¸ë“œì—ì„œ ì´ë²¤íŠ¸ë¡œì˜ ê´€ê³„ë¡œ ì²˜ë¦¬
                            if (not start_node_obj or start_node_obj == {}) and isinstance(end_node_obj, dict) and end_node_obj:
                                # ì´ë²¤íŠ¸ ë…¸ë“œ ì°¾ê¸° (ê°™ì€ ì´ë²¤íŠ¸ IDë¥¼ ê°€ì§„ ë…¸ë“œ)
                                event_id = end_node_obj.get("eventId")
                                if event_id:
                                    # ë‹¤ë¥¸ ë…¸ë“œë“¤ ì¤‘ì—ì„œ ê°™ì€ eventIdë¥¼ ê°€ì§„ ë…¸ë“œ ì°¾ê¸°
                                    for other_r in items:
                                        other_node = other_r.get("n", {})
                                        if (other_node.get("eventId") == event_id and 
                                            other_node.get("_generated_id") != current_node_id):
                                            other_node_id = other_node.get("_generated_id")
                                            if other_node_id:
                                                edge_id = f"{current_node_id}_{other_node_id}_{rel_type}"
                                                if edge_id not in seen_edges:
                                                    seen_edges.add(edge_id)
                                                    net.add_edge(current_node_id, other_node_id, label=rel_type, title=rel_type)
                                                break
        
        # ê¸°ì¡´ ê´€ê³„ ì •ë³´ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)
        rel = r.get("r", {})
        if rel:  # ê´€ê³„ê°€ ìˆëŠ” ê²½ìš°
            start_node = r.get("start_id") or (r.get("start", {}) or {}).get("elementId") or (r.get("start", {}) or {}).get("id")
            end_node = r.get("end_id") or (r.get("end", {}) or {}).get("elementId") or (r.get("end", {}) or {}).get("id")
            rel_type = r.get("type", "RELATES_TO")
            
            if start_node and end_node and start_node != end_node:
                edge_id = f"{start_node}_{end_node}_{rel_type}"
                if edge_id not in seen_edges:
                    seen_edges.add(edge_id)
                    net.add_edge(start_node, end_node, label=rel_type, title=rel_type)
    
    # 3ë‹¨ê³„: ê´€ê³„ê°€ ì—†ëŠ” ê²½ìš°, ë…¸ë“œë“¤ ê°„ì˜ ê°€ìƒ ì—°ê²° ìƒì„± (ì„ íƒì )
    if not seen_edges and len(seen_nodes) > 1:
        st.info("ê´€ê³„ ì •ë³´ê°€ ì—†ì–´ ë…¸ë“œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ê´€ê³„ë¥¼ ë³´ë ¤ë©´ Neo4j ì¿¼ë¦¬ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
        # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
        st.write(f"ê´€ê³„ ë°ì´í„° ìƒ˜í”Œ: {all_relationships[:2] if all_relationships else 'None'}")
        st.write(f"í˜„ì¬ ë…¸ë“œ ID: {[r.get('n', {}).get('_generated_id') for r in items]}")

    # (ê°„ë‹¨ ë²„ì „) ê´€ê³„(edge) ì—†ì´ ë…¸ë“œë§Œ. ê´€ê³„ ì‹œê°í™”ê°€ í•„ìš”í•˜ë©´ ë°±ì—”ë“œì—ì„œ edgesê¹Œì§€ ë„˜ê²¨ì£¼ì„¸ìš”.
    try:
        # HTMLì„ ì§ì ‘ ìƒì„±í•˜ì—¬ Streamlitì—ì„œ í‘œì‹œ
        html_content = net.generate_html()
        st.components.v1.html(html_content, height=int(height.replace("px", "")), scrolling=True)
    except Exception as e:
        st.error(f"ê·¸ë˜í”„ ë Œë”ë§ ì˜¤ë¥˜: {str(e)}")
        st.info("ê·¸ë˜í”„ ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë°ì´í„°ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œ
        if items:
            import pandas as pd
            df_data = []
            for r in items:
                n = r.get("n", {})
                labels = r.get("labels", [])
                row = {
                    "ID": n.get("elementId") or n.get("id", ""),
                    "Title": n.get("title") or n.get("name") or n.get("contractId") or n.get("articleId", ""),
                    "Labels": ", ".join(labels),
                    "Type": n.get("event_type") or n.get("type", ""),
                    "Published": n.get("published_at", ""),
                }
                df_data.append(row)
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True)

# --------- ë©”ì¸ í—¤ë” ----------
st.title("ğŸš€ Enhanced Ontology Chat System")
st.markdown("""
**Context Engineering ì‹œìŠ¤í…œ**ì´ ì—…ê·¸ë ˆì´ë“œë˜ì—ˆìŠµë‹ˆë‹¤! 
ğŸ” ì§€ëŠ¥í˜• ê²€ìƒ‰, ğŸ’¡ LLM ì¸ì‚¬ì´íŠ¸, âš¡ ìºì‹±, ğŸ›¡ï¸ ì•ˆì •ì„±ì´ ëª¨ë‘ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
""")

if ENHANCED_UI_AVAILABLE:
    st.success("âœ… Enhanced UI ì»´í¬ë„ŒíŠ¸ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    st.info("â„¹ï¸ ê¸°ë³¸ UIë¡œ ë™ì‘í•©ë‹ˆë‹¤. í–¥ìƒëœ ê¸°ëŠ¥ì„ ìœ„í•´ `ui/components.py`ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

st.divider()

# --------- íƒ­ êµ¬ì„± ----------
tab_chat, tab_graph, tab_report = st.tabs(["ğŸ’¬ Enhanced Chat", "ğŸ”— ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸", "ğŸ“‘ ë¦¬í¬íŠ¸"])

# ========== íƒ­ 1: Enhanced Chat ==========
with tab_chat:
    # í–¥ìƒëœ ì…ë ¥ ì˜ì—­
    col1, col2 = st.columns([3, 1])
    with col1:
        c_q = st.text_input(
            "ì§ˆì˜",
            value="",
            key=wkey("q", "chat"),
            placeholder="ì˜ˆ: SMR ê´€ë ¨ ìœ ë§ ì¢…ëª©ì€?, 2ì°¨ì „ì§€ ìµœì‹  ë™í–¥, ë°˜ë„ì²´ ì‹œì¥ ì „ë§ ë“±"
        )
    with col2:
        # ìºì‹œ í†µê³„ ë²„íŠ¼ (í–¥í›„ í™•ì¥ìš©)
        if ENHANCED_UI_AVAILABLE:
            show_cache = st.button("ğŸ“Š ìºì‹œ í†µê³„", key=wkey("cache_stats", "chat"))
            if show_cache:
                display_cache_stats()

    # ì‹¤í–‰ ì˜µì…˜
    col_run, col_clear = st.columns([1, 1])
    with col_run:
        c_run = st.button("ğŸš€ ì§ˆì˜ ì‹¤í–‰", key=wkey("run", "chat"), type="primary")
    with col_clear:
        if st.button("ğŸ—‘ï¸ ê²°ê³¼ ì´ˆê¸°í™”", key=wkey("clear", "chat")):
            st.rerun()

    if c_run:
        with st.spinner("Context Engineering ì‹œìŠ¤í…œì´ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                data = call_chat(c_q)

                # ì„±ê³µì ì¸ ì‘ë‹µ ì²˜ë¦¬
                answer = data.get("answer", "")
                meta = data.get("meta", {})
                sources = data.get("sources", [])

                # í–¥ìƒëœ ë‹µë³€ í‘œì‹œ (í’ˆì§ˆ ì§€í‘œ í¬í•¨)
                if ENHANCED_UI_AVAILABLE and meta:
                    enhanced_answer = format_answer_with_quality_indicators(answer, meta)
                    st.markdown(enhanced_answer)
                else:
                    st.markdown(answer)

                # êµ¬ë¶„ì„ 
                st.divider()

                # í–¥ìƒëœ ë©”íƒ€ì •ë³´ í‘œì‹œ
                if ENHANCED_UI_AVAILABLE and meta:
                    st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
                    display_enhanced_meta_info(meta)

                # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ ê°œì„  - í‘œ í˜•ì‹ ì¶”ê°€
                if sources:
                    st.markdown("### ğŸ“° ì°¸ê³  ì†ŒìŠ¤")

                    # í‘œì‹œ ë°©ì‹ ì„ íƒ
                    col_view, col_export = st.columns([2, 1])
                    with col_view:
                        view_mode = st.radio(
                            "í‘œì‹œ ë°©ì‹",
                            ["í‘œ í˜•ì‹", "ë¦¬ìŠ¤íŠ¸ í˜•ì‹"],
                            horizontal=True,
                            key=wkey("view_mode", "chat_sources")
                        )

                    if view_mode == "í‘œ í˜•ì‹":
                        # í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ - Streamlit ë„¤ì´í‹°ë¸Œ ë°©ì‹
                        import pandas as pd

                        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                        news_data = []
                        for i, source in enumerate(sources[:10], 1):  # ìµœëŒ€ 10ê°œê¹Œì§€
                            title = source.get("title", "ì œëª© ì—†ìŒ")
                            url = source.get("url", "")
                            date = source.get("date", "")
                            score = source.get("score", 0)

                            # ì œëª© ê¸¸ì´ ì œí•œ
                            if len(title) > 60:
                                title = title[:57] + "..."

                            news_data.append({
                                "ìˆœë²ˆ": i,
                                "ì œëª©": title,
                                "ë‚ ì§œ": date[:10] if date else "-",
                                "ì ìˆ˜": f"{score:.2f}" if score else "-",
                                "URL": url if url else "-"
                            })

                        df = pd.DataFrame(news_data)

                        # Streamlit ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ (ì»¬ëŸ¼ ì„¤ì • í¬í•¨)
                        st.dataframe(
                            df,
                            use_container_width=True,
                            hide_index=True,
                            column_config={
                                "ìˆœë²ˆ": st.column_config.NumberColumn(
                                    "ìˆœë²ˆ",
                                    width="small",
                                    format="%d"
                                ),
                                "ì œëª©": st.column_config.TextColumn(
                                    "ì œëª©",
                                    width="large",
                                    help="ë‰´ìŠ¤ ì œëª©"
                                ),
                                "ë‚ ì§œ": st.column_config.DateColumn(
                                    "ë°œí–‰ì¼",
                                    width="medium",
                                    format="YYYY-MM-DD"
                                ),
                                "ì ìˆ˜": st.column_config.NumberColumn(
                                    "ê´€ë ¨ë„",
                                    width="small",
                                    format="%.2f"
                                ),
                                "URL": st.column_config.LinkColumn(
                                    "ë§í¬",
                                    width="medium",
                                    help="ë‰´ìŠ¤ ì›ë¬¸ ë§í¬",
                                    display_text="ğŸ”— ì›ë¬¸ë³´ê¸°"
                                )
                            }
                        )

                        # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        csv = df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“„ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                            data=csv,
                            file_name="news_sources.csv",
                            mime="text/csv",
                            key=wkey("download_csv", "chat_sources")
                        )

                    else:
                        # ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹
                        for i, source in enumerate(sources[:5], 1):
                            with st.container():
                                col1, col2 = st.columns([3, 1])
                                with col1:
                                    title = source.get("title", "ì œëª© ì—†ìŒ")
                                    url = source.get("url", "")
                                    if url:
                                        st.markdown(f"**{i}.** [{title}]({url})")
                                    else:
                                        st.markdown(f"**{i}.** {title}")
                                with col2:
                                    date = source.get("date", "")
                                    score = source.get("score", 0)
                                    if date:
                                        st.caption(f"ğŸ“… {date[:10]}")
                                    if score:
                                        st.caption(f"â­ {score:.2f}")

                # ì „ì²´ ê²°ê³¼ JSON (ê°œë°œììš©)
                with st.expander("ğŸ” ì „ì²´ ì‘ë‹µ ë°ì´í„° (ê°œë°œììš©)", expanded=False):
                    st.json(data)

            except requests.exceptions.Timeout:
                st.error("â° ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ê°„ë‹¨í•œ ì§ˆì˜ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
            except requests.exceptions.ConnectionError:
                st.error("ğŸ”Œ API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API_BASE ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            except requests.exceptions.HTTPError as he:
                st.error(f"ğŸš¨ API ì˜¤ë¥˜: {he}")
                if hasattr(he, 'response') and he.response is not None:
                    st.code(he.response.text)
            except Exception as e:
                st.error(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
                st.exception(e)

                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë„ì›€ë§ ì œê³µ
                with st.expander("ğŸ’¡ ë¬¸ì œ í•´ê²° ë„ì›€ë§", expanded=True):
                    st.markdown("""
                    **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:**
                    1. API ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
                    2. ì‚¬ì´ë“œë°”ì—ì„œ API Base URL í™•ì¸
                    3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸
                    4. ì§ˆì˜ë¥¼ ë” ê°„ë‹¨í•˜ê²Œ ìˆ˜ì •

                    **ì¶”ì²œ ì§ˆì˜ ì˜ˆì‹œ:**
                    - "ì‚¼ì„±ì „ì ìµœê·¼ ë‰´ìŠ¤"
                    - "2ì°¨ì „ì§€ ì—…ê³„ ë™í–¥"
                    - "ë°˜ë„ì²´ ì‹œì¥ ì „ë§"
                    - "KAI ì‹¤ì  ì „ë§"
                    """)

    # ë„ì›€ë§ ì„¹ì…˜
    with st.expander("â“ Context Engineering ì‹œìŠ¤í…œ ë„ì›€ë§", expanded=False):
        st.markdown("""
        ### ğŸš€ í–¥ìƒëœ ê¸°ëŠ¥ë“¤

        **ğŸ” ì§€ëŠ¥í˜• ê²€ìƒ‰**: ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ì „ëµìœ¼ë¡œ ë” ì •í™•í•œ ê²°ê³¼
        **ğŸ’¡ ë™ì  ì¸ì‚¬ì´íŠ¸**: LLM ê¸°ë°˜ ì‹¤ì‹œê°„ ë¶„ì„
        **ğŸ“Š ê°œì¸í™”**: ì§ˆì˜ ìœ í˜•ë³„ ë§ì¶¤ ì‘ë‹µ
        **âš¡ ìºì‹±**: ë¹ ë¥¸ ì‘ë‹µ ì†ë„
        **ğŸ›¡ï¸ ì•ˆì •ì„±**: ì„œë¹„ìŠ¤ ì¥ì•  ì‹œì—ë„ ê¸°ë³¸ ì‘ë‹µ ì œê³µ

        ### ğŸ’­ ì§ˆì˜ íŒ
        - **êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ** ì‚¬ìš© (ì˜ˆ: "ì‚¼ì„±ì „ì", "SMR", "2ì°¨ì „ì§€")
        - **ì‹œê°„ ë²”ìœ„** í¬í•¨ (ì˜ˆ: "ìµœê·¼", "2024ë…„")
        - **ê´€ì‹¬ ì˜ì—­** ëª…ì‹œ (ì˜ˆ: "íˆ¬ì", "ìˆ˜ì¶œ", "ì‹¤ì ")
        """)

# ========== íƒ­ 2: ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ==========
with tab_graph:
    st.subheader("ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ")
    g_input = query_block("graph", defaults={"q": "", "limit": 30, "lookback_days": 180})
    
    # ê´€ê³„ í¬í•¨ ì˜µì…˜
    include_relationships = st.checkbox("ê´€ê³„(ì—ì§€) í¬í•¨", value=False, key=wkey("include_rels", "graph"))
    
    cypher_txt = st.text_area(
        "Cypher (í™˜ê²½ì„¤ì • íŒŒì¼ì„ ì“°ì§€ ì•Šê³  ì§ì ‘ ì‹¤í–‰í•˜ë ¤ë©´ ì—¬ê¸°ì— ë¶™ì—¬ë„£ê¸°)",
        value="",
        height=200,
        key=wkey("cypher", "graph"),
        placeholder="ë¹„ì›Œë‘ë©´ ì„œë²„ ì„¤ì •(config/graph_search.cypher) ì‚¬ìš©"
    )
    
    # ê´€ê³„ í¬í•¨ ì¿¼ë¦¬ ì˜ˆì‹œ
    if include_relationships and not cypher_txt:
        st.info("ê´€ê³„ë¥¼ í¬í•¨í•œ ì¿¼ë¦¬ ì˜ˆì‹œ:")
        example_cypher = """
MATCH (n)-[r]-(m)
WHERE toLower(n.title) CONTAINS toLower($q) OR toLower(m.title) CONTAINS toLower($q)
RETURN n, labels(n) AS labels,
       r, type(r) AS type,
       m AS end, labels(m) AS end_labels,
       elementId(n) AS start_id, elementId(m) AS end_id
LIMIT $limit
        """.strip()
        st.code(example_cypher, language="cypher")
    run = st.button("ê·¸ë˜í”„ ì§ˆì˜ ì‹¤í–‰", key=wkey("run", "graph"))
    if run:
        try:
            res = None
            params = {
                "q": g_input["q"],
                "domain": g_input["domain"],
                "lookback_days": g_input["lookback_days"],
                "limit": g_input["limit"],
            }
            
            # API í˜¸ì¶œ ì „ ë””ë²„ê·¸
            st.info(f"API í˜¸ì¶œ íŒŒë¼ë¯¸í„°: {params}")
            
            if cypher_txt.strip():
                st.info("ì‚¬ìš©ì ì •ì˜ Cypher ì¿¼ë¦¬ ì‚¬ìš©")
                res = call_mcp_query_graph(cypher_txt, params)
            else:
                st.info("ê¸°ë³¸ ê·¸ë˜í”„ ê²€ìƒ‰ ì¿¼ë¦¬ ì‚¬ìš©")
                res = call_mcp_query_graph_default(params)
            if not res or not res.get("ok"):
                st.error(f"MCP query_graph ì‹¤íŒ¨: {res}")
            else:
                rows = res.get("data", [])
                if rows:
                    st.success(f"ë…¸ë“œ {len(rows)}ê°œ ìˆ˜ì‹ ")
                else:
                    st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                    st.info("ğŸ’¡ **ì¶”ì²œ í‚¤ì›Œë“œ**: 'ì‚¼ì„±ì „ì', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'SKí•˜ì´ë‹‰ìŠ¤', '005930.KS' ë“±ìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                
                # API ì‘ë‹µ ë””ë²„ê·¸
                with st.expander("ğŸ” API ì‘ë‹µ ë””ë²„ê·¸", expanded=False):
                    st.write("API ì‘ë‹µ ì „ì²´:")
                    st.json(res)
                
                # ë°ì´í„° íƒ€ì…ë³„ë¡œ ë¶„ë¥˜ - ìƒˆ ìŠ¤í‚¤ë§ˆ ë…¸ë“œ í¬í•¨
                news_data = [r for r in rows if "News" in r.get("labels", [])]
                event_data = [r for r in rows if "Event" in r.get("labels", [])]
                company_data = [r for r in rows if "Company" in r.get("labels", [])]
                other_data = [r for r in rows if not any(label in ["News", "Event", "Company"] for label in r.get("labels", []))]
                
                # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
                with st.expander("ğŸ” ë””ë²„ê·¸ ì •ë³´", expanded=False):
                    st.write(f"ì „ì²´ ë°ì´í„° ê°œìˆ˜: {len(rows)}")
                    st.write(f"ë‰´ìŠ¤ ë°ì´í„° ê°œìˆ˜: {len(news_data)}")
                    st.write(f"ì´ë²¤íŠ¸ ë°ì´í„° ê°œìˆ˜: {len(event_data)}")
                    st.write(f"íšŒì‚¬ ë°ì´í„° ê°œìˆ˜: {len(company_data)}")
                    st.write(f"ê¸°íƒ€ ë°ì´í„° ê°œìˆ˜: {len(other_data)}")
                    if rows:
                        st.write("ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ:")
                        st.json(rows[0])
                
                # íƒ­ìœ¼ë¡œ ë°ì´í„° ë¶„ë¥˜ í‘œì‹œ
                tab_news, tab_events, tab_companies, tab_others, tab_graph_viz = st.tabs([
                    f"ğŸ“° ë‰´ìŠ¤ ({len(news_data)})", 
                    f"ğŸ“… ì´ë²¤íŠ¸ ({len(event_data)})", 
                    f"ğŸ¢ íšŒì‚¬ ({len(company_data)})", 
                    f"ğŸ”— ê¸°íƒ€ ({len(other_data)})",
                    "ğŸ¨ ê·¸ë˜í”„"
                ])
                
                # ë‰´ìŠ¤ íƒ­
                with tab_news:
                    if news_data:
                        st.subheader("ì—°ê´€ ë‰´ìŠ¤")

                        # í‘œì‹œ ë°©ì‹ ì„ íƒ
                        news_view_mode = st.radio(
                            "í‘œì‹œ ë°©ì‹",
                            ["í‘œ í˜•ì‹", "ë¦¬ìŠ¤íŠ¸ í˜•ì‹"],
                            horizontal=True,
                            key=wkey("news_view_mode", "graph")
                        )

                        if news_view_mode == "í‘œ í˜•ì‹":
                            # í‘œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                            import pandas as pd

                            # ë‰´ìŠ¤ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                            news_table_data = []
                            for i, news in enumerate(news_data[:10], 1):
                                n = news.get("n", {})
                                url = n.get("url", "")
                                article_id = n.get("articleId", "")
                                last_seen = n.get("lastSeenAt", "")
                                title = n.get("title", "") or f"Article {article_id}"

                                # ì œëª© ê¸¸ì´ ì œí•œ
                                if len(title) > 50:
                                    title = title[:47] + "..."

                                news_table_data.append({
                                    "ìˆœë²ˆ": i,
                                    "ì œëª©": title,
                                    "Article ID": article_id,
                                    "ë°œê²¬ì¼": last_seen[:10] if last_seen else "-",
                                    "URL": url if url else "-"
                                })

                            news_df = pd.DataFrame(news_table_data)

                            # Streamlit ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
                            st.dataframe(
                                news_df,
                                use_container_width=True,
                                hide_index=True,
                                column_config={
                                    "ìˆœë²ˆ": st.column_config.NumberColumn(
                                        "ìˆœë²ˆ",
                                        width="small",
                                        format="%d"
                                    ),
                                    "ì œëª©": st.column_config.TextColumn(
                                        "ì œëª©",
                                        width="large",
                                        help="ë‰´ìŠ¤ ì œëª©"
                                    ),
                                    "Article ID": st.column_config.TextColumn(
                                        "ê¸°ì‚¬ ID",
                                        width="medium",
                                        help="ê¸°ì‚¬ ê³ ìœ  ì‹ë³„ì"
                                    ),
                                    "ë°œê²¬ì¼": st.column_config.DateColumn(
                                        "ë°œê²¬ì¼",
                                        width="medium",
                                        format="YYYY-MM-DD"
                                    ),
                                    "URL": st.column_config.LinkColumn(
                                        "ë§í¬",
                                        width="medium",
                                        help="ë‰´ìŠ¤ ì›ë¬¸ ë§í¬",
                                        display_text="ğŸ”— ì›ë¬¸ë³´ê¸°"
                                    )
                                }
                            )

                            # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            news_csv = news_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ğŸ“„ ë‰´ìŠ¤ CSV ë‹¤ìš´ë¡œë“œ",
                                data=news_csv,
                                file_name="graph_news.csv",
                                mime="text/csv",
                                key=wkey("download_news_csv", "graph")
                            )

                        else:
                            # ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹
                            for i, news in enumerate(news_data[:10]):  # ìµœëŒ€ 10ê°œ í‘œì‹œ
                                n = news.get("n", {})
                                url = n.get("url", "")
                                article_id = n.get("articleId", "")
                                last_seen = n.get("lastSeenAt", "")

                                with st.container():
                                    col1, col2 = st.columns([3, 1])
                                    with col1:
                                        if url:
                                            st.markdown(f"**ë‰´ìŠ¤ {i+1}**: [{url}]({url})")
                                        else:
                                            st.markdown(f"**ë‰´ìŠ¤ {i+1}**: Article ID {article_id}")
                                    with col2:
                                        if last_seen:
                                            st.caption(f"ë°œê²¬: {last_seen[:10]}")
                                    st.divider()
                    else:
                        st.info("ì—°ê´€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì´ë²¤íŠ¸ íƒ­
                with tab_events:
                    if event_data:
                        st.subheader("ê´€ë ¨ ì´ë²¤íŠ¸")
                        for i, event in enumerate(event_data[:10]):
                            n = event.get("n", {})
                            title = n.get("title", "ì œëª© ì—†ìŒ")
                            event_type = n.get("event_type", "")
                            published_at = n.get("published_at", "")
                            
                            with st.container():
                                st.markdown(f"**{i+1}. {title}**")
                                if event_type:
                                    st.caption(f"ìœ í˜•: {event_type}")
                                if published_at:
                                    st.caption(f"ë°œí–‰ì¼: {published_at}")
                                st.divider()
                    else:
                        st.info("ê´€ë ¨ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # íšŒì‚¬ íƒ­
                with tab_companies:
                    if company_data:
                        st.subheader("ê´€ë ¨ íšŒì‚¬")
                        for i, company in enumerate(company_data[:10]):
                            n = company.get("n", {})
                            name = n.get("name", "ì´ë¦„ ì—†ìŒ")
                            ticker = n.get("ticker", "")
                            
                            with st.container():
                                st.markdown(f"**{i+1}. {name}**")
                                if ticker:
                                    st.caption(f"í‹°ì»¤: {ticker}")
                                st.divider()
                    else:
                        st.info("ê´€ë ¨ íšŒì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ê¸°íƒ€ íƒ­
                with tab_others:
                    if other_data:
                        st.subheader("ê¸°íƒ€ ë°ì´í„°")
                        for i, item in enumerate(other_data[:10]):
                            n = item.get("n", {})
                            labels = item.get("labels", [])
                            title = n.get("title") or n.get("name") or n.get("contractId") or "ì œëª© ì—†ìŒ"
                            
                            with st.container():
                                st.markdown(f"**{i+1}. {title}**")
                                st.caption(f"íƒ€ì…: {', '.join(labels)}")
                                st.divider()
                    else:
                        st.info("ê¸°íƒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ê·¸ë˜í”„ íƒ­
                with tab_graph_viz:
                    render_pyvis_graph(rows, key_prefix="graph")
        except Exception as e:
            st.exception(e)

# ========== íƒ­ 3: ë¦¬í¬íŠ¸ ==========
with tab_report:
    st.header("ğŸ“Š í…Œë§ˆë³„ ì¢…ëª© ì „ë§ ë¦¬í¬íŠ¸")
    st.markdown("**í…Œë§ˆ ë˜ëŠ” ê°œë³„ ì¢…ëª©ì„ ì„ íƒí•˜ì—¬ ë‰´ìŠ¤, ì˜¨í†¨ë¡œì§€, ì¬ë¬´ì •ë³´ ê¸°ë°˜ ì „ë§ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤**")

    # ë¦¬í¬íŠ¸ ëª¨ë“œ ì„ íƒ
    report_mode = st.radio(
        "ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“œ",
        ["ğŸ¯ í…Œë§ˆë³„ ë¶„ì„", "ğŸ¢ ê°œë³„ ì¢…ëª© ë¶„ì„"],
        horizontal=True,
        key=wkey("report_mode", "report"),
        help="í…Œë§ˆë³„ ë¶„ì„: 2ì°¨ì „ì§€, ë°˜ë„ì²´, ì›ìë ¥ ë“± / ê°œë³„ ì¢…ëª©: íŠ¹ì • ìƒì¥ì‚¬ ì¤‘ì‹¬ ë¶„ì„"
    )

    # í…Œë§ˆë³„ ì¢…ëª© ë°ì´í„° êµ¬ì„±
    THEME_SECTORS = {
        "ğŸ”‹ 2ì°¨ì „ì§€/ì—ë„ˆì§€": {
            "keywords": ["ë°°í„°ë¦¬", "2ì°¨ì „ì§€", "ë¦¬íŠ¬", "ì „ê¸°ì°¨", "ESS"],
            "companies": [
                {"name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "code": "373220", "sector": "ë°°í„°ë¦¬"},
                {"name": "ì‚¼ì„±SDI", "code": "006400", "sector": "ë°°í„°ë¦¬"},
                {"name": "SKì˜¨", "code": "096770", "sector": "ë°°í„°ë¦¬"},
                {"name": "í¬ìŠ¤ì½”ì¼€ë¯¸ì¹¼", "code": "003670", "sector": "ë°°í„°ë¦¬ ì†Œì¬"},
                {"name": "ì—ì½”í”„ë¡œ", "code": "086520", "sector": "ì–‘ê·¹ì¬"},
                {"name": "L&F", "code": "066970", "sector": "ì–‘ê·¹ì¬"}
            ]
        },
        "ğŸ’¾ ë°˜ë„ì²´/IT": {
            "keywords": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ì‹œìŠ¤í…œë°˜ë„ì²´", "AIì¹©", "HBM"],
            "companies": [
                {"name": "ì‚¼ì„±ì „ì", "code": "005930", "sector": "ì¢…í•© ë°˜ë„ì²´"},
                {"name": "SKí•˜ì´ë‹‰ìŠ¤", "code": "000660", "sector": "ë©”ëª¨ë¦¬ ë°˜ë„ì²´"},
                {"name": "ì¹´ì¹´ì˜¤", "code": "035720", "sector": "IT í”Œë«í¼"},
                {"name": "ë„¤ì´ë²„", "code": "035420", "sector": "IT í”Œë«í¼"},
                {"name": "LGì´ë…¸í…", "code": "011070", "sector": "ì „ìë¶€í’ˆ"}
            ]
        },
        "ğŸš— ëª¨ë¹Œë¦¬í‹°/ìë™ì°¨": {
            "keywords": ["ìë™ì°¨", "ì „ê¸°ì°¨", "ììœ¨ì£¼í–‰", "ëª¨ë¹Œë¦¬í‹°"],
            "companies": [
                {"name": "í˜„ëŒ€ì°¨", "code": "005380", "sector": "ì™„ì„±ì°¨"},
                {"name": "ê¸°ì•„", "code": "000270", "sector": "ì™„ì„±ì°¨"},
                {"name": "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "code": "012330", "sector": "ìë™ì°¨ ë¶€í’ˆ"},
                {"name": "LGì „ì", "code": "066570", "sector": "ì „ì¥ ë¶€í’ˆ"},
                {"name": "ì‚¼ì„±ì „ê¸°", "code": "009150", "sector": "ì „ìë¶€í’ˆ"}
            ]
        },
        "ğŸ—ï¸ ê±´ì„¤/ì¸í”„ë¼": {
            "keywords": ["ê±´ì„¤", "ì¸í”„ë¼", "ìŠ¤ë§ˆíŠ¸ì‹œí‹°", "í•´ì™¸ìˆ˜ì£¼"],
            "companies": [
                {"name": "í˜„ëŒ€ê±´ì„¤", "code": "000720", "sector": "ê±´ì„¤"},
                {"name": "ì‚¼ì„±ë¬¼ì‚°", "code": "028260", "sector": "ê±´ì„¤/ìƒì‚¬"},
                {"name": "GSê±´ì„¤", "code": "006360", "sector": "ê±´ì„¤"},
                {"name": "ëŒ€ìš°ê±´ì„¤", "code": "047040", "sector": "ê±´ì„¤"}
            ]
        },
        "ğŸ’» IT/ì†Œí”„íŠ¸ì›¨ì–´": {
            "keywords": ["IT", "ì†Œí”„íŠ¸ì›¨ì–´", "í´ë¼ìš°ë“œ", "ì¸ê³µì§€ëŠ¥", "AI", "ë¹…ë°ì´í„°"],
            "companies": [
                {"name": "ì‚¼ì„±SDS", "code": "018260", "sector": "IT ì„œë¹„ìŠ¤"},
                {"name": "LG CNS", "code": "251270", "sector": "IT ì„œë¹„ìŠ¤"},
                {"name": "ë„¤ì´ë²„", "code": "035420", "sector": "ì¸í„°ë„· ì„œë¹„ìŠ¤"},
                {"name": "ì¹´ì¹´ì˜¤", "code": "035720", "sector": "ì¸í„°ë„· ì„œë¹„ìŠ¤"},
                {"name": "ì—”ì”¨ì†Œí”„íŠ¸", "code": "036550", "sector": "ì†Œí”„íŠ¸ì›¨ì–´"},
                {"name": "ë‘ì‚°ë²”ë¹„ê³„", "code": "018880", "sector": "ERP ì†Œí”„íŠ¸ì›¨ì–´"}
            ]
        },
        "ğŸ§¬ ë°”ì´ì˜¤/ì˜ë£Œ": {
            "keywords": ["ë°”ì´ì˜¤", "ì œì•½", "ì˜ë£Œ", "í—¬ìŠ¤ì¼€ì–´", "ì‹ ì•½", "ì§„ë‹¨"],
            "companies": [
                {"name": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "code": "207940", "sector": "ë°”ì´ì˜¤ì˜ì•½í’ˆ"},
                {"name": "ì…€íŠ¸ë¦¬ì˜¨", "code": "068270", "sector": "ì œì•½"},
                {"name": "ë°”ì´ì˜¤ë‹ˆì•„", "code": "064550", "sector": "ë°”ì´ì˜¤ì˜ì•½í’ˆ"},
                {"name": "ëŒ€ì›…ì œì•½", "code": "069620", "sector": "ì œì•½"},
                {"name": "ë²„í…ìƒëª…ê³¼í•™", "code": "036010", "sector": "ì œì•½"},
                {"name": "ìœ í•œì–‘í–‰", "code": "000210", "sector": "ì˜ë£Œê¸°ê¸°"}
            ]
        },
        "âš¡ ì—ë„ˆì§€/ë°°í„°ë¦¬": {
            "keywords": ["ì—ë„ˆì§€", "ì‹ ì¬ìƒ", "íƒœì–‘ê´‘", "í’ë ¥", "ë°°í„°ë¦¬", "ì „ê¸°ì°¨"],
            "companies": [
                {"name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "code": "373220", "sector": "ë°°í„°ë¦¬"},
                {"name": "ì‚¼ì„±SDI", "code": "006400", "sector": "ë°°í„°ë¦¬"},
                {"name": "í•œí™”ì†”ë£¨ì…˜", "code": "009830", "sector": "íƒœì–‘ê´‘/ì—ë„ˆì§€"},
                {"name": "OCI", "code": "010060", "sector": "íƒœì–‘ê´‘ ì†Œì¬"},
                {"name": "ì›ì§„ê·¸ë¦°", "code": "143540", "sector": "íƒœì–‘ê´‘"},
                {"name": "ë‘ì‚°ì—ë„ˆë¹Œ", "code": "069730", "sector": "í’ë ¥"}
            ]
        }
    }

    # ëª¨ë“œë³„ UI êµ¬ì„±
    if report_mode == "ğŸ¯ í…Œë§ˆë³„ ë¶„ì„":
        st.subheader("ğŸ¯ í…Œë§ˆë³„ ë¶„ì„ ì„¤ì •")

        # í…Œë§ˆ ì„ íƒ
        selected_theme = st.selectbox(
            "ë¶„ì„í•  í…Œë§ˆ ì„ íƒ",
            list(THEME_SECTORS.keys()),
            key=wkey("theme_select", "report"),
            help="ê° í…Œë§ˆë³„ë¡œ ê´€ë ¨ ì¢…ëª©ë“¤ê³¼ í‚¤ì›Œë“œê°€ ìë™ ì„¤ì •ë©ë‹ˆë‹¤"
        )

        # ì„ íƒëœ í…Œë§ˆ ì •ë³´ í‘œì‹œ
        theme_data = THEME_SECTORS[selected_theme]

        col1, col2 = st.columns([1, 1])
        with col1:
            st.markdown("**ğŸ” ë¶„ì„ í‚¤ì›Œë“œ**")
            st.info(" â€¢ ".join(theme_data["keywords"]))

        with col2:
            st.markdown("**ğŸ¢ í¬í•¨ ì¢…ëª©**")
            company_list = [f"{comp['name']}({comp['code']})" for comp in theme_data["companies"]]
            st.info(" â€¢ ".join(company_list[:3]) + f" ì™¸ {len(company_list)-3}ê°œ")

        # ë¶„ì„ ê¸°ê°„ ì„¤ì •
        analysis_period = st.select_slider(
            "ë¶„ì„ ê¸°ê°„",
            ["1ì£¼ì¼", "2ì£¼ì¼", "1ê°œì›”", "3ê°œì›”", "6ê°œì›”"],
            value="1ê°œì›”",
            key=wkey("period", "theme_report")
        )

    else:  # ê°œë³„ ì¢…ëª© ë¶„ì„
        st.subheader("ğŸ¢ ê°œë³„ ì¢…ëª© ë¶„ì„ ì„¤ì •")

        # ì§ì ‘ ì…ë ¥ ë˜ëŠ” í…Œë§ˆì—ì„œ ì„ íƒ
        input_method = st.radio(
            "ì¢…ëª© ì„ íƒ ë°©ë²•",
            ["ğŸ“ ì§ì ‘ ì…ë ¥", "ğŸ“‹ í…Œë§ˆë³„ ì„ íƒ"],
            horizontal=True,
            key=wkey("input_method", "report")
        )

        if input_method == "ğŸ“ ì§ì ‘ ì…ë ¥":
            col1, col2 = st.columns([2, 1])
            with col1:
                company_input = st.text_input(
                    "íšŒì‚¬ëª… ë˜ëŠ” ì¢…ëª©ì½”ë“œ",
                    placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, 005930, LGì—ë„ˆì§€ì†”ë£¨ì…˜",
                    key=wkey("company_input", "report")
                )
            with col2:
                analysis_period = st.selectbox(
                    "ë¶„ì„ ê¸°ê°„",
                    ["1ì£¼ì¼", "2ì£¼ì¼", "1ê°œì›”", "3ê°œì›”", "6ê°œì›”"],
                    index=2,
                    key=wkey("period", "individual_report")
                )
        else:
            col1, col2 = st.columns([1, 1])
            with col1:
                theme_for_company = st.selectbox(
                    "í…Œë§ˆ ì„ íƒ",
                    list(THEME_SECTORS.keys()),
                    key=wkey("theme_for_company", "report")
                )
            with col2:
                companies_in_theme = THEME_SECTORS[theme_for_company]["companies"]
                selected_company = st.selectbox(
                    "ì¢…ëª© ì„ íƒ",
                    [f"{comp['name']} ({comp['code']})" for comp in companies_in_theme],
                    key=wkey("company_from_theme", "report")
                )

    st.divider()

    # ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •
    st.subheader("âš™ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì„¤ì •")

    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        include_news = st.checkbox("ğŸ“° ìµœì‹  ë‰´ìŠ¤ ë¶„ì„", value=True, key=wkey("include_news", "report"))
    with col2:
        include_ontology = st.checkbox("ğŸ•¸ï¸ ì˜¨í†¨ë¡œì§€ ê·¸ë˜í”„", value=True, key=wkey("include_ontology", "report"))
    with col3:
        include_financial = st.checkbox("ğŸ’° ì¬ë¬´ ì •ë³´", value=True, key=wkey("include_financial", "report"))

    # ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼
    st.markdown("---")
    generate_report = st.button(
        "ğŸš€ ì „ë§ ë¦¬í¬íŠ¸ ìƒì„±",
        type="primary",
        key=wkey("generate_report", "report"),
        help="ì„ íƒëœ ì„¤ì •ì— ë”°ë¼ ì¢…í•© ì „ë§ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤"
    )

    # ë¦¬í¬íŠ¸ ìƒì„± ë¡œì§
    if generate_report:
        # ì¿¼ë¦¬ êµ¬ì„±
        if report_mode == "ğŸ¯ í…Œë§ˆë³„ ë¶„ì„":
            # í…Œë§ˆë³„ ë¶„ì„ìš© ì¿¼ë¦¬ ìƒì„±
            query_text = f"{selected_theme.replace('ğŸš€ ', '').replace('ğŸ”‹ ', '').replace('ğŸ’¾ ', '').replace('ğŸš— ', '').replace('ğŸ—ï¸ ', '')} ê´€ë ¨ ìµœì‹  ë™í–¥ ì „ë§"
            keywords = theme_data["keywords"]
            companies = [comp["name"] for comp in theme_data["companies"]]

            st.info(f"**ë¶„ì„ ëŒ€ìƒ**: {selected_theme} | **ê¸°ê°„**: {analysis_period} | **ì¢…ëª© ìˆ˜**: {len(companies)}ê°œ")

        else:
            # ê°œë³„ ì¢…ëª© ë¶„ì„ìš© ì¿¼ë¦¬ ìƒì„±
            if input_method == "ğŸ“ ì§ì ‘ ì…ë ¥":
                if not company_input:
                    st.warning("íšŒì‚¬ëª… ë˜ëŠ” ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    st.stop()
                query_text = f"{company_input} ìµœì‹  ë‰´ìŠ¤ ì „ë§ ë¶„ì„"
                keywords = [company_input]
                companies = [company_input]
            else:
                # í…Œë§ˆì—ì„œ ì„ íƒí•œ ì¢…ëª©
                company_name = selected_company.split(" (")[0]  # "ì‚¼ì„±ì „ì (005930)" -> "ì‚¼ì„±ì „ì"
                query_text = f"{company_name} ìµœì‹  ë‰´ìŠ¤ ì „ë§ ë¶„ì„"
                keywords = [company_name]
                companies = [company_name]

            st.info(f"**ë¶„ì„ ëŒ€ìƒ**: {companies[0]} | **ê¸°ê°„**: {analysis_period}")

        # ê¸°ê°„ì„ ì¼ìˆ˜ë¡œ ë³€í™˜
        period_days = {"1ì£¼ì¼": 7, "2ì£¼ì¼": 14, "1ê°œì›”": 30, "3ê°œì›”": 90, "6ê°œì›”": 180}
        lookback_days = period_days.get(analysis_period, 30)

        with st.spinner("ğŸ” ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘..."):
            try:
                # ìƒˆë¡œìš´ ì „ë§ ë¦¬í¬íŠ¸ API í˜¸ì¶œ
                report_data = call_forecast_report({
                    "query": query_text,
                    "keywords": keywords,
                    "companies": companies,
                    "lookback_days": lookback_days,
                    "include_news": include_news,
                    "include_ontology": include_ontology,
                    "include_financial": include_financial,
                    "report_mode": report_mode
                })

                # ë¦¬í¬íŠ¸ í‘œì‹œ
                st.success("âœ… ì „ë§ ë¦¬í¬íŠ¸ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ë¦¬í¬íŠ¸ í—¤ë”
                st.markdown(f"# ğŸ“Š {query_text}")
                st.markdown(f"**ìƒì„±ì¼ì‹œ**: {report_data.get('generated_at', 'ì•Œ ìˆ˜ ì—†ìŒ')} | **ë¶„ì„ ê¸°ê°„**: {analysis_period}")

                # ë¦¬í¬íŠ¸ ë‚´ìš© í‘œì‹œ
                if "executive_summary" in report_data:
                    st.markdown("## ğŸ¯ í•µì‹¬ ìš”ì•½")
                    st.markdown(report_data["executive_summary"])

                if "news_analysis" in report_data:
                    st.markdown("## ğŸ“° ë‰´ìŠ¤ ë¶„ì„")
                    st.markdown(report_data["news_analysis"])

                if "ontology_insights" in report_data:
                    st.markdown("## ğŸ•¸ï¸ ê´€ê³„ ë¶„ì„")
                    st.markdown(report_data["ontology_insights"])

                if "financial_outlook" in report_data:
                    st.markdown("## ğŸ’° ì¬ë¬´ ì „ë§")
                    st.markdown(report_data["financial_outlook"])

                if "conclusion" in report_data:
                    st.markdown("## ğŸ“ˆ íˆ¬ì ì „ë§")
                    st.markdown(report_data["conclusion"])

                # ì°¸ê³  ìë£Œ
                if "sources" in report_data and report_data["sources"]:
                    st.markdown("## ğŸ“‘ ì°¸ê³  ìë£Œ")
                    for i, source in enumerate(report_data["sources"][:5], 1):
                        st.markdown(f"{i}. [{source.get('title', 'ì œëª©ì—†ìŒ')}]({source.get('url', '#')}) - {source.get('date', '')}")

            except Exception as e:
                st.error(f"âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.info("ğŸ’¡ ëŒ€ì•ˆ: Enhanced Chat íƒ­ì—ì„œ ê°œë³„ ì§ˆì˜ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
