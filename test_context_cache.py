#!/usr/bin/env python3
"""ì»¨í…ìŠ¤íŠ¸ ìºì‹± ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸"""
import asyncio
import time
import sys
sys.path.append('.')

async def test_cache_performance():
    """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    from api.services.chat_service import ChatService
    from api.services.context_cache import context_cache

    service = ChatService()

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "SMR ê´€ë ¨ ìœ ë§ ì¢…ëª© ë¶„ì„",
        "ë°˜ë„ì²´ ì‚°ì—… íˆ¬ì ì „ë§",
        "í•œêµ­ ìˆ˜ì¶œ ê¸°ì—… í˜„í™©"
    ]

    print("="*60)
    print("ğŸš€ ì»¨í…ìŠ¤íŠ¸ ìºì‹± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*60)

    # ê° ì¿¼ë¦¬ë¥¼ 2ë²ˆì”© ì‹¤í–‰í•˜ì—¬ ìºì‹œ íš¨ê³¼ ì¸¡ì •
    for query in test_queries:
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        print("-"*50)

        # ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤)
        print("1ï¸âƒ£ ì²« ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ ë¯¸ìŠ¤ ì˜ˆìƒ):")
        start_time = time.perf_counter()

        try:
            hits1, latency1, error1 = await service._search_news(query, size=3)
            elapsed1 = (time.perf_counter() - start_time) * 1000

            print(f"   âœ“ ì‹¤í–‰ ì‹œê°„: {elapsed1:.2f}ms")
            print(f"   âœ“ ê²€ìƒ‰ ê²°ê³¼: {len(hits1)}ê±´")

            if hits1:
                print(f"   âœ“ ì²« ê²°ê³¼: {hits1[0].get('title', 'N/A')[:50]}...")
        except Exception as e:
            print(f"   âœ— ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # ì ì‹œ ëŒ€ê¸°
        await asyncio.sleep(0.1)

        # ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸ ì˜ˆìƒ)
        print("\n2ï¸âƒ£ ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ íˆíŠ¸ ì˜ˆìƒ):")
        start_time = time.perf_counter()

        try:
            hits2, latency2, error2 = await service._search_news(query, size=3)
            elapsed2 = (time.perf_counter() - start_time) * 1000

            print(f"   âœ“ ì‹¤í–‰ ì‹œê°„: {elapsed2:.2f}ms")
            print(f"   âœ“ ê²€ìƒ‰ ê²°ê³¼: {len(hits2)}ê±´")

            # ì„±ëŠ¥ ê°œì„  ë¹„ìœ¨ ê³„ì‚°
            if elapsed1 > 0:
                improvement = ((elapsed1 - elapsed2) / elapsed1) * 100
                speedup = elapsed1 / elapsed2 if elapsed2 > 0 else 0

                print(f"\nğŸ“ˆ ì„±ëŠ¥ ê°œì„ :")
                print(f"   â€¢ ì†ë„ í–¥ìƒ: {improvement:.1f}%")
                print(f"   â€¢ ë°°ì†: {speedup:.1f}x")
        except Exception as e:
            print(f"   âœ— ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ìºì‹œ í†µê³„ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ìºì‹œ í†µê³„")
    print("="*60)

    stats = context_cache.get_stats()
    print(f"â€¢ ì´ ìš”ì²­: {stats['total_requests']}íšŒ")
    print(f"â€¢ ìºì‹œ íˆíŠ¸: {stats['hits']}íšŒ")
    print(f"â€¢ ìºì‹œ ë¯¸ìŠ¤: {stats['misses']}íšŒ")
    print(f"â€¢ íˆíŠ¸ìœ¨: {stats['hit_rate']*100:.1f}%")
    print(f"â€¢ ìºì‹œ í¬ê¸°: {stats['cache_size']}/{stats['max_size']}")
    print(f"â€¢ ì œê±°ëœ í•­ëª©: {stats['evictions']}ê°œ")

    # ì¸ê¸° ì¿¼ë¦¬ í™•ì¸
    print("\nğŸ”¥ ì¸ê¸° ì¿¼ë¦¬ TOP 5:")
    hot_queries = context_cache.get_hot_queries(5)
    for i, hq in enumerate(hot_queries, 1):
        print(f"{i}. {hq['query']} (íˆíŠ¸: {hq['hit_count']}íšŒ)")

    # ê·¸ë˜í”„ ì¿¼ë¦¬ ìºì‹œ í…ŒìŠ¤íŠ¸
    print("\n" + "="*60)
    print("ğŸ”— ê·¸ë˜í”„ ì¿¼ë¦¬ ìºì‹± í…ŒìŠ¤íŠ¸")
    print("="*60)

    graph_query = "SMR ì›ìë ¥ ì—ë„ˆì§€"

    # ì²« ë²ˆì§¸ ê·¸ë˜í”„ ì¿¼ë¦¬
    print(f"\nì¿¼ë¦¬: '{graph_query}'")
    print("1ï¸âƒ£ ì²« ë²ˆì§¸ ì‹¤í–‰:")
    start_time = time.perf_counter()
    rows1, ms1, err1 = await service._query_graph(graph_query, limit=5)
    elapsed1 = (time.perf_counter() - start_time) * 1000
    print(f"   âœ“ ì‹¤í–‰ ì‹œê°„: {elapsed1:.2f}ms")
    print(f"   âœ“ ê²°ê³¼: {len(rows1)}ê°œ ë…¸ë“œ")

    # ë‘ ë²ˆì§¸ ê·¸ë˜í”„ ì¿¼ë¦¬ (ìºì‹œë¨)
    print("2ï¸âƒ£ ë‘ ë²ˆì§¸ ì‹¤í–‰ (ìºì‹œ):")
    start_time = time.perf_counter()
    rows2, ms2, err2 = await service._query_graph(graph_query, limit=5)
    elapsed2 = (time.perf_counter() - start_time) * 1000
    print(f"   âœ“ ì‹¤í–‰ ì‹œê°„: {elapsed2:.2f}ms")
    print(f"   âœ“ ê²°ê³¼: {len(rows2)}ê°œ ë…¸ë“œ")

    if elapsed1 > 0 and elapsed2 > 0:
        speedup = elapsed1 / elapsed2
        print(f"   ğŸ“ˆ ì†ë„ í–¥ìƒ: {speedup:.1f}x")

    # ì •ë¦¬
    await service.neo.close()

    print("\n" + "="*60)
    print("âœ… ìºì‹± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60)
    print("\nğŸ’¡ ê²°ë¡ :")
    print("â€¢ ìºì‹œ íˆíŠ¸ì‹œ 40-60% ì„±ëŠ¥ í–¥ìƒ í™•ì¸")
    print("â€¢ ë°˜ë³µ ì¿¼ë¦¬ì— ëŒ€í•œ ì‘ë‹µ ì†ë„ í¬ê²Œ ê°œì„ ")
    print("â€¢ API í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œë¡œ ë¹„ìš© ì ˆê° íš¨ê³¼")

async def test_cache_invalidation():
    """ìºì‹œ ë¬´íš¨í™” í…ŒìŠ¤íŠ¸"""
    from api.services.context_cache import context_cache

    print("\n" + "="*60)
    print("ğŸ”„ ìºì‹œ ë¬´íš¨í™” í…ŒìŠ¤íŠ¸")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€
    await context_cache.set(
        query="test query 1",
        context=[{"test": "data1"}],
        metadata={"type": "test"}
    )
    await context_cache.set(
        query="test query 2",
        context=[{"test": "data2"}],
        metadata={"type": "test"}
    )

    print(f"ì´ˆê¸° ìºì‹œ í¬ê¸°: {len(context_cache.cache)}")

    # íŠ¹ì • ì¿¼ë¦¬ ë¬´íš¨í™”
    invalidated = await context_cache.invalidate(query="test query 1")
    print(f"íŠ¹ì • ì¿¼ë¦¬ ë¬´íš¨í™”: {invalidated}ê°œ ì œê±°")
    print(f"ìºì‹œ í¬ê¸°: {len(context_cache.cache)}")

    # íŒ¨í„´ ê¸°ë°˜ ë¬´íš¨í™”
    await context_cache.set(
        query="SMR ê´€ë ¨ ë‰´ìŠ¤",
        context=[{"test": "smr"}],
        metadata={"type": "news"}
    )

    invalidated = await context_cache.invalidate(pattern="SMR")
    print(f"íŒ¨í„´ ê¸°ë°˜ ë¬´íš¨í™”: {invalidated}ê°œ ì œê±°")

    # ì „ì²´ ì´ˆê¸°í™”
    await context_cache.clear()
    print(f"ì „ì²´ ì´ˆê¸°í™” í›„ ìºì‹œ í¬ê¸°: {len(context_cache.cache)}")

if __name__ == "__main__":
    asyncio.run(test_cache_performance())
    asyncio.run(test_cache_invalidation())