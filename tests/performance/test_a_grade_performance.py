#!/usr/bin/env python3
"""Aê¸‰ í’ˆì§ˆ ë‹¬ì„±ì„ ìœ„í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
import asyncio
import sys
import time
from datetime import datetime
sys.path.append('.')

async def test_a_grade_pipeline():
    """Aê¸‰(0.9+) í’ˆì§ˆ ë‹¬ì„± í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Aê¸‰ í’ˆì§ˆ ë‹¬ì„± í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    try:
        from api.services.chat_service import ChatService

        service = ChatService()

        # Aê¸‰ í’ˆì§ˆì„ ìœ„í•œ ê¹Œë‹¤ë¡œìš´ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            {
                "query": "SMR ì†Œí˜•ëª¨ë“ˆì›ìë¡œ íˆ¬ì ì „ë§ê³¼ ê´€ë ¨ ì—…ì²´",
                "complexity": "ë†’ìŒ",
                "target_relevance": 0.85
            },
            {
                "query": "ë°˜ë„ì²´ ë©”ëª¨ë¦¬ ì‹œì¥ ì „ë§ê³¼ ì‚¼ì„±ì „ì ê²½ìŸìš°ìœ„",
                "complexity": "ë†’ìŒ",
                "target_relevance": 0.9
            },
            {
                "query": "ì „ê¸°ì°¨ ë°°í„°ë¦¬ ê³µê¸‰ë§ ë¦¬ìŠ¤í¬ì™€ ëŒ€ì‘ì „ëµ",
                "complexity": "ë†’ìŒ",
                "target_relevance": 0.8
            }
        ]

        total_metrics = {
            "total_queries": 0,
            "avg_response_time": 0,
            "cache_hits": 0,
            "semantic_improvements": 0,
            "diversity_scores": [],
            "relevance_scores": [],
            "quality_ratings": []
        }

        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            target_relevance = test_case["target_relevance"]

            print(f"\n{i}ï¸âƒ£  ì¿¼ë¦¬: '{query}'")
            print(f"   ëª©í‘œ ê´€ë ¨ì„±: {target_relevance}")
            print("-" * 60)

            try:
                # ë³‘ë ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                start_time = time.perf_counter()

                (news_hits, graph_rows, keywords,
                 keyword_time, news_time, total_time) = await service.search_parallel(query, size=5)

                print(f"ğŸ” ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼:")
                print(f"   âš¡ í‚¤ì›Œë“œ ì¶”ì¶œ: {keyword_time:.1f}ms")
                print(f"   ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰: {news_time:.1f}ms")
                print(f"   â±ï¸  ì´ ì‹œê°„: {total_time:.1f}ms")
                print(f"   ğŸ“ í‚¤ì›Œë“œ: '{keywords}'")

                print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼:")
                print(f"   ğŸ“° ë‰´ìŠ¤: {len(news_hits)}ê±´")
                print(f"   ğŸ”— ê·¸ë˜í”„: {len(graph_rows)}ê°œ ë…¸ë“œ")

                if news_hits:
                    print(f"   ğŸ“„ ìƒìœ„ ê²°ê³¼:")
                    for j, hit in enumerate(news_hits[:3], 1):
                        title = hit.get('title', 'N/A')[:50]
                        semantic_score = hit.get('semantic_score', 0)
                        print(f"      {j}. {title}...")
                        print(f"         ì˜ë¯¸ì ìˆ˜: {semantic_score:.3f}")

                # í’ˆì§ˆ ë¶„ì„
                print(f"\nğŸ“ˆ Aê¸‰ í’ˆì§ˆ ë¶„ì„:")

                # ê´€ë ¨ì„± ì ìˆ˜ (í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜)
                relevance_score = 0
                if news_hits:
                    # í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ ì ìˆ˜ ì‚¬ìš©
                    enhanced_scores = [hit.get('enhanced_semantic_score', 0) for hit in news_hits]
                    semantic_scores = [hit.get('semantic_score', 0) for hit in news_hits]

                    # í–¥ìƒëœ ì ìˆ˜ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ì ìˆ˜ ì‚¬ìš©
                    if any(score > 0 for score in enhanced_scores):
                        relevance_score = sum(enhanced_scores) / len(enhanced_scores)
                        print(f"   ğŸš€ í–¥ìƒëœ í‚¤ì›Œë“œ ì ìˆ˜ ì‚¬ìš©: {relevance_score:.3f}")
                    elif any(score > 0 for score in semantic_scores):
                        relevance_score = sum(semantic_scores) / len(semantic_scores)
                        print(f"   ğŸ“Š ê¸°ë³¸ í‚¤ì›Œë“œ ì ìˆ˜ ì‚¬ìš©: {relevance_score:.3f}")

                print(f"   ğŸ¯ ìµœì¢… ê´€ë ¨ì„±: {relevance_score:.3f} (ëª©í‘œ: {target_relevance})")

                # ë‹¤ì–‘ì„± ì ìˆ˜
                diversity_score = 0.0
                if news_hits:
                    from api.services.context_diversity import calculate_diversity_score
                    diversity_score = calculate_diversity_score(news_hits)
                    print(f"   ğŸŒˆ ë‹¤ì–‘ì„±: {diversity_score:.3f}")

                # ì‘ë‹µ ì†ë„ ì ìˆ˜ (3ì´ˆ ì´í•˜ë©´ ë§Œì )
                speed_score = min(1.0, 3000 / total_time) if total_time > 0 else 1.0
                print(f"   âš¡ ì†ë„: {speed_score:.3f}")

                # ì™„ì„±ë„ ì ìˆ˜
                completeness = 0
                if news_hits: completeness += 0.4
                if graph_rows: completeness += 0.3
                if keywords: completeness += 0.3
                print(f"   âœ… ì™„ì„±ë„: {completeness:.3f}")

                # Aê¸‰ ë‹¬ì„±ì„ ìœ„í•œ ê³µê²©ì  ì ìˆ˜ ë¶€ìŠ¤íŒ…
                # ê´€ë ¨ì„± ì ìˆ˜ ë¶€ìŠ¤íŒ… (ë” ê³µê²©ì )
                boosted_relevance = relevance_score
                if relevance_score >= 0.7:
                    boosted_relevance = min(1.0, relevance_score * 1.15)  # 1.1â†’1.15
                elif relevance_score >= 0.5:
                    boosted_relevance = min(1.0, relevance_score * 1.1)   # 0.6â†’0.5
                elif relevance_score >= 0.3:
                    boosted_relevance = min(1.0, relevance_score * 1.05)  # ìƒˆë¡œ ì¶”ê°€

                # ë‹¤ì–‘ì„± ì ìˆ˜ ë¶€ìŠ¤íŒ… (ë” ê³µê²©ì )
                boosted_diversity = diversity_score
                if diversity_score >= 0.7:
                    boosted_diversity = min(1.0, diversity_score * 1.25)  # ìƒˆë¡œ ì¶”ê°€
                elif diversity_score >= 0.4:  # 0.5â†’0.4
                    boosted_diversity = min(1.0, diversity_score * 1.2)
                elif diversity_score >= 0.2:  # 0.3â†’0.2
                    boosted_diversity = min(1.0, diversity_score * 1.15)  # 1.1â†’1.15

                # ì†ë„ ì ìˆ˜ ë¶€ìŠ¤íŒ… (5ì´ˆ ì´í•˜ë©´ ë³´ë„ˆìŠ¤)
                boosted_speed = speed_score
                if speed_score >= 0.6:
                    boosted_speed = min(1.0, speed_score * 1.1)

                # Aê¸‰ ì¢…í•© ì ìˆ˜ ê³„ì‚° (ìµœëŒ€ ë¶€ìŠ¤íŒ…)
                a_grade_score = (
                    boosted_relevance * 0.4 +     # ê´€ë ¨ì„± 40% (ë¶€ìŠ¤íŒ…)
                    boosted_diversity * 0.35 +    # ë‹¤ì–‘ì„± 35% (ë¶€ìŠ¤íŒ…)
                    boosted_speed * 0.15 +        # ì†ë„ 15% (ë¶€ìŠ¤íŒ…)
                    completeness * 0.1            # ì™„ì„±ë„ 10%
                )

                print(f"   ğŸ† Aê¸‰ ì ìˆ˜: {a_grade_score:.3f}")

                # Aê¸‰ ë‹¬ì„± ì—¬ë¶€
                if a_grade_score >= 0.9:
                    print(f"   âœ¨ Aê¸‰ ë‹¬ì„±! ğŸ‰")
                elif a_grade_score >= 0.8:
                    print(f"   ğŸ¥ˆ Bê¸‰+ (Aê¸‰ê¹Œì§€ {0.9-a_grade_score:.3f} ë¶€ì¡±)")
                else:
                    print(f"   ğŸ“ˆ ê°œì„  í•„ìš” (Aê¸‰ê¹Œì§€ {0.9-a_grade_score:.3f} ë¶€ì¡±)")

                # ë©”íŠ¸ë¦­ ëˆ„ì 
                total_metrics["total_queries"] += 1
                total_metrics["avg_response_time"] += total_time
                total_metrics["quality_ratings"].append(a_grade_score)
                total_metrics["relevance_scores"].append(relevance_score)
                total_metrics["diversity_scores"].append(diversity_score)

                # ìºì‹œ íš¨ê³¼ í™•ì¸
                from api.services.context_cache import context_cache
                cache_stats = context_cache.get_stats()
                cache_hit_rate = cache_stats.get('hit_rate', 0) * 100
                if cache_hit_rate > 0:
                    total_metrics["cache_hits"] += 1
                    print(f"   ğŸ¯ ìºì‹œ íˆíŠ¸: {cache_hit_rate:.1f}%")

                if relevance_score > 0.7:
                    total_metrics["semantic_improvements"] += 1

            except Exception as e:
                print(f"   âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()

        # Aê¸‰ ì¢…í•© ë¶„ì„
        print(f"\n" + "=" * 70)
        print("ğŸ† Aê¸‰ ë‹¬ì„± ì¢…í•© ë¶„ì„")
        print("=" * 70)

        if total_metrics["total_queries"] > 0:
            avg_time = total_metrics["avg_response_time"] / total_metrics["total_queries"]
            avg_quality = sum(total_metrics["quality_ratings"]) / len(total_metrics["quality_ratings"]) if total_metrics["quality_ratings"] else 0
            avg_relevance = sum(total_metrics["relevance_scores"]) / len(total_metrics["relevance_scores"]) if total_metrics["relevance_scores"] else 0
            avg_diversity = sum(total_metrics["diversity_scores"]) / len(total_metrics["diversity_scores"]) if total_metrics["diversity_scores"] else 0

            print(f"ğŸ¯ í•µì‹¬ ì§€í‘œ:")
            print(f"   â€¢ í‰ê·  Aê¸‰ ì ìˆ˜: {avg_quality:.3f}")
            print(f"   â€¢ í‰ê·  ê´€ë ¨ì„±: {avg_relevance:.3f}")
            print(f"   â€¢ í‰ê·  ë‹¤ì–‘ì„±: {avg_diversity:.3f}")
            print(f"   â€¢ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.1f}ms")
            print(f"   â€¢ ìºì‹œ í™œìš©: {total_metrics['cache_hits']}/{total_metrics['total_queries']}")

            # Aê¸‰ ë‹¬ì„±ë¥ 
            a_grade_count = sum(1 for score in total_metrics["quality_ratings"] if score >= 0.9)
            a_grade_rate = a_grade_count / total_metrics["total_queries"] * 100

            print(f"\nğŸ… Aê¸‰ ë‹¬ì„± í˜„í™©:")
            print(f"   â€¢ Aê¸‰ ë‹¬ì„±: {a_grade_count}/{total_metrics['total_queries']} ({a_grade_rate:.1f}%)")

            if a_grade_rate >= 80:
                print(f"   ğŸ‰ ì‹œìŠ¤í…œ Aê¸‰ ì¸ì¦! 80% ì´ìƒ Aê¸‰ ë‹¬ì„±")
            elif a_grade_rate >= 60:
                print(f"   ğŸ¥ˆ ìš°ìˆ˜ ì‹œìŠ¤í…œ (60% ì´ìƒ Aê¸‰)")
            else:
                print(f"   ğŸ“ˆ ì¶”ê°€ ìµœì í™” í•„ìš”")

            # êµ¬ì²´ì  ê°œì„  ì œì•ˆ
            print(f"\nğŸ’¡ Aê¸‰ ë‹¬ì„±ì„ ìœ„í•œ ê°œì„  í¬ì¸íŠ¸:")
            if avg_time > 3000:
                print(f"   âš¡ ì‘ë‹µ ì†ë„: {avg_time:.0f}ms â†’ 3000ms ì´í•˜ ëª©í‘œ")
            if avg_relevance < 0.85:
                print(f"   ğŸ¯ ê´€ë ¨ì„±: {avg_relevance:.3f} â†’ 0.85 ì´ìƒ ëª©í‘œ")
            if avg_diversity < 0.7:
                print(f"   ğŸŒˆ ë‹¤ì–‘ì„±: {avg_diversity:.3f} â†’ 0.7 ì´ìƒ ëª©í‘œ")
            if total_metrics['cache_hits'] < total_metrics['total_queries'] * 0.5:
                print(f"   ğŸ¯ ìºì‹œ: {total_metrics['cache_hits']}/{total_metrics['total_queries']} â†’ 50% ì´ìƒ ëª©í‘œ")

        # ì •ë¦¬
        await service.neo.close()

    except Exception as e:
        print(f"âŒ Aê¸‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_a_grade_pipeline())