#!/usr/bin/env python3
"""ì»¨í…ìŠ¤íŠ¸ ë‹¤ì–‘ì„± ìµœì í™” í…ŒìŠ¤íŠ¸"""
import asyncio
import sys
import time
from datetime import datetime, timedelta
sys.path.append('.')

async def test_diversity_optimization():
    """ë‹¤ì–‘ì„± ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("ğŸŒˆ ì»¨í…ìŠ¤íŠ¸ ë‹¤ì–‘ì„± ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # ë‹¤ì–‘ì„± í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë¬¸ì„œ ì„¸íŠ¸
    test_documents = [
        # ë°˜ë„ì²´ ê´€ë ¨ (ê°™ì€ ì£¼ì œ)
        {
            "content": "ì‚¼ì„±ì „ìê°€ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê¸°ìˆ ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤.",
            "title": "ì‚¼ì„± ë©”ëª¨ë¦¬ ê¸°ìˆ  í˜ì‹ ",
            "source": "tech_news",
            "score": 0.95,
            "timestamp": "2024-01-15T10:00:00Z"
        },
        {
            "content": "SKí•˜ì´ë‹‰ìŠ¤ë„ ì°¨ì„¸ëŒ€ ë©”ëª¨ë¦¬ ì¹© ì–‘ì‚°ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.",
            "title": "SKí•˜ì´ë‹‰ìŠ¤ ë©”ëª¨ë¦¬ ì–‘ì‚°",
            "source": "business_daily",
            "score": 0.88,
            "timestamp": "2024-01-16T14:30:00Z"
        },
        {
            "content": "ì‚¼ì„±ì „ì ë©”ëª¨ë¦¬ ì‚¬ì—…ë¶€ ì‹¤ì ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "title": "ì‚¼ì„± ë©”ëª¨ë¦¬ ì‹¤ì  í˜¸ì¡°",
            "source": "tech_news",  # ê°™ì€ ì†ŒìŠ¤
            "score": 0.91,
            "timestamp": "2024-01-17T09:15:00Z"
        },
        # ìë™ì°¨ ê´€ë ¨ (ë‹¤ë¥¸ ì£¼ì œ)
        {
            "content": "í˜„ëŒ€ìë™ì°¨ê°€ ì „ê¸°ì°¨ ì‹ ëª¨ë¸ì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤.",
            "title": "í˜„ëŒ€ì°¨ ì „ê¸°ì°¨ ê³µê°œ",
            "source": "auto_news",
            "score": 0.82,
            "timestamp": "2024-02-01T16:20:00Z"
        },
        {
            "content": "ê¸°ì•„ì°¨ë„ ì „ê¸°ì°¨ ë¼ì¸ì—…ì„ í™•ëŒ€í•œë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.",
            "title": "ê¸°ì•„ì°¨ ì „ê¸°ì°¨ í™•ëŒ€",
            "source": "auto_news",  # ê°™ì€ ì†ŒìŠ¤
            "score": 0.79,
            "timestamp": "2024-02-02T11:45:00Z"
        },
        # ì—ë„ˆì§€ ê´€ë ¨ (ë˜ ë‹¤ë¥¸ ì£¼ì œ)
        {
            "content": "í•œêµ­ì´ SMR ì›ìë¡œ ê¸°ìˆ  ê°œë°œì— íˆ¬ìë¥¼ ëŠ˜ë¦°ë‹¤.",
            "title": "SMR ê¸°ìˆ  íˆ¬ì í™•ëŒ€",
            "source": "energy_today",
            "score": 0.86,
            "timestamp": "2024-03-01T08:30:00Z"
        },
        # ë°”ì´ì˜¤ ê´€ë ¨
        {
            "content": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤ê°€ ìƒˆë¡œìš´ ì˜ì•½í’ˆ ìƒì‚° ê³„ì•½ì„ ì²´ê²°í–ˆìŠµë‹ˆë‹¤.",
            "title": "ì‚¼ì„±ë°”ì´ì˜¤ ê³„ì•½ ì²´ê²°",
            "source": "bio_weekly",
            "score": 0.84,
            "timestamp": "2024-03-15T13:10:00Z"
        },
        # ì¤‘ë³µë„ê°€ ë†’ì€ ë¬¸ì„œë“¤
        {
            "content": "ì‚¼ì„±ì „ì ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê¸°ìˆ ì´ í•œì¸µ ë°œì „í–ˆìŠµë‹ˆë‹¤.",
            "title": "ì‚¼ì„± ë©”ëª¨ë¦¬ ê¸°ìˆ  ë°œì „",
            "source": "tech_news",
            "score": 0.89,
            "timestamp": "2024-01-15T11:00:00Z"  # ë¹„ìŠ·í•œ ì‹œê°„
        }
    ]

    try:
        from api.services.context_diversity import diversity_optimizer, optimize_context_diversity, calculate_diversity_score

        print(f"ğŸ“Š ì´ˆê¸° ë¬¸ì„œ ìˆ˜: {len(test_documents)}ê°œ")

        # 1. ì›ë³¸ ë‹¤ì–‘ì„± ì¸¡ì •
        print("\n1ï¸âƒ£ ì›ë³¸ ë¬¸ì„œ ì§‘í•© ë‹¤ì–‘ì„± ë¶„ì„")
        print("-" * 50)

        original_metrics = diversity_optimizer.calculate_diversity_metrics(test_documents)
        print(f"ğŸ“ˆ ì£¼ì œ ë‹¤ì–‘ì„±: {original_metrics.topic_diversity:.3f}")
        print(f"ğŸ“° ì†ŒìŠ¤ ë‹¤ì–‘ì„±: {original_metrics.source_diversity:.3f}")
        print(f"â° ì‹œê°„ì  ë‹¤ì–‘ì„±: {original_metrics.temporal_diversity:.3f}")
        print(f"ğŸ” ì»¨í…ì¸  ë…ì°½ì„±: {original_metrics.content_uniqueness:.3f}")
        print(f"ğŸ† ì „ì²´ ë‹¤ì–‘ì„± ì ìˆ˜: {original_metrics.overall_score:.3f}")

        # 2. ê· í˜•ì¡íŒ ë‹¤ì–‘ì„± ìµœì í™”
        target_sizes = [3, 5, 7]
        strategies = ["balanced", "topic_first", "temporal_first"]

        for target_size in target_sizes:
            if target_size >= len(test_documents):
                continue

            print(f"\n2ï¸âƒ£ ëª©í‘œ í¬ê¸°: {target_size}ê°œ ë¬¸ì„œ")
            print("-" * 50)

            for strategy in strategies:
                print(f"\nğŸ¯ {strategy} ì „ëµ:")

                start_time = time.perf_counter()
                optimized = optimize_context_diversity(
                    test_documents.copy(),
                    target_size,
                    strategy
                )
                elapsed = (time.perf_counter() - start_time) * 1000

                print(f"   â±ï¸  ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ms")
                print(f"   ğŸ“„ ì„ íƒëœ ë¬¸ì„œ: {len(optimized)}ê°œ")

                # ì„ íƒëœ ë¬¸ì„œë“¤ì˜ ë‹¤ì–‘ì„± ë¶„ì„
                metrics = diversity_optimizer.calculate_diversity_metrics(optimized)
                print(f"   ğŸ“Š ë‹¤ì–‘ì„± ì ìˆ˜: {metrics.overall_score:.3f}")

                print("   ğŸ“‹ ì„ íƒëœ ë¬¸ì„œ:")
                for i, doc in enumerate(optimized, 1):
                    source = doc.get('source', 'N/A')[:15]
                    title = doc.get('title', 'N/A')[:40]
                    print(f"      {i}. {title} ({source})")

        # 3. ì¤‘ë³µ ì œê±° íš¨ê³¼ í…ŒìŠ¤íŠ¸
        print(f"\n3ï¸âƒ£ ì¤‘ë³µ ì œê±° íš¨ê³¼")
        print("-" * 50)

        print("ì›ë³¸ ë¬¸ì„œ í•´ì‹œ:")
        for i, doc in enumerate(test_documents[:5], 1):
            content = doc.get("content", "")
            content_hash = diversity_optimizer._calculate_content_hash(content)
            print(f"   {i}. {content_hash} - {doc.get('title', 'N/A')}")

        # ì¤‘ë³µ ì œê±° ì „í›„ ë¹„êµ
        unique_docs = diversity_optimizer._remove_duplicates(test_documents)
        print(f"\nğŸ”„ ì¤‘ë³µ ì œê±°: {len(test_documents)}ê°œ â†’ {len(unique_docs)}ê°œ")
        print(f"ğŸ“‰ ì¤‘ë³µ ë¹„ìœ¨: {(1 - len(unique_docs)/len(test_documents))*100:.1f}%")

        # 4. ì£¼ì œë³„ ê·¸ë£¹í™” í…ŒìŠ¤íŠ¸
        print(f"\n4ï¸âƒ£ ì£¼ì œë³„ ê·¸ë£¹í™”")
        print("-" * 50)

        topic_groups = diversity_optimizer._group_by_topics(test_documents)
        for topic, docs in topic_groups.items():
            print(f"ğŸ“‚ {topic}: {len(docs)}ê°œ ë¬¸ì„œ")
            for doc in docs[:2]:  # ê° ì£¼ì œë³„ ìµœëŒ€ 2ê°œë§Œ í‘œì‹œ
                title = doc.get('title', 'N/A')[:30]
                print(f"   - {title}")

        # 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        print(f"\n5ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("-" * 50)

        # í° ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        large_dataset = test_documents * 10  # 80ê°œ ë¬¸ì„œ
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì¡°ê±´: {len(large_dataset)}ê°œ ë¬¸ì„œ")

        start_time = time.perf_counter()
        optimized_large = optimize_context_diversity(large_dataset, 10, "balanced")
        elapsed = (time.perf_counter() - start_time) * 1000

        print(f"âš¡ ëŒ€ìš©ëŸ‰ ìµœì í™”: {elapsed:.1f}ms")
        print(f"ğŸ“ˆ ì²˜ë¦¬ ì†ë„: {len(large_dataset)/elapsed*1000:.1f} docs/sec")

        final_diversity = calculate_diversity_score(optimized_large)
        print(f"ğŸ¯ ìµœì¢… ë‹¤ì–‘ì„± ì ìˆ˜: {final_diversity:.3f}")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

async def test_edge_cases():
    """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ§ª ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    from api.services.context_diversity import optimize_context_diversity

    # ë¹ˆ ë¦¬ìŠ¤íŠ¸
    print("1ï¸âƒ£ ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸:")
    result = optimize_context_diversity([], 5)
    print(f"   ê²°ê³¼: {len(result)}ê°œ")

    # ëª©í‘œë³´ë‹¤ ì ì€ ë¬¸ì„œ
    print("\n2ï¸âƒ£ ëª©í‘œë³´ë‹¤ ì ì€ ë¬¸ì„œ:")
    small_docs = [
        {"content": "í…ŒìŠ¤íŠ¸ 1", "title": "ë¬¸ì„œ 1", "source": "test"},
        {"content": "í…ŒìŠ¤íŠ¸ 2", "title": "ë¬¸ì„œ 2", "source": "test"}
    ]
    result = optimize_context_diversity(small_docs, 5)
    print(f"   ì…ë ¥: {len(small_docs)}ê°œ, ëª©í‘œ: 5ê°œ, ê²°ê³¼: {len(result)}ê°œ")

    # ëª¨ë“  ë¬¸ì„œê°€ ë™ì¼í•œ ì£¼ì œ
    print("\n3ï¸âƒ£ ë‹¨ì¼ ì£¼ì œ ë¬¸ì„œë“¤:")
    single_topic_docs = [
        {"content": f"ë°˜ë„ì²´ ê´€ë ¨ ë‰´ìŠ¤ {i}", "title": f"ë°˜ë„ì²´ {i}", "source": f"source_{i%2}"}
        for i in range(8)
    ]
    result = optimize_context_diversity(single_topic_docs, 4)
    print(f"   ê²°ê³¼: {len(result)}ê°œ (ì†ŒìŠ¤ë³„ë¡œ ë¶„ì‚°ë˜ì–´ì•¼ í•¨)")

    print("\nâœ… ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    asyncio.run(test_diversity_optimization())
    asyncio.run(test_edge_cases())