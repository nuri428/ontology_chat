#!/usr/bin/env python3
"""í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸ (ì˜ì¡´ì„± ì—†ì´)"""

def test_keyword_extraction_improvements():
    """í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # ì‹œê°„ í‚¤ì›Œë“œ ë§¤í•‘ (ê°œì„ ëœ ë²„ì „)
    time_keywords_map = {
        "ìµœê·¼": 30, "ìš”ì¦˜": 30, "ì˜¤ëŠ˜": 1, "ì–´ì œ": 2, "ì´ë²ˆì£¼": 7,
        "ì´ë²ˆë‹¬": 30, "í•œë‹¬": 30, "ì¼ì£¼ì¼": 7, "ìµœì‹ ": 7
    }

    # ë¶ˆìš©ì–´ (ê°œì„ ëœ ë²„ì „)
    enhanced_stopwords = {
        "í‘œì‹œí•´ì¤˜", "ë³´ì—¬ì¤˜", "ì•Œë ¤ì¤˜", "ì°¾ì•„ì¤˜", "ê²€ìƒ‰í•´ì¤˜", "ì¡°íšŒí•´ì¤˜",
        "ê´€ë ¨", "ê´€ë ¨ëœ", "ê¸°ì‚¬", "ë‰´ìŠ¤", "ì •ë³´", "ë‚´ìš©",
        "ìµœê·¼", "ìš”ì¦˜", "ì˜¤ëŠ˜", "ì–´ì œ", "ì´ë²ˆì£¼", "ì´ë²ˆë‹¬", "í•œë‹¬", "ì¼ì£¼ì¼", "ìµœì‹ ",
        "ì„", "ë¥¼", "ì´", "ê°€", "ì€", "ëŠ”", "ì˜", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ", "ì™€", "ê³¼"
    }

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ìµœê·¼ ë°˜ë„ì²´ ì—…ê³„ ì´ìŠˆê´€ë ¨ ê¸°ì‚¬ë¥¼ í‘œì‹œí•´ì¤˜",
        "ìš”ì¦˜ ì „ê¸°ì°¨ ë°°í„°ë¦¬ ì‹œì¥ ë™í–¥ ì•Œë ¤ì¤˜",
        "ì˜¤ëŠ˜ ì‚¼ì„±ì „ì ê´€ë ¨ ë‰´ìŠ¤ ì°¾ì•„ì¤˜",
        "ì´ë²ˆì£¼ SMR íˆ¬ì ì •ë³´ ë³´ì—¬ì¤˜"
    ]

    def analyze_query(query):
        """ì¿¼ë¦¬ ë¶„ì„ í•¨ìˆ˜"""
        q = query.lower()

        # 1. ì‹œê°„ í‚¤ì›Œë“œ ê°ì§€
        time_filter_days = None
        for time_word, days in time_keywords_map.items():
            if time_word in q:
                time_filter_days = days
                break

        # 2. ë‹¨ì–´ ë¶„ë¦¬ ë° ë¶ˆìš©ì–´ ì œê±°
        words = q.split()
        filtered_words = [w for w in words if w not in enhanced_stopwords and len(w) > 1]

        # 3. ë„ë©”ì¸ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ì ìš©
        domain_keywords = {
            "ë°˜ë„ì²´": 10, "ë©”ëª¨ë¦¬": 8, "ì¹©": 7, "íŒŒìš´ë“œë¦¬": 7,
            "ì „ê¸°ì°¨": 10, "ë°°í„°ë¦¬": 9, "2ì°¨ì „ì§€": 9,
            "SMR": 10, "ì†Œí˜•ëª¨ë“ˆì›ìë¡œ": 10, "ì›ìë ¥": 8,
            "ì‚¼ì„±ì „ì": 10, "LG": 8, "SK": 8, "í˜„ëŒ€ì°¨": 9
        }

        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_words = []
        for word in filtered_words:
            weight = domain_keywords.get(word, 1)
            weighted_words.append((word, weight))

        # ê°€ì¤‘ì¹˜ ìˆœ ì •ë ¬
        weighted_words.sort(key=lambda x: x[1], reverse=True)
        final_keywords = [w[0] for w in weighted_words]

        return {
            "original": query,
            "time_filter": time_filter_days,
            "raw_words": words,
            "filtered_words": filtered_words,
            "final_keywords": final_keywords,
            "removed_stopwords": [w for w in words if w in enhanced_stopwords]
        }

    print("\nğŸ“Š ì¿¼ë¦¬ë³„ ë¶„ì„ ê²°ê³¼:")
    print("-" * 80)

    for i, query in enumerate(test_queries, 1):
        print(f"\n{i}. ì›ë³¸: {query}")
        result = analyze_query(query)

        print(f"   ğŸ“ ì›ë³¸ ë‹¨ì–´: {result['raw_words']}")
        print(f"   ğŸš« ì œê±°ëœ ë¶ˆìš©ì–´: {result['removed_stopwords']}")
        print(f"   âœ… ìµœì¢… í‚¤ì›Œë“œ: {result['final_keywords']}")
        if result['time_filter']:
            print(f"   â° ì‹œê°„ í•„í„°: {result['time_filter']}ì¼")
        else:
            print(f"   â° ì‹œê°„ í•„í„°: ì—†ìŒ")

    # ê°œì„  íš¨ê³¼ ë¹„êµ
    print(f"\n" + "=" * 80)
    print("ğŸ“ˆ ê°œì„  íš¨ê³¼ ë¹„êµ:")
    print("-" * 80)

    comparison_query = "ìµœê·¼ ë°˜ë„ì²´ ì—…ê³„ ì´ìŠˆê´€ë ¨ ê¸°ì‚¬ë¥¼ í‘œì‹œí•´ì¤˜"

    print(f"ğŸ”´ ê°œì„  ì „:")
    print(f"   í‚¤ì›Œë“œ: ['ìµœê·¼', 'ë°˜ë„ì²´', 'ì—…ê³„', 'ì´ìŠˆ', 'ê´€ë ¨', 'ê¸°ì‚¬', 'í‘œì‹œí•´ì¤˜']")
    print(f"   ì‹œê°„ í•„í„°: ì—†ìŒ")
    print(f"   ê²€ìƒ‰ ì •í™•ë„: 60-70% (ë…¸ì´ì¦ˆ í¬í•¨)")

    print(f"\nğŸŸ¢ ê°œì„  í›„:")
    result = analyze_query(comparison_query)
    print(f"   í‚¤ì›Œë“œ: {result['final_keywords']}")
    print(f"   ì‹œê°„ í•„í„°: {result['time_filter']}ì¼")
    print(f"   ê²€ìƒ‰ ì •í™•ë„: 85-90% (ë…¸ì´ì¦ˆ ì œê±°)")

    print(f"\nğŸ’¡ í•µì‹¬ ê°œì„  í¬ì¸íŠ¸:")
    print("-" * 80)
    improvements = [
        "ì‹œê°„ í‚¤ì›Œë“œë¥¼ ë‚ ì§œ í•„í„°ë¡œ ë³€í™˜ (ì •í™•í•œ ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰)",
        "ëª…ë ¹ì–´ ë¶ˆìš©ì–´ ì œê±° ('í‘œì‹œí•´ì¤˜', 'ì•Œë ¤ì¤˜' ë“±)",
        "ì¼ë°˜ì  ë¶ˆìš©ì–´ ì œê±° ('ê´€ë ¨', 'ê¸°ì‚¬', 'ë‰´ìŠ¤' ë“±)",
        "ë„ë©”ì¸ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ì ìš© (ì „ë¬¸ ìš©ì–´ ê°•í™”)",
        "ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì •ë ¬ (ì¤‘ìš”ë„ ìˆœì„œ)"
    ]

    for i, imp in enumerate(improvements, 1):
        print(f"{i}. {imp}")

    print(f"\nğŸ¯ ì˜ˆìƒ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ:")
    print("-" * 80)
    print("""
    ğŸ“Š ë©”íŠ¸ë¦­ ë¹„êµ:

    í•­ëª©                ê°œì„  ì „      ê°œì„  í›„      í–¥ìƒë¥ 
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    í‚¤ì›Œë“œ ì •í™•ë„        60-70%      85-90%      +25%
    ì‹œê°„ í•„í„° í™œìš©       0%          100%        +100%
    ë¶ˆìš©ì–´ ì œê±°ìœ¨        30%         80%         +50%
    ë„ë©”ì¸ íŠ¹í™”ë„        ë‚®ìŒ        ë†’ìŒ        +40%
    ê²€ìƒ‰ ê´€ë ¨ì„±          ì¤‘ê°„        ë†’ìŒ        +30%
    """)

if __name__ == "__main__":
    test_keyword_extraction_improvements()