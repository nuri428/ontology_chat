#!/usr/bin/env python3
"""ì‹¤ì œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ë° ë¶„ì„"""
import asyncio
import sys
import json
import time
sys.path.append('.')

async def test_real_query():
    """ì‹¤ì œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  ê²°ê³¼ ë¶„ì„"""
    print("ğŸ”¬ ì‹¤ì œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ë° ê°œì„ ì  ë¶„ì„")
    print("=" * 80)

    try:
        from api.services.chat_service import ChatService

        service = ChatService()

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        query = "ìµœê·¼ ë°˜ë„ì²´ ì—…ê³„ ì´ìŠˆ ê´€ë ¨ ê¸°ì‚¬ë¥¼ í‘œì‹œí•´ì¤˜"

        print(f"ğŸ“ ì§ˆë¬¸: {query}")
        print("-" * 80)

        start_time = time.time()

        # ë‹µë³€ ìƒì„±
        result = await service.generate_answer(query)

        processing_time = (time.time() - start_time) * 1000

        # ê²°ê³¼ ë¶„ì„
        print("\nğŸ“Š ê²°ê³¼ ë¶„ì„:")
        print("=" * 80)

        # 1. ê¸°ë³¸ ë©”íŠ¸ë¦­
        print("\n1ï¸âƒ£ ê¸°ë³¸ ë©”íŠ¸ë¦­:")
        print(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ms")
        print(f"   - ì†ŒìŠ¤ ê°œìˆ˜: {len(result.get('sources', []))}ê°œ")
        print(f"   - ê·¸ë˜í”„ ë°ì´í„°: {len(result.get('graph_samples', []))}ê°œ")

        # 2. ë‹µë³€ êµ¬ì¡° ë¶„ì„
        answer = result.get("answer", "")
        print(f"\n2ï¸âƒ£ ë‹µë³€ êµ¬ì¡°:")
        print(f"   - ì „ì²´ ê¸¸ì´: {len(answer)}ì")
        print(f"   - LLM ì¸ì‚¬ì´íŠ¸ í¬í•¨: {'ğŸ’¡' in answer or 'ì¸ì‚¬ì´íŠ¸' in answer}")
        print(f"   - ì„¹ì…˜ êµ¬ë¶„: {'##' in answer}")
        print(f"   - ë‰´ìŠ¤ ì„¹ì…˜: {'ğŸ“°' in answer}")
        print(f"   - ê¸°ì—… ì •ë³´: {'ğŸ¢' in answer}")

        # 3. ì†ŒìŠ¤ í’ˆì§ˆ ë¶„ì„
        sources = result.get("sources", [])
        print(f"\n3ï¸âƒ£ ì†ŒìŠ¤ í’ˆì§ˆ:")
        if sources:
            # ì œëª© ë¶„ì„
            titles = [s.get("title", "") for s in sources]
            semiconductor_keywords = ["ë°˜ë„ì²´", "ì¹©", "ë©”ëª¨ë¦¬", "íŒŒìš´ë“œë¦¬", "TSMC", "ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"]
            relevant_count = sum(1 for title in titles if any(kw in title for kw in semiconductor_keywords))
            print(f"   - ê´€ë ¨ì„± ìˆëŠ” ê¸°ì‚¬: {relevant_count}/{len(sources)}ê°œ ({relevant_count/len(sources)*100:.1f}%)")

            # ë‚ ì§œ ë¶„ì„
            dates_available = sum(1 for s in sources if s.get("date"))
            print(f"   - ë‚ ì§œ ì •ë³´ ìˆìŒ: {dates_available}/{len(sources)}ê°œ")

            # ë¯¸ë””ì–´ ë‹¤ì–‘ì„±
            media_sources = set(s.get("media", "Unknown") for s in sources)
            print(f"   - ë¯¸ë””ì–´ ë‹¤ì–‘ì„±: {len(media_sources)}ê°œ ì†ŒìŠ¤")
            print(f"     {list(media_sources)[:5]}")

        # 4. ë©”íƒ€ë°ì´í„° ë¶„ì„
        meta = result.get("meta", {})
        print(f"\n4ï¸âƒ£ ì‹œìŠ¤í…œ ë©”íƒ€ë°ì´í„°:")
        print(f"   - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°: {meta.get('orchestrator', 'N/A')}")

        latency = meta.get("latency_ms", {})
        if latency:
            print(f"   - OpenSearch: {latency.get('opensearch', 0):.2f}ms")
            print(f"   - Neo4j: {latency.get('neo4j', 0):.2f}ms")
            print(f"   - Stock API: {latency.get('stock', 0):.2f}ms")

        errors = meta.get("errors", {})
        error_count = sum(1 for v in errors.values() if v)
        print(f"   - ì˜¤ë¥˜ ë°œìƒ: {error_count}ê°œ ì„œë¹„ìŠ¤")

        # 5. ë‹µë³€ ë‚´ìš© ìƒ˜í”Œ
        print(f"\n5ï¸âƒ£ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 800ì):")
        print("-" * 80)
        print(answer[:800] + "..." if len(answer) > 800 else answer)

        # 6. ê°œì„ ì  ë¶„ì„
        print("\n" + "=" * 80)
        print("ğŸ” ê°œì„ ì  ë¶„ì„:")
        print("-" * 80)

        improvements = []

        # ì²˜ë¦¬ ì‹œê°„ ì²´í¬
        if processing_time > 5000:
            improvements.append("âš ï¸ ì²˜ë¦¬ ì‹œê°„ì´ 5ì´ˆ ì´ìƒ - ìºì‹± ë˜ëŠ” ë³‘ë ¬ ì²˜ë¦¬ ê°œì„  í•„ìš”")
        elif processing_time > 3000:
            improvements.append("âš ï¸ ì²˜ë¦¬ ì‹œê°„ 3-5ì´ˆ - ìµœì í™” ì—¬ì§€ ìˆìŒ")
        else:
            improvements.append("âœ… ì²˜ë¦¬ ì‹œê°„ ì–‘í˜¸ (3ì´ˆ ì´ë‚´)")

        # ê´€ë ¨ì„± ì²´í¬
        if sources and relevant_count / len(sources) < 0.5:
            improvements.append("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± ë‚®ìŒ - í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„  í•„ìš”")
        elif sources and relevant_count / len(sources) < 0.8:
            improvements.append("âš ï¸ ì¼ë¶€ ë¹„ê´€ë ¨ ê²°ê³¼ í¬í•¨ - í•„í„°ë§ ê°•í™” í•„ìš”")
        else:
            improvements.append("âœ… ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± ë†’ìŒ")

        # LLM ì¸ì‚¬ì´íŠ¸ ì²´í¬
        if not ('ğŸ’¡' in answer or 'ì¸ì‚¬ì´íŠ¸' in answer):
            improvements.append("âš ï¸ LLM ì¸ì‚¬ì´íŠ¸ ë¯¸ìƒì„± - LLM ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”")
        else:
            improvements.append("âœ… LLM ì¸ì‚¬ì´íŠ¸ ìƒì„±ë¨")

        # ì†ŒìŠ¤ ë‹¤ì–‘ì„± ì²´í¬
        if sources and len(media_sources) < 2:
            improvements.append("âš ï¸ ë¯¸ë””ì–´ ì†ŒìŠ¤ ë‹¤ì–‘ì„± ë¶€ì¡±")
        else:
            improvements.append("âœ… ë‹¤ì–‘í•œ ë¯¸ë””ì–´ ì†ŒìŠ¤")

        # ë‹µë³€ êµ¬ì¡° ì²´í¬
        if len(answer) < 500:
            improvements.append("âš ï¸ ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŒ - ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡± ê°€ëŠ¥ì„±")
        elif len(answer) > 3000:
            improvements.append("âš ï¸ ë‹µë³€ì´ ë„ˆë¬´ ê¹€ - ìš”ì•½ í•„ìš”")
        else:
            improvements.append("âœ… ë‹µë³€ ê¸¸ì´ ì ì ˆ")

        # ì˜¤ë¥˜ ì²´í¬
        if error_count > 0:
            improvements.append(f"âš ï¸ {error_count}ê°œ ì„œë¹„ìŠ¤ ì˜¤ë¥˜ ë°œìƒ - ì•ˆì •ì„± ê°œì„  í•„ìš”")
        else:
            improvements.append("âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì •ìƒ ë™ì‘")

        # ê°œì„ ì  ì¶œë ¥
        for i, improvement in enumerate(improvements, 1):
            print(f"{i}. {improvement}")

        # 7. ê¶Œì¥ ì‚¬í•­
        print("\nğŸ“Œ ê¶Œì¥ ê°œì„  ì‚¬í•­:")
        print("-" * 80)

        recommendations = []

        if processing_time > 3000:
            recommendations.append("1. ì‘ë‹µ ì†ë„ ê°œì„ :")
            recommendations.append("   - ë” ê³µê²©ì ì¸ ìºì‹± ì „ëµ ì ìš©")
            recommendations.append("   - ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”")
            recommendations.append("   - LLM íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (10ì´ˆ â†’ 5ì´ˆ)")

        if sources and relevant_count / len(sources) < 0.8:
            recommendations.append("2. ê²€ìƒ‰ ê´€ë ¨ì„± ê°œì„ :")
            recommendations.append("   - í‚¤ì›Œë“œ í™•ì¥ ë¡œì§ ê°œì„ ")
            recommendations.append("   - ì˜ë¯¸ì  ìœ ì‚¬ë„ ì„ê³„ê°’ ì¡°ì •")
            recommendations.append("   - ë„ë©”ì¸ íŠ¹í™” í‚¤ì›Œë“œ ë§¤í•‘ ê°•í™”")

        if not ('ğŸ’¡' in answer or 'ì¸ì‚¬ì´íŠ¸' in answer):
            recommendations.append("3. LLM ì¸ì‚¬ì´íŠ¸ ìƒì„±:")
            recommendations.append("   - Ollama ì—°ê²° ìƒíƒœ í™•ì¸")
            recommendations.append("   - í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„ ")
            recommendations.append("   - í´ë°± ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„")

        if len(answer) < 500 or len(answer) > 3000:
            recommendations.append("4. ë‹µë³€ í’ˆì§ˆ ê°œì„ :")
            recommendations.append("   - ì»¨í…ìŠ¤íŠ¸ í”„ë£¨ë‹ ì¡°ì •")
            recommendations.append("   - LLM í”„ë¡¬í”„íŠ¸ì— ê¸¸ì´ ì œí•œ ëª…ì‹œ")
            recommendations.append("   - ì¤‘ìš”ë„ ê¸°ë°˜ ì •ë³´ ì„ ë³„")

        for rec in recommendations:
            print(rec)

        # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        with open("query_analysis_result.json", "w", encoding="utf-8") as f:
            json.dump({
                "query": query,
                "processing_time_ms": processing_time,
                "sources_count": len(sources),
                "answer_length": len(answer),
                "improvements": improvements,
                "recommendations": recommendations,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }, f, ensure_ascii=False, indent=2)

        print("\nğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ query_analysis_result.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_real_query())