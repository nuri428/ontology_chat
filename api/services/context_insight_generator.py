"""
LLM ê¸°ë°˜ ë™ì  ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°
ì‚¬ìš©ì ì§ˆì˜ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ìë™ ìƒì„±
"""
import json
import asyncio
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from api.logging import setup_logging
logger = setup_logging()

try:
    from api.utils.llm_keyword_extractor_simple import SimpleLLMKeywordExtractor
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False

from api.logging import setup_logging
logger = setup_logging()

try:
    from api.services.cache_manager import cache_decorator
    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False

@dataclass
class ContextInsight:
    """ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ì •ë³´"""
    title: str
    content: str
    icon: str
    category: str
    confidence: float
    sources: List[str] = None

@dataclass
class InsightGenerationResult:
    """ì¸ì‚¬ì´íŠ¸ ìƒì„± ê²°ê³¼"""
    insights: List[ContextInsight]
    overall_context: str
    confidence: float
    reasoning: str

class ContextInsightGenerator:
    """LLM ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        if not LLM_AVAILABLE:
            logger.warning("LLMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ì—¬ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ë§Œ ì œê³µë©ë‹ˆë‹¤")
            self.llm_extractor = None
        else:
            self.llm_extractor = SimpleLLMKeywordExtractor()
    
    async def generate_insights(
        self, 
        query: str, 
        news_hits: List[Dict] = None,
        graph_summary: Dict = None,
        stock_info: Dict = None
    ) -> InsightGenerationResult:
        """ì§ˆì˜ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        # ìºì‹± ì ìš© (30ë¶„)
        if CACHE_AVAILABLE:
            from api.services.cache_manager import cache_manager
            
            # ìºì‹œ í‚¤ ìƒì„±ìš© ê°„ë‹¨í•œ í•´ì‹œ
            cache_key_data = f"{query}_{len(news_hits) if news_hits else 0}_{bool(graph_summary)}_{bool(stock_info)}"
            cached_result = cache_manager.get("insight_generation", cache_key_data)
            if cached_result:
                logger.debug("ì¸ì‚¬ì´íŠ¸ ìƒì„± ìºì‹œ íˆíŠ¸")
                return cached_result
        
        # ì‹¤ì œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        result = await self._generate_insights_impl(query, news_hits, graph_summary, stock_info)
        
        # ìºì‹œì— ì €ì¥ (30ë¶„)
        if CACHE_AVAILABLE and result.confidence > 0.3:
            cache_manager.set("insight_generation", result, ttl=1800.0, cache_key=cache_key_data)
        
        return result
    
    async def _generate_insights_impl(
        self, 
        query: str, 
        news_hits: List[Dict] = None,
        graph_summary: Dict = None,
        stock_info: Dict = None
    ) -> InsightGenerationResult:
        """ì§ˆì˜ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        if not self.llm_extractor:
            return self._fallback_insights(query, news_hits, graph_summary, stock_info)
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context_data = self._prepare_context_data(query, news_hits, graph_summary, stock_info)
            
            # LLMìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insights_result = await self._generate_llm_insights(query, context_data)
            
            if insights_result.confidence > 0.3:
                return insights_result
            else:
                logger.warning("LLM ì¸ì‚¬ì´íŠ¸ ì‹ ë¢°ë„ê°€ ë‚®ì•„ í´ë°± ì‚¬ìš©")
                return self._fallback_insights(query, news_hits, graph_summary, stock_info)
                
        except Exception as e:
            logger.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._fallback_insights(query, news_hits, graph_summary, stock_info)
    
    def _prepare_context_data(
        self, 
        query: str, 
        news_hits: List[Dict], 
        graph_summary: Dict, 
        stock_info: Dict
    ) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„"""
        context_parts = [f"ì‚¬ìš©ì ì§ˆì˜: {query}"]
        
        # ë‰´ìŠ¤ ìš”ì•½
        if news_hits:
            news_titles = [hit.get("title", "") for hit in news_hits[:5]]
            context_parts.append(f"ê´€ë ¨ ë‰´ìŠ¤: {', '.join(news_titles)}")
        
        # ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸
        if graph_summary:
            context_parts.append(f"ê´€ë ¨ ì—”í‹°í‹°: {graph_summary}")
        
        # ì£¼ì‹ ì •ë³´
        if stock_info:
            context_parts.append(f"ì£¼ì‹ ì •ë³´: {stock_info.get('symbol', '')} - {stock_info.get('price', '')}")
        
        return " | ".join(context_parts)
    
    async def _generate_llm_insights(self, query: str, context_data: str) -> InsightGenerationResult:
        """LLMì„ í™œìš©í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        insight_prompt = f"""You are a Korean business analyst. Generate business insights in JSON format only.

Query: "{query}"
Context: {context_data}

Generate insights about Korean business trends, focusing on defense industry, exports, and investments.

Return ONLY valid JSON (no explanations, no markdown):
{{"insights":[{{"title":"ë°©ì‚° ìˆ˜ì¶œ í™•ëŒ€","content":"K-ë°©ì‚° ìˆ˜ì¶œ ì¦ê°€ë¡œ ê´€ë ¨ ê¸°ì—…ë“¤ì˜ ì„±ì¥ì´ ì˜ˆìƒë©ë‹ˆë‹¤","icon":"ğŸš€","category":"market","confidence":0.8,"sources":["news"]}},{{"title":"ì •ë¶€ ì§€ì› ì •ì±…","content":"ë°©ì‚° ìˆ˜ì¶œ ì§€ì› ì •ì±…ì´ ì—…ê³„ ì„±ì¥ì„ ë’·ë°›ì¹¨í•©ë‹ˆë‹¤","icon":"ğŸ›ï¸","category":"policy","confidence":0.9,"sources":["policy"]}}],"overall_context":"ë°©ì‚°ì—…ê³„ ì„±ì¥ì„¸ ì§€ì†","confidence":0.85,"reasoning":"ë‰´ìŠ¤ì™€ ì‹œì¥ ë™í–¥ ë¶„ì„ ê²°ê³¼"}}"""

        try:
            # LLM í˜¸ì¶œ (ì§ì ‘ í˜¸ì¶œ)
            response = self.llm_extractor.llm.invoke(insight_prompt)
            
            # JSON íŒŒì‹±
            parsed_result = self._parse_insight_response(response)
            
            if parsed_result:
                return parsed_result
            else:
                raise Exception("JSON íŒŒì‹± ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"LLM ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def _parse_insight_response(self, response: str) -> Optional[InsightGenerationResult]:
        """LLM ì¸ì‚¬ì´íŠ¸ ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ
            json_str = self._extract_json_from_response(response)
            parsed = json.loads(json_str)
            
            # ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±
            insights = []
            for insight_data in parsed.get("insights", []):
                insight = ContextInsight(
                    title=insight_data.get("title", ""),
                    content=insight_data.get("content", ""),
                    icon=insight_data.get("icon", "ğŸ“Š"),
                    category=insight_data.get("category", "general"),
                    confidence=insight_data.get("confidence", 0.5),
                    sources=insight_data.get("sources", [])
                )
                insights.append(insight)
            
            return InsightGenerationResult(
                insights=insights,
                overall_context=parsed.get("overall_context", ""),
                confidence=parsed.get("confidence", 0.5),
                reasoning=parsed.get("reasoning", "")
            )
            
        except (json.JSONDecodeError, KeyError, TypeError) as e:
            logger.debug(f"ì¸ì‚¬ì´íŠ¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _extract_json_from_response(self, response: str) -> str:
        """ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ"""
        response = response.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in response:
            start = response.find("```json") + 7
            end = response.find("```", start)
            if end > start:
                return response[start:end].strip()
        
        if "```" in response:
            start = response.find("```") + 3
            end = response.find("```", start)
            if end > start:
                return response[start:end].strip()
        
        # JSON ê°ì²´ ì°¾ê¸°
        start = response.find("{")
        if start >= 0:
            brace_count = 0
            for i, char in enumerate(response[start:], start):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        return response[start:i+1]
        
        return response
    
    def _fallback_insights(
        self, 
        query: str, 
        news_hits: List[Dict], 
        graph_summary: Dict, 
        stock_info: Dict
    ) -> InsightGenerationResult:
        """ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ (LLM ì‹¤íŒ¨ ì‹œ í´ë°±)"""
        
        q_lower = query.lower()
        insights = []
        
        # ë„ë©”ì¸ë³„ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸
        if "ì§€ìƒë¬´ê¸°" in q_lower or "ë°©ì‚°" in q_lower:
            insights.append(ContextInsight(
                title="ë°©ì‚° ì‚°ì—… ì„±ì¥",
                content="K-ë°©ì‚° ìˆ˜ì¶œ ì¦ê°€ì™€ ì •ë¶€ ì§€ì› ì •ì±…ìœ¼ë¡œ êµ­ë‚´ ë°©ì‚°ì—…ê³„ê°€ ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                icon="ğŸ”«",
                category="defense",
                confidence=0.7
            ))
        
        if "ìˆ˜ì¶œ" in q_lower:
            insights.append(ContextInsight(
                title="í•´ì™¸ ì§„ì¶œ í™•ëŒ€",
                content="ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œê³¼ ìˆ˜ì¶œ ë‹¤ë³€í™”ë¥¼ í†µí•œ ì„±ì¥ ê¸°íšŒê°€ í™•ëŒ€ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
                icon="ğŸŒ",
                category="export",
                confidence=0.6
            ))
        
        if "ì¢…ëª©" in q_lower or "ì£¼ì‹" in q_lower:
            insights.append(ContextInsight(
                title="íˆ¬ì ê¸°íšŒ ë¶„ì„",
                content="ê´€ë ¨ ê¸°ì—…ë“¤ì˜ ì‹¤ì  ê°œì„ ê³¼ ì‹œì¥ ì „ë§ì„ í†µí•œ íˆ¬ì ê°€ì¹˜ë¥¼ ê²€í† í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                icon="ğŸ“ˆ",
                category="investment",
                confidence=0.6
            ))
        
        if "ìµœê·¼" in q_lower or "ìµœì‹ " in q_lower:
            insights.append(ContextInsight(
                title="ìµœì‹  ë™í–¥",
                content="2024-2025ë…„ ìµœì‹  ì´ìŠˆì™€ ì •ì±… ë³€í™”, ì‹œì¥ ë°˜ì‘ì„ ì£¼ëª©í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.",
                icon="â°",
                category="trend",
                confidence=0.5
            ))
        
        # ë‰´ìŠ¤ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        if news_hits and len(news_hits) >= 3:
            insights.append(ContextInsight(
                title="ì–¸ë¡  ê´€ì‹¬ë„",
                content=f"ê´€ë ¨ ë‰´ìŠ¤ {len(news_hits)}ê±´ì´ ë³´ë„ë˜ì–´ ë†’ì€ ì‹œì¥ ê´€ì‹¬ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.",
                icon="ğŸ“°",
                category="media",
                confidence=0.8
            ))
        
        return InsightGenerationResult(
            insights=insights[:4],  # ìµœëŒ€ 4ê°œ
            overall_context="ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì…ë‹ˆë‹¤.",
            confidence=0.4,
            reasoning="LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        )
    
    def format_insights_for_display(self, result: InsightGenerationResult) -> str:
        """ì¸ì‚¬ì´íŠ¸ë¥¼ ë””ìŠ¤í”Œë ˆì´ìš© ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not result.insights:
            return ""
        
        lines = ["### ğŸ” ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸\n"]
        
        for insight in result.insights:
            lines.append(f"- {insight.icon} **{insight.title}**: {insight.content}")
        
        if result.overall_context:
            lines.append(f"\n**ğŸ’¡ ì¢…í•© ë¶„ì„**: {result.overall_context}")
        
        lines.append("")
        return "\n".join(lines)

# ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤
insight_generator = ContextInsightGenerator()