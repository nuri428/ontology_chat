# src/ontology_chat/services/report_service.py
from __future__ import annotations

from collections import Counter
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

from api.adapters.mcp_neo4j import Neo4jMCP
from api.adapters.mcp_opensearch import OpenSearchMCP
from api.adapters.mcp_stock import StockMCP
from api.adapters.ollama_embedding import OllamaEmbeddingMCP
from api.config import settings
from api.logging import setup_logging
from api.services.cypher_builder import build_label_aware_search_cypher
from icecream import ic
logger = setup_logging()
# ========== ìœ í‹¸ ==========

def _safe_dt(s: Any) -> Optional[str]:
    """neo4j DateTime/str -> ISO8601 ë¬¸ìì—´ë¡œ ì •ê·œí™”."""
    try:
        # neo4j python ë“œë¼ì´ë²„ì˜ DateTime ê°ì²´ëŠ” str()ë¡œ ISO ë¹„ìŠ·í•˜ê²Œ ë‚˜ì˜´
        return str(s) if s else None
    except Exception:
        return None

def _fmt_ccy(v: Any, ccy: str | None = None) -> str:
    try:
        fv = float(v)
        if fv >= 1_0000_0000:  # ì–µ ë‹¨ìœ„ í‘œì‹œ (KRW ê¸°ì¤€ ê°)
            return f"{fv/1_0000_0000:.1f}ì–µ" + (f" {ccy}" if ccy else "")
        if fv >= 1_0000:       # ë§Œ ë‹¨ìœ„
            return f"{fv/1_0000:.1f}ë§Œ" + (f" {ccy}" if ccy else "")
        return f"{fv:,.0f}" + (f" {ccy}" if ccy else "")
    except Exception:
        return str(v)

def _flatten_news_hits(hits: List[Dict[str, Any]], limit: int = 10) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    for h in hits[:limit]:
        src = h.get("_source", {}) or {}
        meta = src.get("metadata") or {}
        out.append(
            {
                "id": h.get("_id"),
                "title": src.get("title") or meta.get("title") or "(no title)",
                "url": src.get("url") or meta.get("url"),
                "date": (
                    src.get("created_datetime")
                    or src.get("created_date")
                    or meta.get("created_datetime")
                    or meta.get("created_date")
                ),
                "score": h.get("_score"),
                "index": h.get("_index"),
            }
        )
    return out

# ========== ë°ì´í„° ì»¨í…Œì´ë„ˆ ==========

class ReportRequest(BaseModel):
    query: str = Field(..., description="ìì—°ì–´ ì§ˆì˜, ì˜ˆ: 'ê¸°ì—…ëª… ì œí’ˆ ìˆ˜ì£¼'")
    domain: Optional[str] = Field(None, description="ë„ë©”ì¸ ë³´ì¡° í‚¤ì›Œë“œ, ì˜ˆ: 'ì œí’ˆ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ í”Œë«í¼'")
    lookback_days: int = Field(180, ge=1, le=720)
    news_size: int = Field(20, ge=5, le=200)
    graph_limit: int = Field(50, ge=10, le=200)
    symbol: Optional[str] = Field(None, description="ì£¼ê°€ ì‹¬ë³¼(ì„ íƒ). ì˜ˆ: '005930.KS'")

class ReportResponse(BaseModel):
    markdown: str
    metrics: Dict[str, Any]
    meta: Dict[str, Any]
    
@dataclass
class ReportContext:
    query: str
    lookback_days: int
    domain: Optional[str]
    news_hits: List[Dict[str, Any]]
    graph_rows: List[Dict[str, Any]]
    stock: Optional[Dict[str, Any]]
    meta: Dict[str, Any]

# ========== í•µì‹¬ ì„œë¹„ìŠ¤ ==========

class ReportService:
    """
    - ES, Neo4j, Stockì—ì„œ ë°ì´í„°ë¥¼ ëŒì–´ì™€ ê°„ë‹¨í•œ ì§€í‘œë¥¼ ë§Œë“¤ê³ 
    - Markdown ë³´ê³ ì„œ(í…ìŠ¤íŠ¸)ë¡œ ì¡°ë¦½
    """
    def __init__(self):
        self.os = OpenSearchMCP()
        self.neo = Neo4jMCP()
        self.st = StockMCP()
        self.embedding = OllamaEmbeddingMCP() if settings.enable_hybrid_search else None

    def _extract_keywords(self, query: str, domain: Optional[str] = None) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re

        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ê´€ë ¨', 'ì—ì„œëŠ”', '?', '!'}

        # ì¿¼ë¦¬ ì •ì œ
        query_words = re.findall(r'\b\w+\b', query.lower())
        keywords = [word for word in query_words if word not in stop_words and len(word) >= 2]

        # ë„ë©”ì¸ í‚¤ì›Œë“œ ì¶”ê°€
        if domain:
            domain_words = re.findall(r'\b\w+\b', domain.lower())
            domain_keywords = [word for word in domain_words if word not in stop_words and len(word) >= 2]
            keywords.extend(domain_keywords)

        # ì¤‘ìš”ë„ ìˆœì„œ ì •ë ¬ (ê¸¸ì´ ê¸°ì¤€)
        keywords = sorted(set(keywords), key=len, reverse=True)

        return keywords[:10]  # ìƒìœ„ 10ê°œë§Œ

    async def _vector_search(self, index: str, query_vector: List[float], size: int = 10) -> List[Dict[str, Any]]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (news_article_embedding ì¸ë±ìŠ¤)"""
        vector_query = {
            "size": size,
            "query": {
                "knn": {
                    "vector_field": {
                        "vector": query_vector,
                        "k": size
                    }
                }
            },
            "_source": {
                "includes": ["title", "url", "created_date", "created_datetime", "text", "metadata"]
            }
        }

        try:
            vector_res = await self.os.search(index=index, query=vector_query, size=size)
            hits = vector_res.get("hits", {}).get("hits", [])
            logger.debug(f"[ReportService] Vector search returned {len(hits)} results")
            return hits
        except Exception as e:
            logger.warning(f"[ReportService] Vector search failed: {e}")
            return []

    async def _keyword_search(self, index: str, query: str, size: int = 10) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)"""
        keyword_query = {
            "query": {
                "multi_match": {
                    "query": query,
                    "fields": ["title^3", "text^2", "content^1.5"],
                    "type": "best_fields"
                }
            },
            "_source": {
                "includes": ["title", "url", "created_date", "created_datetime", "text", "content"]
            }
        }

        try:
            keyword_res = await self.os.search(index=index, query=keyword_query, size=size)
            return keyword_res.get("hits", {}).get("hits", [])
        except Exception as e:
            logger.warning(f"[ReportService] Keyword search failed: {e}")
            return []

    def _merge_rrf(self, keyword_results: List[Dict[str, Any]], vector_results: List[Dict[str, Any]], k: int = 60) -> List[Dict[str, Any]]:
        """Reciprocal Rank Fusionìœ¼ë¡œ í‚¤ì›Œë“œ/ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ê²°í•©"""

        # ë¬¸ì„œë³„ ì ìˆ˜ ê³„ì‚°
        doc_scores = {}

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.6)
        for rank, hit in enumerate(keyword_results):
            doc_id = hit.get("_id")
            if doc_id:
                rrf_score = 0.6 / (k + rank + 1)
                doc_scores[doc_id] = doc_scores.get(doc_id, 0) + rrf_score
                if doc_id not in [h.get("_id") for h in doc_scores.get("docs", [])]:
                    doc_scores.setdefault("docs", []).append(hit)

        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜ (ê°€ì¤‘ì¹˜ 0.4)
        for rank, hit in enumerate(vector_results):
            doc_id = hit.get("_id")
            if doc_id:
                rrf_score = 0.4 / (k + rank + 1)
                doc_scores[doc_id] = doc_scores.get(doc_id, 0) + rrf_score
                if doc_id not in [h.get("_id") for h in doc_scores.get("docs", [])]:
                    doc_scores.setdefault("docs", []).append(hit)

        # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        merged_docs = doc_scores.get("docs", [])
        for doc in merged_docs:
            doc_id = doc.get("_id")
            doc["_score"] = doc_scores.get(doc_id, 0)

        merged_docs.sort(key=lambda x: x.get("_score", 0), reverse=True)
        return merged_docs

    async def _hybrid_search(self, query: str, size: int = 20) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ ê²°í•©"""
        if not settings.enable_hybrid_search or not self.embedding:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¹„í™œì„±í™”ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰ë§Œ
            return await self._keyword_search(settings.news_bulk_index, query, size)

        try:
            # BGE-M3ë¡œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_vector = await self.embedding.encode(query)

            # ë³‘ë ¬ë¡œ í‚¤ì›Œë“œ/ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
            keyword_task = self._keyword_search(settings.news_embedding_index, query, size)
            vector_task = self._vector_search(settings.news_embedding_index, query_vector, size)

            keyword_results, vector_results = await keyword_task, await vector_task

            # RRFë¡œ ê²°í•©
            merged_results = self._merge_rrf(keyword_results, vector_results)

            logger.info(f"[ReportService] Hybrid search: keyword={len(keyword_results)}, vector={len(vector_results)}, merged={len(merged_results)}")
            return merged_results[:size]

        except Exception as e:
            logger.error(f"[ReportService] Hybrid search failed: {e}")
            # ì‹¤íŒ¨ì‹œ ê¸°ì¡´ í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ fallback
            return await self._keyword_search(settings.news_bulk_index, query, size)

    def _build_fallback_query(self, strategy: dict) -> dict:
        """Fallback ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        if strategy["strategy"] == "individual_keywords":
            return {
                "query": {
                    "bool": {
                        "should": [
                            {
                                "multi_match": {
                                    "query": keyword,
                                    "fields": ["title^4", "content^1.5", "text^2", "metadata.title^4"],
                                    "type": "best_fields",
                                    "boost": 3.0 - i * 0.5  # ì¤‘ìš”ë„ì— ë”°ë¼ ë¶€ìŠ¤íŠ¸ ì¡°ì •
                                }
                            }
                            for i, keyword in enumerate(strategy["keywords"])
                        ],
                        "minimum_should_match": 1
                    }
                },
                "sort": ["_score", {"created_datetime": {"order": "desc", "missing": "_last"}}],
                "_source": {"includes": ["title", "url", "created_date", "created_datetime", "content"]}
            }

        elif strategy["strategy"] == "fuzzy_match":
            return {
                "query": {
                    "multi_match": {
                        "query": strategy["query"],
                        "fields": ["title^3", "content", "text^1.5"],
                        "type": "best_fields",
                        "fuzziness": strategy.get("fuzziness", "AUTO"),
                        "prefix_length": 1,
                        "max_expansions": 50
                    }
                },
                "sort": ["_score", {"created_datetime": {"order": "desc", "missing": "_last"}}],
                "_source": {"includes": ["title", "url", "created_date", "created_datetime", "content"]}
            }

        elif strategy["strategy"] == "wildcard":
            return {
                "query": {
                    "bool": {
                        "should": [
                            {
                                "wildcard": {
                                    "title": {"value": f"*{keyword}*", "boost": 2.0}
                                }
                            }
                            for keyword in strategy["keywords"]
                        ] + [
                            {
                                "wildcard": {
                                    "content": {"value": f"*{keyword}*", "boost": 1.0}
                                }
                            }
                            for keyword in strategy["keywords"]
                        ],
                        "minimum_should_match": 1
                    }
                },
                "sort": ["_score", {"created_datetime": {"order": "desc", "missing": "_last"}}],
                "_source": {"includes": ["title", "url", "created_date", "created_datetime", "content"]}
            }

        # ê¸°ë³¸ ì¿¼ë¦¬ (fallbackì˜ fallback)
        return {
            "query": {"match_all": {}},
            "sort": [{"created_datetime": {"order": "desc", "missing": "_last"}}],
            "_source": {"includes": ["title", "url", "created_date", "created_datetime"]},
            "size": 10
        }

    async def fetch_context(
        self,
        query: str,
        *,
        news_size: int = 20,
        graph_limit: int = 50,
        lookback_days: int = 180,
        domain: Optional[str] = None,
        symbol: Optional[str] = None,
    ) -> ReportContext:
        # --- OpenSearch: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„°) ë˜ëŠ” ê¸°ì¡´ ê²€ìƒ‰ ---
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œë„
            news_hits = await self._hybrid_search(query, news_size)

            if news_hits:
                logger.info(f"[ReportService] Hybrid search successful: {len(news_hits)} results")
            else:
                logger.info("[ReportService] Hybrid search returned no results, trying fallback")
        except Exception as e:
            logger.warning(f"[ReportService] Hybrid search failed: {e}")
            news_hits = []
        # ê°œì„ ëœ Fallback: ë‹¨ê³„ë³„ ìœ ì—°ì„± ì¦ê°€
        if not news_hits:
            fallback_strategies = [
                # ì „ëµ 1: í‚¤ì›Œë“œë³„ ê°œë³„ ê²€ìƒ‰
                {
                    "strategy": "individual_keywords",
                    "keywords": query_keywords[:2],  # ìƒìœ„ 2ê°œ í‚¤ì›Œë“œë§Œ
                    "operator": "OR"
                },
                # ì „ëµ 2: ë§¤ìš° ìœ ì—°í•œ ë¶€ë¶„ ë§¤ì¹­
                {
                    "strategy": "fuzzy_match",
                    "query": query,
                    "fuzziness": "AUTO"
                },
                # ì „ëµ 3: ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰
                {
                    "strategy": "wildcard",
                    "keywords": [kw for kw in query_keywords if len(kw) >= 3][:3]
                }
            ]

            for strategy in fallback_strategies:
                try:
                    for fallback_index in ["news-*", "news_article_bulk", "news*"]:
                        try:
                            fallback_body = self._build_fallback_query(strategy)
                            news_res_fb = await self.os.search(index=fallback_index, query=fallback_body, size=news_size)
                            news_hits = news_res_fb.get("hits", {}).get("hits", [])
                            if news_hits:
                                logger.info(f"[ReportService] Fallback success with {strategy['strategy']} on {fallback_index}")
                                break
                        except Exception as fb_e:
                            logger.warning(f"[ReportService] Fallback {strategy['strategy']} on {fallback_index} failed: {fb_e}")
                            continue

                    if news_hits:  # ì„±ê³µí•˜ë©´ ì¤‘ë‹¨
                        break

                except Exception as e:
                    logger.warning(f"[ReportService] Fallback strategy {strategy['strategy']} failed: {e}")
                    continue

        # --- Neo4j (ê²€ìƒ‰ Cypher ìš°ì„ : íŒŒì¼/í™˜ê²½ì—ì„œ ë¡œë“œ â†’ ì—†ìœ¼ë©´ ë¼ë²¨ì–´ì›¨ì–´ ë¹Œë“œ) ---
        cypher = settings.resolve_search_cypher()
        ic(cypher)
        if not cypher:
            keys_map = settings.get_graph_search_keys()
            ic(keys_map)
            cypher = build_label_aware_search_cypher(keys_map)
        ic(cypher)
        params = {"q": query, "limit": graph_limit}
        # ì˜µì…˜ íŒŒë¼ë¯¸í„°(ì¡´ì¬í•´ë„ Cypherì—ì„œ ì•ˆ ì“°ë©´ ë¬´ì‹œë¨)
        params["lookback_days"] = lookback_days
        if domain:
            params["domain"] = domain

        graph_rows = await self.neo.query(cypher, params)

        # --- Stock ---
        stock_data = None
        if symbol:
            try:
                stock_data = await self.st.get_price(symbol)
            except Exception as e:
                logger.warning(f"[ReportService] Stock error: {e}")

        meta = {
            "indices": {
                "news_bulk_index": settings.news_bulk_index,
                "news_embedding_index": settings.news_embedding_index,
            },
            "database": settings.neo4j_database,
            "lookback_days": lookback_days,
            "domain": domain,
            "news_hits_count": len(news_hits),
            "hybrid_search_enabled": settings.enable_hybrid_search,
            "bge_m3_host": settings.bge_m3_host if settings.enable_hybrid_search else None,
        }
        return ReportContext(
            query=query,
            lookback_days=lookback_days,
            domain=domain,
            news_hits=news_hits,
            graph_rows=graph_rows,
            stock=stock_data,
            meta=meta,
        )

    # --------- ì§€í‘œ ê³„ì‚° ---------

    def compute_graph_metrics(self, rows: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        - ë¼ë²¨ ë¶„í¬
        - ê³„ì•½(Contract) í•©ê³„/ìƒìœ„ ìƒ˜í”Œ
        - ì—°ê²° ë‹¨ì„œ(Company/Program/Product ë“± ì´ë¦„ ìƒ˜í”Œ)
        """
        label_counter = Counter()
        contracts: List[Dict[str, Any]] = []
        companies: List[str] = []
        programs: List[str] = []
        products: List[str] = []
        events_sample: List[Dict[str, Any]] = []

        # ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆì— ë§ì¶˜ ë°ì´í„° ìˆ˜ì§‘
        companies: List[Dict[str, Any]] = []  # ìƒì¥ì‚¬ ì •ë³´ í™•ì¥
        products: List[str] = []  # ìƒˆë¡œ ì¶”ê°€
        financial_metrics: List[Dict[str, Any]] = []  # ìƒˆë¡œ ì¶”ê°€
        investments: List[Dict[str, Any]] = []  # ìƒˆë¡œ ì¶”ê°€

        for r in rows:
            labels = r.get("labels", []) or []
            label_counter.update(labels)
            n = r.get("n") or {}

            if "Contract" in labels:
                contracts.append({
                    "contractId": n.get("contractId"),
                    "amount": n.get("amount"),
                    "value_ccy": n.get("value_ccy"),
                    "award_date": n.get("award_date"),
                })

            if "Company" in labels:
                company_info = {
                    "name": n.get("name"),
                    "ticker": n.get("ticker"),
                    "market": n.get("market"),
                    "sector": n.get("sector"),
                    "market_cap": n.get("market_cap"),
                    "is_listed": n.get("is_listed", False),
                }
                if company_info["name"]:
                    companies.append(company_info)

            if "Program" in labels:
                name = n.get("label") or n.get("code")
                if name:
                    programs.append(name)

            if "Product" in labels:  # ìƒˆë¡œ ì¶”ê°€
                name = n.get("name")
                if name:
                    products.append(name)

            # Product ë˜ëŠ” WeaponSystem (í˜¸í™˜ì„± ìœ ì§€)
            if "Product" in labels or "WeaponSystem" in labels:
                name = n.get("label") or n.get("name") or n.get("productName")
                if name:
                    products.append(name)

            if "FinancialMetric" in labels:  # ìƒˆë¡œ ì¶”ê°€
                financial_metrics.append({
                    "metric_type": n.get("metric_type"),
                    "amount": n.get("amount"),
                    "currency": n.get("currency"),
                    "period": n.get("period"),
                    "year_over_year": n.get("year_over_year"),
                })

            if "Investment" in labels:  # ìƒˆë¡œ ì¶”ê°€
                investments.append({
                    "investment_type": n.get("investment_type"),
                    "amount": n.get("amount"),
                    "currency": n.get("currency"),
                    "stake_percentage": n.get("stake_percentage"),
                    "purpose": n.get("purpose"),
                })

            if "Event" in labels:
                events_sample.append({
                    "event_type": n.get("event_type"),
                    "title": n.get("title"),
                    "published_at": _safe_dt(n.get("published_at")),
                    "sentiment": n.get("sentiment"),
                    "confidence": n.get("confidence"),
                })

        # ê³„ì•½ í•©ê³„/ìƒìœ„
        total_amt = 0.0
        for c in contracts:
            try:
                if c.get("amount") is not None:
                    total_amt += float(c["amount"])
            except Exception:
                pass

        top_contracts = sorted(
            contracts, key=lambda x: (x.get("amount") or 0), reverse=True
        )[:5]

        # ì¬ë¬´ì§€í‘œ ë¶„ì„
        total_revenue = 0.0
        total_operating_profit = 0.0
        for fm in financial_metrics:
            try:
                amount = float(fm.get("amount", 0))
                if fm.get("metric_type") == "revenue":
                    total_revenue += amount
                elif fm.get("metric_type") == "operating_profit":
                    total_operating_profit += amount
            except Exception:
                pass

        # íˆ¬ì ë¶„ì„
        total_investment = 0.0
        for inv in investments:
            try:
                if inv.get("amount") is not None:
                    total_investment += float(inv["amount"])
            except Exception:
                pass

        # ìƒì¥ì‚¬ ë¶„ì„ (ìƒì¥ì‚¬ ìš°ì„  ì •ë ¬)
        listed_companies = [c for c in companies if c.get("is_listed")]
        unlisted_companies = [c for c in companies if not c.get("is_listed")]

        # ì‹œê°€ì´ì•¡ ê¸°ì¤€ ì •ë ¬
        listed_companies.sort(key=lambda x: x.get("market_cap", 0), reverse=True)

        # íšŒì‚¬ëª… ë¦¬ìŠ¤íŠ¸ (ìƒì¥ì‚¬ ìš°ì„ )
        company_names = ([c["name"] for c in listed_companies] +
                        [c["name"] for c in unlisted_companies])

        return {
            "label_distribution": label_counter.most_common(),
            "contract_total_amount": total_amt,
            "contract_top": top_contracts,
            "companies_top": [k for k, _ in Counter(company_names).most_common(8)],
            "listed_companies": listed_companies[:5],  # ìƒìœ„ 5ê°œ ìƒì¥ì‚¬
            "programs_top": [k for k, _ in Counter(programs).most_common(8)],
            "products_top": [k for k, _ in Counter(products).most_common(8)],
            "weapons_top": [k for k, _ in Counter(products).most_common(8)],  # í˜¸í™˜ì„± ìœ ì§€
            "products_top": [k for k, _ in Counter(products).most_common(8)],  # ìƒˆë¡œ ì¶”ê°€
            "events_sample": events_sample[:8],
            "financial_summary": {  # ìƒˆë¡œ ì¶”ê°€
                "total_revenue": total_revenue,
                "total_operating_profit": total_operating_profit,
                "revenue_companies": len([fm for fm in financial_metrics if fm.get("metric_type") == "revenue"]),
            },
            "investment_summary": {  # ìƒˆë¡œ ì¶”ê°€
                "total_amount": total_investment,
                "count": len(investments),
                "types": list(set([inv.get("investment_type") for inv in investments if inv.get("investment_type")])),
            },
        }

    def compute_news_metrics(self, hits: List[Dict[str, Any]]) -> Dict[str, Any]:
        items = _flatten_news_hits(hits, limit=10)
        return {
            "top_news": items,
            "count": len(hits),
        }

    def compute_stock_metrics(self, stock: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        if not stock:
            return {}
        return {
            "symbol": stock.get("symbol"),
            "price": stock.get("price"),
        }

    # --------- ë¦¬í¬íŠ¸ ìƒì„± (Markdown) ---------

    def generate_markdown(self, ctx: ReportContext) -> str:
        g = self.compute_graph_metrics(ctx.graph_rows)
        n = self.compute_news_metrics(ctx.news_hits)
        s = self.compute_stock_metrics(ctx.stock)

        lines: List[str] = []
        lines.append("# ğŸ“Š ìƒì¥ì‚¬ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        lines.append(f"**ì§ˆì˜**: `{ctx.query}`  \n"
                     f"**ë¶„ì„ ê¸°ê°„**: ìµœê·¼ {ctx.lookback_days}ì¼  "
                     f"{'(ë„ë©”ì¸: ' + ctx.domain + ')' if ctx.domain else ''}\n")
        lines.append("---")

        # Stock
        if s:
            lines.append("## ì£¼ê°€ ìŠ¤ëƒ…ìƒ·")
            lines.append(f"- `{s.get('symbol')}` í˜„ì¬ê°€(ê·¼ì‚¬): **{s.get('price')}**\n")

        # Graph metrics
        lines.append("## ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ ìš”ì•½")
        # ë¼ë²¨ ë¶„í¬
        if g["label_distribution"]:
            lines.append("**ë¼ë²¨ ë¶„í¬ Top-8**")
            lines.append("")
            for label, cnt in g["label_distribution"][:8]:
                lines.append(f"- `{label}`: {cnt}ê°œ")
            lines.append("")

        # ê³„ì•½ í•©ê³„ / ìƒìœ„
        lines.append("**ê³„ì•½(Contract) í•©ê³„/ìƒìœ„**")
        lines.append(f"- í•©ê³„(í‘œë©´ìƒ): **{_fmt_ccy(g['contract_total_amount'])}**")
        if g["contract_top"]:
            lines.append("- ìƒìœ„ ê³„ì•½:")
            for c in g["contract_top"]:
                amount_s = _fmt_ccy(c.get("amount"), c.get("value_ccy"))
                lines.append(f"  - `{c.get('contractId')}` Â· {amount_s} Â· {c.get('award_date')}")
        lines.append("")

        # ìƒì¥ì‚¬ ì •ë³´
        if g["listed_companies"]:
            lines.append("**ğŸ“ˆ ì£¼ìš” ìƒì¥ì‚¬**")
            for company in g["listed_companies"]:
                name = company["name"]
                ticker = f"({company['ticker']})" if company.get("ticker") else ""
                market = f"[{company['market']}]" if company.get("market") else ""
                market_cap = f" Â· ì‹œì´ {_fmt_ccy(company['market_cap'])}" if company.get("market_cap") else ""
                sector = f" Â· {company['sector']}" if company.get("sector") else ""
                lines.append(f"- {name} {ticker} {market}{market_cap}{sector}")
            lines.append("")

        # ì¬ë¬´ ì •ë³´
        financial = g["financial_summary"]
        if financial["total_revenue"] > 0 or financial["total_operating_profit"] > 0:
            lines.append("**ğŸ’° ì¬ë¬´ ì •ë³´**")
            if financial["total_revenue"] > 0:
                lines.append(f"- ì´ ë§¤ì¶œ: **{_fmt_ccy(financial['total_revenue'])}**")
            if financial["total_operating_profit"] > 0:
                lines.append(f"- ì´ ì˜ì—…ì´ìµ: **{_fmt_ccy(financial['total_operating_profit'])}**")
            if financial["revenue_companies"] > 0:
                lines.append(f"- ì‹¤ì  ë°œí‘œ ê¸°ì—…: {financial['revenue_companies']}ê°œì‚¬")
            lines.append("")

        # íˆ¬ì ì •ë³´
        investment = g["investment_summary"]
        if investment["total_amount"] > 0:
            lines.append("**ğŸ’¼ íˆ¬ì ì •ë³´**")
            lines.append(f"- ì´ íˆ¬ì ê·œëª¨: **{_fmt_ccy(investment['total_amount'])}**")
            lines.append(f"- íˆ¬ì ê±´ìˆ˜: {investment['count']}ê±´")
            if investment["types"]:
                types_str = ", ".join(investment["types"])
                lines.append(f"- íˆ¬ì ìœ í˜•: {types_str}")
            lines.append("")

        # ì—”í„°í‹° Top
        if g["companies_top"]:
            lines.append("**ğŸ¢ ì—°ê´€ íšŒì‚¬ Top**: " + ", ".join([f"`{x}`" for x in g["companies_top"]]))
        if g["products_top"]:  # ìƒˆë¡œ ì¶”ê°€
            lines.append("**ğŸ› ï¸ ê´€ë ¨ ì œí’ˆ Top**: " + ", ".join([f"`{x}`" for x in g["products_top"]]))
        if g["programs_top"]:
            lines.append("**ğŸ¯ ì—°ê´€ í”„ë¡œê·¸ë¨ Top**: " + ", ".join([f"`{x}`" for x in g["programs_top"]]))
        if g.get("products_top"):  # products_topì„ ìš°ì„  í™•ì¸
            lines.append("**ğŸ› ï¸ ê´€ë ¨ ì œí’ˆ/ì‹œìŠ¤í…œ Top**: " + ", ".join([f"`{x}`" for x in g["products_top"]]))
        elif g.get("weapons_top"):  # í˜¸í™˜ì„± ìœ ì§€
            lines.append("**ğŸ› ï¸ ê´€ë ¨ ì‹œìŠ¤í…œ Top**: " + ", ".join([f"`{x}`" for x in g["weapons_top"]]))
        lines.append("")

        # ì´ë²¤íŠ¸ ìƒ˜í”Œ
        if g["events_sample"]:
            lines.append("**ì´ë²¤íŠ¸ ìƒ˜í”Œ**")
            for e in g["events_sample"]:
                title = e.get("title") or "(ì œëª© ì—†ìŒ)"
                lines.append(f"- {e.get('event_type') or '?'} Â· {e.get('sentiment') or '-'} Â· {e.get('published_at') or '-'}")
                if title:
                    lines.append(f"  - {title}")
            lines.append("")

        # ë‰´ìŠ¤ Top
        lines.append("## ê´€ë ¨ ë‰´ìŠ¤ Top-10")
        if n["top_news"]:
            for i, item in enumerate(n["top_news"], 1):
                title = item.get("title") or "(ì œëª© ì—†ìŒ)"
                url = item.get("url") or ""
                date = item.get("date") or ""
                lines.append(f"{i}. [{title}]({url}) â€” {date}")
        else:
            lines.append("> ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        lines.append("")

        # ì‹œì‚¬ì (ì´ˆì•ˆ)
        lines.append("## ì‹œì‚¬ì  (ì´ˆì•ˆ)")
        insight_bullets = []
        if g["contract_total_amount"] > 0:
            insight_bullets.append("ìµœê·¼ ê¸°ê°„ ê³„ì•½ ê·œëª¨ê°€ ìœ ì˜ë¯¸í•¨ â†’ ì‹¤ì /ì£¼ê°€ ë°˜ì˜ ê°€ëŠ¥ì„± ê²€í† .")
        if g["companies_top"]:
            insight_bullets.append(f"í•µì‹¬ ì°¸ì—¬ì‚¬: {', '.join(g['companies_top'][:3])}")
        if g.get("products_top"):  # products_topì„ ìš°ì„  í™•ì¸
            insight_bullets.append(f"í•µì‹¬ ì œí’ˆ/ì‹œìŠ¤í…œ: {', '.join(g['products_top'][:3])}")
        elif g.get("weapons_top"):  # í˜¸í™˜ì„± ìœ ì§€
            insight_bullets.append(f"í•µì‹¬ ì‹œìŠ¤í…œ: {', '.join(g['weapons_top'][:3])}")
        if not insight_bullets:
            insight_bullets.append("ë°ì´í„°ê°€ ì œí•œì ì´ë¯€ë¡œ ê¸°ê°„/í‚¤ì›Œë“œë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ í™•ì¶© í•„ìš”.")
        for b in insight_bullets:
            lines.append(f"- {b}")

        lines.append("\n---\n*ì´ ë¦¬í¬íŠ¸ëŠ” Neo4j ê·¸ë˜í”„/ë‰´ìŠ¤ ì¸ë±ìŠ¤/ì£¼ê°€ ìŠ¤ëƒ…ìƒ·ì„ ê²°í•©í•˜ì—¬ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n")
        return "\n".join(lines)

    async def generate_report(
        self,
        query: str,
        *,
        domain: Optional[str] = None,
        lookback_days: int = 180,
        news_size: int = 20,
        graph_limit: int = 50,
        symbol: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        ìµœìƒìœ„ API:
        - ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ â†’ ì§€í‘œ ê³„ì‚° â†’ Markdown ì¡°ë¦½
        - ë°˜í™˜: {"markdown": ..., "ctx": ReportContext, "metrics": {...}}
        """
        ctx = await self.fetch_context(
            query=query,
            news_size=news_size,
            graph_limit=graph_limit,
            lookback_days=lookback_days,
            domain=domain,
            symbol=symbol,
        )
        md = self.generate_markdown(ctx)
        metrics = {
            "graph": self.compute_graph_metrics(ctx.graph_rows),
            "news": self.compute_news_metrics(ctx.news_hits),
            "stock": self.compute_stock_metrics(ctx.stock),
        }
        return {"markdown": md, "ctx": ctx, "metrics": metrics}

    # ========== ë¦¬í¬íŠ¸ ì „ìš© ê³ ê¸‰ ê¸°ëŠ¥ë“¤ ==========

    async def generate_comparative_report(
        self,
        queries: List[str],
        *,
        domain: Optional[str] = None,
        lookback_days: int = 180,
        news_size: int = 20,
        graph_limit: int = 50,
    ) -> Dict[str, Any]:
        """ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (ë¦¬í¬íŠ¸ë§Œì˜ ê³ ìœ  ê¸°ëŠ¥)"""

        comparisons = []
        all_contexts = []

        for query in queries:
            ctx = await self.fetch_context(
                query=query,
                news_size=news_size,
                graph_limit=graph_limit,
                lookback_days=lookback_days,
                domain=domain,
            )
            all_contexts.append(ctx)

            metrics = {
                "graph": self.compute_graph_metrics(ctx.graph_rows),
                "news": self.compute_news_metrics(ctx.news_hits),
            }

            comparisons.append({
                "query": query,
                "metrics": metrics,
                "contract_total": metrics["graph"]["contract_total_amount"],
                "news_count": metrics["news"]["count"],
                "top_companies": metrics["graph"]["companies_top"][:3],
            })

        # ë¹„êµ ë¶„ì„ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        md_lines = ["# ğŸ“Š ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸\n"]
        md_lines.append(f"**ë¶„ì„ ëŒ€ìƒ**: {len(queries)}ê°œ í•­ëª©")
        md_lines.append(f"**ê¸°ê°„**: ìµœê·¼ {lookback_days}ì¼\n")

        # ìš”ì•½ í…Œì´ë¸”
        md_lines.append("## ğŸ“ˆ í•µì‹¬ ì§€í‘œ ë¹„êµ")
        md_lines.append("| í•­ëª© | ê³„ì•½ ê·œëª¨ | ë‰´ìŠ¤ ê±´ìˆ˜ | ì£¼ìš” ê¸°ì—… |")
        md_lines.append("|------|-----------|-----------|-----------|")

        for comp in comparisons:
            companies_str = ", ".join(comp["top_companies"]) if comp["top_companies"] else "-"
            md_lines.append(f"| {comp['query']} | {_fmt_ccy(comp['contract_total'])} | {comp['news_count']}ê±´ | {companies_str} |")

        md_lines.append("\n## ğŸ“‹ ìƒì„¸ ë¶„ì„")

        # ê° í•­ëª©ë³„ ìƒì„¸ ë¶„ì„
        for i, (comp, ctx) in enumerate(zip(comparisons, all_contexts), 1):
            md_lines.append(f"### {i}. {comp['query']}")

            # í•µì‹¬ ì§€í‘œ
            graph_metrics = comp["metrics"]["graph"]
            md_lines.append(f"- **ê³„ì•½ ì´ì•¡**: {_fmt_ccy(comp['contract_total'])}")
            md_lines.append(f"- **ê´€ë ¨ ë‰´ìŠ¤**: {comp['news_count']}ê±´")
            md_lines.append(f"- **ê·¸ë˜í”„ ë…¸ë“œ**: {len(ctx.graph_rows)}ê°œ")

            if graph_metrics["label_distribution"]:
                top_labels = graph_metrics["label_distribution"][:3]
                label_str = ", ".join([f"{label}({count})" for label, count in top_labels])
                md_lines.append(f"- **ì£¼ìš” ìœ í˜•**: {label_str}")

            md_lines.append("")

        # ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­
        md_lines.append("## ğŸ’¡ ë¹„êµ ì¸ì‚¬ì´íŠ¸")

        # ê³„ì•½ ê·œëª¨ ìˆœìœ„
        sorted_by_contract = sorted(comparisons, key=lambda x: x["contract_total"], reverse=True)
        if sorted_by_contract[0]["contract_total"] > 0:
            md_lines.append(f"- **ê³„ì•½ ê·œëª¨ 1ìœ„**: `{sorted_by_contract[0]['query']}` ({_fmt_ccy(sorted_by_contract[0]['contract_total'])})")

        # ë‰´ìŠ¤ í™œë°œë„ ìˆœìœ„
        sorted_by_news = sorted(comparisons, key=lambda x: x["news_count"], reverse=True)
        md_lines.append(f"- **ë‰´ìŠ¤ í™œë°œë„ 1ìœ„**: `{sorted_by_news[0]['query']}` ({sorted_by_news[0]['news_count']}ê±´)")

        md_lines.append("\n---\n*ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ëŠ” ë¦¬í¬íŠ¸ ì „ìš© ê¸°ëŠ¥ì…ë‹ˆë‹¤.*")

        return {
            "markdown": "\n".join(md_lines),
            "comparisons": comparisons,
            "contexts": all_contexts,
            "type": "comparative"
        }

    async def generate_trend_analysis(
        self,
        query: str,
        *,
        domain: Optional[str] = None,
        periods: List[int] = [30, 90, 180],  # ê¸°ê°„ë³„ íŠ¸ë Œë“œ ë¶„ì„
    ) -> Dict[str, Any]:
        """ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""

        trend_data = []

        for period in periods:
            ctx = await self.fetch_context(
                query=query,
                lookback_days=period,
                news_size=50,
                graph_limit=100,
                domain=domain,
            )

            metrics = {
                "graph": self.compute_graph_metrics(ctx.graph_rows),
                "news": self.compute_news_metrics(ctx.news_hits),
            }

            trend_data.append({
                "period": period,
                "contract_total": metrics["graph"]["contract_total_amount"],
                "news_count": metrics["news"]["count"],
                "graph_nodes": len(ctx.graph_rows),
                "top_companies": metrics["graph"]["companies_top"][:5],
                "events_count": len(metrics["graph"]["events_sample"]),
            })

        # íŠ¸ë Œë“œ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        md_lines = ["# ğŸ“ˆ ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„\n"]
        md_lines.append(f"**ë¶„ì„ ëŒ€ìƒ**: `{query}`")
        md_lines.append(f"**ë¶„ì„ ê¸°ê°„**: {periods}ì¼ êµ¬ê°„ë³„ ë¹„êµ\n")

        # íŠ¸ë Œë“œ í…Œì´ë¸”
        md_lines.append("## ğŸ“Š ê¸°ê°„ë³„ ì¶”ì´")
        md_lines.append("| ê¸°ê°„ | ê³„ì•½ ê·œëª¨ | ë‰´ìŠ¤ ê±´ìˆ˜ | ê·¸ë˜í”„ ë…¸ë“œ | ì´ë²¤íŠ¸ ìˆ˜ |")
        md_lines.append("|------|-----------|-----------|-------------|-----------|")

        for trend in trend_data:
            md_lines.append(f"| ìµœê·¼ {trend['period']}ì¼ | {_fmt_ccy(trend['contract_total'])} | {trend['news_count']}ê±´ | {trend['graph_nodes']}ê°œ | {trend['events_count']}ê°œ |")

        # íŠ¸ë Œë“œ ë¶„ì„
        md_lines.append("\n## ğŸ“‹ íŠ¸ë Œë“œ í•´ì„")

        if len(trend_data) >= 2:
            recent = trend_data[0]  # ìµœë‹¨ê¸°
            longer = trend_data[-1]  # ìµœì¥ê¸°

            # ê³„ì•½ íŠ¸ë Œë“œ
            if recent["contract_total"] > longer["contract_total"] * 0.5:
                md_lines.append("- **ê³„ì•½ íŠ¸ë Œë“œ**: ğŸ“ˆ ìµœê·¼ í™œë°œí•œ ê³„ì•½ í™œë™ ê°ì§€")
            else:
                md_lines.append("- **ê³„ì•½ íŠ¸ë Œë“œ**: ğŸ“‰ ê³„ì•½ í™œë™ì´ ìƒëŒ€ì ìœ¼ë¡œ ì €ì¡°")

            # ë‰´ìŠ¤ íŠ¸ë Œë“œ
            news_ratio = recent["news_count"] / max(longer["news_count"], 1) * (longer["period"] / recent["period"])
            if news_ratio > 1.2:
                md_lines.append("- **ì–¸ë¡  ê´€ì‹¬**: ğŸ“ˆ ìµœê·¼ ì–¸ë¡  ê´€ì‹¬ë„ ê¸‰ì¦")
            elif news_ratio < 0.8:
                md_lines.append("- **ì–¸ë¡  ê´€ì‹¬**: ğŸ“‰ ì–¸ë¡  ê´€ì‹¬ë„ í•˜ë½ ì¶”ì„¸")
            else:
                md_lines.append("- **ì–¸ë¡  ê´€ì‹¬**: â¡ï¸ ì–¸ë¡  ê´€ì‹¬ë„ ì•ˆì •ì  ìœ ì§€")

        # ê¸°ê°„ë³„ ì£¼ìš” ê¸°ì—… ë³€í™”
        md_lines.append("\n## ğŸ¢ ê¸°ê°„ë³„ ì£¼ìš” ê¸°ì—…")
        for trend in trend_data:
            companies_str = ", ".join(trend["top_companies"]) if trend["top_companies"] else "ì—†ìŒ"
            md_lines.append(f"- **ìµœê·¼ {trend['period']}ì¼**: {companies_str}")

        md_lines.append("\n---\n*íŠ¸ë Œë“œ ë¶„ì„ì€ ë¦¬í¬íŠ¸ ì „ìš© ê³ ê¸‰ ê¸°ëŠ¥ì…ë‹ˆë‹¤.*")

        return {
            "markdown": "\n".join(md_lines),
            "trend_data": trend_data,
            "type": "trend_analysis"
        }

    def generate_executive_summary(self, ctx: ReportContext) -> str:
        """ê²½ì˜ì§„ ìš”ì•½ ë¦¬í¬íŠ¸ (ê°„ê²°í•œ í•µì‹¬ ì •ë³´ë§Œ)"""

        g = self.compute_graph_metrics(ctx.graph_rows)
        n = self.compute_news_metrics(ctx.news_hits)

        lines = ["# ğŸ¯ ê²½ì˜ì§„ ìš”ì•½ ë¦¬í¬íŠ¸\n"]
        lines.append(f"**ì§ˆì˜**: `{ctx.query}`")
        lines.append(f"**ë¶„ì„ ê¸°ê°„**: ìµœê·¼ {ctx.lookback_days}ì¼\n")

        # í•µì‹¬ ìˆ«ì
        lines.append("## ğŸ“Š í•µì‹¬ ì§€í‘œ")
        lines.append(f"- **ì´ ê³„ì•½ ê·œëª¨**: {_fmt_ccy(g['contract_total_amount'])}")
        lines.append(f"- **ê´€ë ¨ ë‰´ìŠ¤**: {n['count']}ê±´")
        lines.append(f"- **ë¶„ì„ ë°ì´í„°**: {len(ctx.graph_rows)}ê°œ ì—”í„°í‹°")

        # í†±3 ìš”ì•½
        if g["companies_top"]:
            lines.append(f"- **ì£¼ìš” ê¸°ì—…**: {', '.join(g['companies_top'][:3])}")

        # ìµœì‹  ë‰´ìŠ¤ 1ê±´
        if n["top_news"]:
            latest = n["top_news"][0]
            lines.append(f"- **ìµœì‹  ì´ìŠˆ**: [{latest.get('title', 'ì œëª©ì—†ìŒ')}]({latest.get('url', '')})")

        # ê°„ë‹¨í•œ ê²°ë¡ 
        lines.append("\n## ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸")
        if g["contract_total_amount"] > 1000000000:  # 10ì–µ ì´ìƒ
            lines.append("- ğŸŸ¢ **ëŒ€í˜• ê³„ì•½** ê·œëª¨ë¡œ ì£¼ëª© í•„ìš”")
        elif g["contract_total_amount"] > 100000000:  # 1ì–µ ì´ìƒ
            lines.append("- ğŸŸ¡ **ì¤‘ê°„ ê·œëª¨** ê³„ì•½ í™œë™")
        else:
            lines.append("- ğŸ”´ **ì†Œê·œëª¨** ë˜ëŠ” ê³„ì•½ ì •ë³´ ì œí•œì ")

        if n["count"] > 10:
            lines.append("- ğŸ“ˆ **ë†’ì€ ì–¸ë¡  ê´€ì‹¬ë„**")
        elif n["count"] > 5:
            lines.append("- ğŸ“Š **ë³´í†µ ì–¸ë¡  ê´€ì‹¬ë„**")
        else:
            lines.append("- ğŸ“‰ **ë‚®ì€ ì–¸ë¡  ê´€ì‹¬ë„**")

        lines.append("\n---\n*1ë¶„ ì½ê¸°ìš© ê²½ì˜ì§„ ìš”ì•½ ë¦¬í¬íŠ¸*")

        return "\n".join(lines)
