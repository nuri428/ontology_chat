name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: "3.10"
  UV_VERSION: "0.4.0"

jobs:
  # Code Quality Checks
  quality-checks:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/uv
          .venv
        key: ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-${{ hashFiles('pyproject.toml', 'uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: |
        uv sync --dev

    - name: Code formatting check
      run: |
        uv run python -m pip install ruff black --quiet
        uv run ruff check .
        uv run black --check .

    - name: Type checking
      run: |
        uv run python -m pip install pyright --quiet
        uv run pyright --warnings

    - name: Security scan
      run: |
        uv run python -m pip install bandit safety --quiet
        uv run bandit -r api/ -f json -o security-report.json || true
        uv run safety check --json --output safety-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          security-report.json
          safety-report.json

  # Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: quality-checks

    strategy:
      matrix:
        python-version: ["3.10", "3.11"]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/uv
          .venv
        key: ${{ runner.os }}-python-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml', 'uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        uv sync --dev

    - name: Run unit tests
      run: |
        uv run pytest tests/ -m unit --cov=api --cov-report=xml --cov-report=html --junit-xml=test-results.xml

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          test-results.xml
          htmlcov/

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      neo4j:
        image: neo4j:5-community
        env:
          NEO4J_AUTH: neo4j/test_password
          NEO4J_dbms_memory_pagecache_size: 256M
          NEO4J_dbms_memory_heap_initial__size: 256M
          NEO4J_dbms_memory_heap_max__size: 512M
        ports:
          - 7474:7474
          - 7687:7687
        options: >-
          --health-cmd "cypher-shell -u neo4j -p test_password 'RETURN 1'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10

      opensearch:
        image: opensearchproject/opensearch:2.11.0
        env:
          discovery.type: single-node
          plugins.security.disabled: true
          OPENSEARCH_JAVA_OPTS: "-Xms256m -Xmx512m"
        ports:
          - 9200:9200
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 10

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/uv
          .venv
        key: ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-${{ hashFiles('pyproject.toml', 'uv.lock') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: |
        uv sync --dev

    - name: Wait for services
      run: |
        timeout 60 bash -c 'until curl -f http://localhost:9200/_cluster/health; do echo "Waiting for OpenSearch..."; sleep 5; done'
        timeout 60 bash -c 'until cypher-shell -u neo4j -p test_password "RETURN 1"; do echo "Waiting for Neo4j..."; sleep 5; done'

    - name: Run integration tests
      env:
        NEO4J_URI: bolt://localhost:7687
        NEO4J_USER: neo4j
        NEO4J_PASSWORD: test_password
        OPENSEARCH_HOST: localhost
        OPENSEARCH_PORT: 9200
        TESTING: true
      run: |
        uv run pytest tests/ -m integration --junit-xml=integration-results.xml

    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: integration-results.xml

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install UV
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: |
        uv sync --dev

    - name: Run performance tests
      run: |
        uv run pytest tests/ -m performance --benchmark-json=benchmark.json

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: performance-benchmarks
        path: benchmark.json

    - name: Store benchmark result
      uses: benchmark-action/github-action-benchmark@v1
      if: github.ref == 'refs/heads/main'
      with:
        tool: 'pytest'
        output-file-path: benchmark.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: true

  # Docker Build
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Cache Docker layers
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: false
        tags: ontology-chat:${{ github.sha }}
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max

    - name: Move cache
      run: |
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  # Quality Gate
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [quality-checks, unit-tests, integration-tests, docker-build]
    if: always()

    steps:
    - name: Check all jobs status
      run: |
        echo "Quality Checks: ${{ needs.quality-checks.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"

        if [[ "${{ needs.quality-checks.result }}" != "success" ||
              "${{ needs.unit-tests.result }}" != "success" ||
              "${{ needs.integration-tests.result }}" != "success" ||
              "${{ needs.docker-build.result }}" != "success" ]]; then
          echo "Quality gate failed!"
          exit 1
        fi

        echo "âœ… All quality checks passed!"