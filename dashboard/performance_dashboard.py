"""
Ontology Chat - Performance Analytics Dashboard

ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„ì„ ìœ„í•œ Streamlit ê¸°ë°˜ ì›¹ ëŒ€ì‹œë³´ë“œ
A-grade í’ˆì§ˆ ìœ ì§€ ë° ì‹œìŠ¤í…œ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì¢…í•©ì ì¸ ì‹œê°í™” ì œê³µ
"""

import asyncio
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
from datetime import datetime, timedelta
import time
import json

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Ontology Chat Analytics",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }

    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }

    .metric-value {
        font-size: 2rem;
        font-weight: bold;
    }

    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
    }

    .status-healthy { color: #28a745; font-weight: bold; }
    .status-warning { color: #ffc107; font-weight: bold; }
    .status-critical { color: #dc3545; font-weight: bold; }

    .cache-level {
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        background: #f8f9fa;
    }
</style>
""", unsafe_allow_html=True)

# API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
API_BASE = "http://localhost:8000"

class DashboardAPI:
    """Dashboard API client"""

    @staticmethod
    def get_dashboard_data():
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = requests.get(f"{API_BASE}/analytics/dashboard", timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                return None
        except Exception as e:
            st.error(f"API ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            return None

    @staticmethod
    def get_performance_history(period="24h"):
        """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = requests.get(f"{API_BASE}/analytics/performance/history?period={period}", timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                return None
        except Exception as e:
            st.error(f"íˆìŠ¤í† ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return None

    @staticmethod
    def get_cache_analysis():
        """ìºì‹œ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = requests.get(f"{API_BASE}/analytics/cache/analysis", timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                return None
        except Exception as e:
            st.error(f"ìºì‹œ ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return None


def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""

    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸš€ Ontology Chat Performance Dashboard</h1>', unsafe_allow_html=True)
    st.markdown("**A-Grade Quality Monitoring & System Performance Analytics**")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ Dashboard Settings")

    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
    auto_refresh = st.sidebar.checkbox("Auto Refresh (30s)", value=True)
    if auto_refresh:
        time.sleep(30)
        st.rerun()

    # ì‹œê°„ ë²”ìœ„ ì„¤ì •
    time_range = st.sidebar.selectbox(
        "ğŸ“… Time Range",
        ["1h", "6h", "24h", "7d", "30d"],
        index=2
    )

    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.sidebar.button("ğŸ”„ Refresh Data"):
        st.cache_data.clear()
        st.rerun()

    # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ
    dashboard_data = load_dashboard_data()

    if dashboard_data is None:
        st.error("âš ï¸ Unable to load dashboard data. Please check if the API server is running.")
        st.info("Start the API server: `uvicorn api.main:app --reload`")
        return

    # ë©”ì¸ ë©”íŠ¸ë¦­ í‘œì‹œ
    render_main_metrics(dashboard_data)

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š Real-time Overview",
        "ğŸï¸ Performance Trends",
        "ğŸ’¾ Cache Analytics",
        "â­ Quality Analysis",
        "ğŸš¨ System Health"
    ])

    with tab1:
        render_realtime_overview(dashboard_data)

    with tab2:
        render_performance_trends(time_range)

    with tab3:
        render_cache_analytics()

    with tab4:
        render_quality_analysis(dashboard_data)

    with tab5:
        render_system_health(dashboard_data)


@st.cache_data(ttl=30)
def load_dashboard_data():
    """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ (30ì´ˆ ìºì‹œ)"""
    return DashboardAPI.get_dashboard_data()


def render_main_metrics(data):
    """ë©”ì¸ ë©”íŠ¸ë¦­ ì¹´ë“œ ë Œë”ë§"""
    summary = data.get("summary", {})
    real_time = data.get("real_time_metrics", {})

    # 4ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ì£¼ìš” ë©”íŠ¸ë¦­ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        quality_score = real_time.get("quality_score", 0)
        quality_status = "ğŸŸ¢" if quality_score >= 0.900 else "ğŸŸ¡" if quality_score >= 0.850 else "ğŸ”´"
        st.metric(
            label="A-Grade Quality Score",
            value=f"{quality_score:.3f}",
            delta=f"{quality_status} {'A-Grade' if quality_score >= 0.900 else 'Below A-Grade'}"
        )

    with col2:
        response_time = real_time.get("response_time_ms", 0)
        response_status = "ğŸŸ¢" if response_time < 100 else "ğŸŸ¡" if response_time < 200 else "ğŸ”´"
        st.metric(
            label="Avg Response Time",
            value=f"{response_time:.1f}ms",
            delta=f"{response_status} {'Excellent' if response_time < 100 else 'Good' if response_time < 200 else 'Needs Attention'}"
        )

    with col3:
        cache_hit_rate = real_time.get("cache_hit_rate", 0)
        cache_status = "ğŸŸ¢" if cache_hit_rate > 0.8 else "ğŸŸ¡" if cache_hit_rate > 0.6 else "ğŸ”´"
        st.metric(
            label="Cache Hit Rate",
            value=f"{cache_hit_rate:.1%}",
            delta=f"{cache_status} {'Excellent' if cache_hit_rate > 0.8 else 'Good' if cache_hit_rate > 0.6 else 'Suboptimal'}"
        )

    with col4:
        requests_per_min = real_time.get("requests_per_minute", 0)
        throughput_status = "ğŸŸ¢" if requests_per_min > 10 else "ğŸŸ¡" if requests_per_min > 5 else "ğŸ”´"
        st.metric(
            label="Requests/Minute",
            value=f"{requests_per_min:.1f}",
            delta=f"{throughput_status} {'High Traffic' if requests_per_min > 10 else 'Normal' if requests_per_min > 5 else 'Low Traffic'}"
        )


def render_realtime_overview(data):
    """ì‹¤ì‹œê°„ ê°œìš” ë Œë”ë§"""
    st.header("ğŸ“Š Real-time System Overview")

    real_time = data.get("real_time_metrics", {})

    # ì‹¤ì‹œê°„ ì°¨íŠ¸ ìƒì„±
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ¯ Quality & Performance")

        # ê²Œì´ì§€ ì°¨íŠ¸ - í’ˆì§ˆ ì ìˆ˜
        quality_score = real_time.get("quality_score", 0)

        fig_gauge = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = quality_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Quality Score"},
            delta = {'reference': 0.900},
            gauge = {
                'axis': {'range': [0, 1.0]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 0.850], 'color': "lightgray"},
                    {'range': [0.850, 0.900], 'color': "yellow"},
                    {'range': [0.900, 1.0], 'color': "lightgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 0.900
                }
            }
        ))
        fig_gauge.update_layout(height=300)
        st.plotly_chart(fig_gauge, use_container_width=True)

    with col2:
        st.subheader("âš¡ Response Time Distribution")

        # íˆìŠ¤í† ê·¸ë¨ - ì‘ë‹µ ì‹œê°„ ë¶„í¬ (ëª¨í‚¹ ë°ì´í„°)
        response_times = [
            real_time.get("response_time_ms", 50) + (i * 5) for i in range(-10, 11)
        ]

        fig_hist = px.histogram(
            x=response_times,
            nbins=20,
            title="Response Time Distribution",
            labels={'x': 'Response Time (ms)', 'y': 'Frequency'}
        )
        fig_hist.update_layout(height=300)
        st.plotly_chart(fig_hist, use_container_width=True)

    # ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½
    st.subheader("ğŸ–¥ï¸ System Status Summary")

    status_cols = st.columns(4)

    with status_cols[0]:
        st.info(f"**Active Connections**\n{real_time.get('active_connections', 0)}")

    with status_cols[1]:
        error_rate = real_time.get('error_rate', 0)
        error_color = "success" if error_rate < 0.01 else "warning" if error_rate < 0.05 else "error"
        if error_color == "success":
            st.success(f"**Error Rate**\n{error_rate:.3%}")
        elif error_color == "warning":
            st.warning(f"**Error Rate**\n{error_rate:.3%}")
        else:
            st.error(f"**Error Rate**\n{error_rate:.3%}")

    with status_cols[2]:
        cache_eff = real_time.get('cache_effectiveness', 0)
        st.info(f"**Cache Effectiveness**\n{cache_eff:.1%}")

    with status_cols[3]:
        uptime_hours = data.get("summary", {}).get("uptime_hours", 0)
        st.success(f"**System Uptime**\n{uptime_hours:.1f} hours")


def render_performance_trends(time_range):
    """ì„±ëŠ¥ íŠ¸ë Œë“œ ë Œë”ë§"""
    st.header("ğŸï¸ Performance Trends")

    # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¡œë“œ
    history_data = DashboardAPI.get_performance_history(time_range)

    if history_data is None:
        st.error("Failed to load performance history data")
        return

    data_points = history_data.get("data_points", [])

    if not data_points:
        st.warning("No historical data available")
        return

    # DataFrame ìƒì„±
    df = pd.DataFrame(data_points)
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    # íŠ¸ë Œë“œ ì°¨íŠ¸
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“ˆ Quality Score Trend")
        fig_quality = px.line(
            df, x='timestamp', y='quality_score',
            title=f"Quality Score - Last {time_range}",
            labels={'quality_score': 'Quality Score', 'timestamp': 'Time'}
        )
        fig_quality.add_hline(y=0.900, line_dash="dash", line_color="red", annotation_text="A-Grade Threshold")
        fig_quality.update_layout(height=400)
        st.plotly_chart(fig_quality, use_container_width=True)

    with col2:
        st.subheader("âš¡ Response Time Trend")
        fig_response = px.line(
            df, x='timestamp', y='response_time_ms',
            title=f"Response Time - Last {time_range}",
            labels={'response_time_ms': 'Response Time (ms)', 'timestamp': 'Time'}
        )
        fig_response.update_layout(height=400)
        st.plotly_chart(fig_response, use_container_width=True)

    # ìºì‹œ ë° ì—ëŸ¬ìœ¨ íŠ¸ë Œë“œ
    col3, col4 = st.columns(2)

    with col3:
        st.subheader("ğŸ’¾ Cache Hit Rate Trend")
        fig_cache = px.line(
            df, x='timestamp', y='cache_hit_rate',
            title=f"Cache Hit Rate - Last {time_range}",
            labels={'cache_hit_rate': 'Cache Hit Rate', 'timestamp': 'Time'}
        )
        fig_cache.update_layout(height=400)
        st.plotly_chart(fig_cache, use_container_width=True)

    with col4:
        st.subheader("ğŸš¨ Error Rate Trend")
        fig_error = px.line(
            df, x='timestamp', y='error_rate',
            title=f"Error Rate - Last {time_range}",
            labels={'error_rate': 'Error Rate', 'timestamp': 'Time'}
        )
        fig_error.update_layout(height=400)
        st.plotly_chart(fig_error, use_container_width=True)

    # ìš”ì•½ í†µê³„
    st.subheader("ğŸ“Š Period Summary")
    summary = history_data.get("summary", {})

    summary_cols = st.columns(3)
    with summary_cols[0]:
        st.metric("Avg Quality Score", f"{summary.get('avg_quality_score', 0):.3f}")
    with summary_cols[1]:
        st.metric("Avg Response Time", f"{summary.get('avg_response_time', 0):.1f}ms")
    with summary_cols[2]:
        st.metric("Avg Cache Hit Rate", f"{summary.get('avg_cache_hit_rate', 0):.1%}")


def render_cache_analytics():
    """ìºì‹œ ë¶„ì„ ë Œë”ë§"""
    st.header("ğŸ’¾ Cache Performance Analytics")

    cache_data = DashboardAPI.get_cache_analysis()

    if cache_data is None:
        st.error("Failed to load cache analysis data")
        return

    # ì „ì²´ ìºì‹œ ì„±ëŠ¥
    overall = cache_data.get("overall_performance", {})

    st.subheader("ğŸ† Overall Cache Performance")

    perf_cols = st.columns(4)
    with perf_cols[0]:
        hit_rate = overall.get("hit_rate", 0)
        st.metric("Overall Hit Rate", f"{hit_rate:.1%}")

    with perf_cols[1]:
        effectiveness = overall.get("effectiveness_score", 0)
        st.metric("Effectiveness Score", f"{effectiveness:.3f}")

    with perf_cols[2]:
        improvement = overall.get("response_time_improvement", "0%")
        st.metric("Response Time Improvement", improvement)

    with perf_cols[3]:
        quality_contrib = overall.get("quality_contribution", 0)
        st.metric("Quality Contribution", f"{quality_contrib:.3f}")

    # ë ˆë²¨ë³„ ë¶„ì„
    st.subheader("ğŸ—ï¸ Multi-Level Cache Analysis")

    level_analysis = cache_data.get("level_analysis", {})

    # L1, L2, L3 íƒ­
    l1_tab, l2_tab, l3_tab = st.tabs(["ğŸš€ L1 Memory", "ğŸŒ L2 Redis", "ğŸ’½ L3 Disk"])

    with l1_tab:
        render_cache_level_analysis("L1 Memory Cache", level_analysis.get("l1_memory", {}))

    with l2_tab:
        render_cache_level_analysis("L2 Redis Cache", level_analysis.get("l2_redis", {}))

    with l3_tab:
        render_cache_level_analysis("L3 Disk Cache", level_analysis.get("l3_disk", {}))

    # ìºì‹œ íŒ¨í„´ ë¶„ì„
    st.subheader("ğŸ“ˆ Cache Usage Patterns")

    patterns = cache_data.get("cache_patterns", {})
    hot_queries = patterns.get("hot_queries", [])

    if hot_queries:
        st.write("**ğŸ”¥ Hot Queries:**")
        hot_df = pd.DataFrame(hot_queries)
        st.dataframe(hot_df, use_container_width=True)

    # ìµœì í™” ì œì•ˆ
    suggestions = cache_data.get("optimization_suggestions", [])
    if suggestions:
        st.subheader("ğŸ’¡ Optimization Suggestions")
        for i, suggestion in enumerate(suggestions, 1):
            st.info(f"**{i}.** {suggestion}")


def render_cache_level_analysis(level_name, data):
    """ìºì‹œ ë ˆë²¨ë³„ ë¶„ì„ ë Œë”ë§"""
    st.write(f"### {level_name}")

    if not data:
        st.warning(f"{level_name} data not available")
        return

    cols = st.columns(3)

    with cols[0]:
        hit_rate = data.get("hit_rate", 0)
        hit_color = "success" if hit_rate > 0.6 else "warning" if hit_rate > 0.3 else "error"
        if hit_color == "success":
            st.success(f"**Hit Rate**: {hit_rate:.1%}")
        elif hit_color == "warning":
            st.warning(f"**Hit Rate**: {hit_rate:.1%}")
        else:
            st.error(f"**Hit Rate**: {hit_rate:.1%}")

    with cols[1]:
        efficiency = data.get("efficiency_score", 0)
        st.metric("Efficiency Score", f"{efficiency:.2f}")

    with cols[2]:
        access_time = data.get("avg_access_time_ms", 0)
        st.metric("Avg Access Time", f"{access_time:.1f}ms")

    # ì¶”ê°€ ë©”íŠ¸ë¦­
    if "memory_utilization" in data:
        st.progress(data["memory_utilization"] / 100.0)
        st.caption(f"Memory Utilization: {data['memory_utilization']:.1f}%")

    if "disk_utilization" in data:
        st.progress(data["disk_utilization"] / 100.0)
        st.caption(f"Disk Utilization: {data['disk_utilization']:.1f}%")

    if "connection_status" in data:
        status = data["connection_status"]
        if status:
            st.success("âœ… Connected")
        else:
            st.error("âŒ Disconnected")

    # ê¶Œì¥ì‚¬í•­
    recommendation = data.get("recommendation", "")
    if recommendation:
        st.info(f"**ğŸ’¡ Recommendation:** {recommendation}")


def render_quality_analysis(data):
    """í’ˆì§ˆ ë¶„ì„ ë Œë”ë§"""
    st.header("â­ A-Grade Quality Analysis")

    # í˜„ì¬ í’ˆì§ˆ ìƒíƒœ
    quality_analysis = data.get("quality_analysis", {})
    current_score = quality_analysis.get("current_score", 0.949)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ¯ Quality Status")

        grade = "A" if current_score >= 0.900 else "B" if current_score >= 0.800 else "C"
        grade_color = "success" if grade == "A" else "warning" if grade == "B" else "error"

        if grade_color == "success":
            st.success(f"**Current Grade: {grade}**")
        elif grade_color == "warning":
            st.warning(f"**Current Grade: {grade}**")
        else:
            st.error(f"**Current Grade: {grade}**")

        st.metric("Quality Score", f"{current_score:.3f}")
        st.metric("Threshold Margin", f"+{current_score - 0.900:.3f}")

    with col2:
        st.subheader("ğŸ“Š Contributing Factors")

        factors = quality_analysis.get("contributing_factors", {})

        # ê¸°ì—¬ ìš”ì†Œ ì°¨íŠ¸
        if factors:
            factor_names = []
            factor_values = []

            for name, info in factors.items():
                factor_names.append(name.replace("_", " ").title())
                factor_values.append(info.get("score", 0) if isinstance(info, dict) else info)

            fig_factors = px.bar(
                x=factor_names,
                y=factor_values,
                title="Quality Contributing Factors",
                labels={'x': 'Factors', 'y': 'Contribution Score'}
            )
            st.plotly_chart(fig_factors, use_container_width=True)

    # í’ˆì§ˆ íˆìŠ¤í† ë¦¬
    st.subheader("ğŸ“ˆ Quality History")

    # Mock quality history data
    quality_history = [
        {"date": datetime.now() - timedelta(days=i), "score": 0.949 + (i * 0.001)}
        for i in range(30, 0, -1)
    ]

    df_quality = pd.DataFrame(quality_history)

    fig_quality_history = px.line(
        df_quality, x='date', y='score',
        title="Quality Score - Last 30 Days",
        labels={'score': 'Quality Score', 'date': 'Date'}
    )
    fig_quality_history.add_hline(y=0.900, line_dash="dash", line_color="red", annotation_text="A-Grade Threshold")
    st.plotly_chart(fig_quality_history, use_container_width=True)


def render_system_health(data):
    """ì‹œìŠ¤í…œ í—¬ìŠ¤ ë Œë”ë§"""
    st.header("ğŸš¨ System Health & Alerts")

    system_health = data.get("system_health", {})
    components = system_health.get("components", {})

    st.subheader("ğŸ”§ Component Status")

    # ì»´í¬ë„ŒíŠ¸ ìƒíƒœ
    for component_name, component_info in components.items():
        with st.expander(f"{component_name.replace('_', ' ').title()}", expanded=True):

            if isinstance(component_info, dict):
                status = component_info.get("status", "unknown")

                if status == "healthy":
                    st.success(f"âœ… {component_name} is healthy")
                elif status == "degraded":
                    st.warning(f"âš ï¸ {component_name} is degraded")
                else:
                    st.error(f"âŒ {component_name} has issues")

                # ìƒì„¸ ì •ë³´ í‘œì‹œ
                for key, value in component_info.items():
                    if key != "status":
                        st.text(f"{key}: {value}")

    # í™œì„± ì•Œë¦¼
    alerts = system_health.get("alerts", [])

    if alerts:
        st.subheader("ğŸš¨ Active Alerts")

        for alert in alerts:
            severity = alert.get("severity", "info")
            message = alert.get("message", "No message")

            if severity == "critical":
                st.error(f"ğŸ”´ **CRITICAL**: {message}")
            elif severity == "warning":
                st.warning(f"ğŸŸ¡ **WARNING**: {message}")
            else:
                st.info(f"ğŸ”µ **INFO**: {message}")
    else:
        st.success("âœ… No active alerts")

    # ê¶Œì¥ì‚¬í•­
    recommendations = system_health.get("recommendations", [])

    if recommendations:
        st.subheader("ğŸ’¡ System Recommendations")
        for i, rec in enumerate(recommendations, 1):
            st.info(f"**{i}.** {rec}")


if __name__ == "__main__":
    main()