#!/usr/bin/env python3
"""í˜„ì¬ ì ìš©ëœ ëª¨ë“  ê¸°ëŠ¥ì˜ ì¢…í•© í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
import asyncio
import sys
import time
from datetime import datetime
sys.path.append('.')

async def test_integrated_pipeline():
    """í†µí•© íŒŒì´í”„ë¼ì¸ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”¬ í†µí•© ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    try:
        from api.services.chat_service import ChatService

        service = ChatService()

        # ë‹¤ì–‘í•œ ë³µì¡ë„ì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            {
                "query": "SMR ê´€ë ¨ ìœ ë§ íˆ¬ì ì¢…ëª© ë¶„ì„",
                "complexity": "ì¤‘ê°„",
                "expected_features": ["ì—ë„ˆì§€", "ì›ìë ¥", "íˆ¬ì", "ìƒì¥ì‚¬"]
            },
            {
                "query": "ë°˜ë„ì²´ ë©”ëª¨ë¦¬ ì‹œì¥ ì „ë§ê³¼ ì‚¼ì„±ì „ì ê²½ìŸë ¥",
                "complexity": "ë†’ìŒ",
                "expected_features": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ì‚¼ì„±ì „ì", "ì‹œì¥ë¶„ì„"]
            },
            {
                "query": "ì „ê¸°ì°¨ ë°°í„°ë¦¬ ê³µê¸‰ë§ ì´ìŠˆ",
                "complexity": "ì¤‘ê°„",
                "expected_features": ["ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ê³µê¸‰ë§"]
            }
        ]

        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ê¸°ëŠ¥:")
        print(f"   âœ… Ollama LLM (llama3.1:8b)")
        print(f"   âœ… ì»¨í…ìŠ¤íŠ¸ ìºì‹±")
        print(f"   âœ… ë™ì  í”„ë£¨ë‹")
        print(f"   âœ… ì˜ë¯¸ì  ìœ ì‚¬ë„ í•„í„°ë§")
        print(f"   âœ… ë‹¤ì–‘ì„± ìµœì í™”")
        print(f"   âœ… Neo4j ì˜¨í†¨ë¡œì§€ í™•ì¥")

        total_metrics = {
            "total_queries": 0,
            "avg_response_time": 0,
            "cache_hits": 0,
            "semantic_improvements": 0,
            "diversity_scores": [],
            "quality_ratings": []
        }

        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            complexity = test_case["complexity"]

            print(f"\n{i}ï¸âƒ£  ì¿¼ë¦¬: '{query}'")
            print(f"   ë³µì¡ë„: {complexity}")
            print("-" * 60)

            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            start_time = time.perf_counter()

            try:
                # 1. í‚¤ì›Œë“œ ì¶”ì¶œ (Ollama LLM)
                print("ğŸ” 1ë‹¨ê³„: Ollama LLM í‚¤ì›Œë“œ ì¶”ì¶œ")
                keyword_start = time.perf_counter()
                keywords = await service._get_context_keywords(query)
                keyword_time = (time.perf_counter() - keyword_start) * 1000

                print(f"   â±ï¸  í‚¤ì›Œë“œ ì¶”ì¶œ: {keyword_time:.1f}ms")
                print(f"   ğŸ“ ì¶”ì¶œ í‚¤ì›Œë“œ: '{keywords}'")

                # 2. ë‰´ìŠ¤ ê²€ìƒ‰ (ì˜¨í†¨ë¡œì§€ ê°•í™” + ëª¨ë“  í•„í„° ì ìš©)
                print(f"\nğŸ” 2ë‹¨ê³„: í†µí•© ë‰´ìŠ¤ ê²€ìƒ‰")
                search_start = time.perf_counter()

                news_hits, search_time, search_error = await service._search_news_with_ontology(query, size=5)
                search_elapsed = (time.perf_counter() - search_start) * 1000

                print(f"   â±ï¸  ê²€ìƒ‰ ì‹œê°„: {search_elapsed:.1f}ms")
                print(f"   ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(news_hits)}ê±´")

                if news_hits:
                    print(f"   ğŸ“„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:")
                    for j, hit in enumerate(news_hits[:3], 1):
                        title = hit.get('title', 'N/A')[:50]
                        semantic_score = hit.get('semantic_score', 0)
                        combined_score = hit.get('combined_score', 0)
                        print(f"      {j}. {title}...")
                        print(f"         ì˜ë¯¸ì ìˆ˜: {semantic_score:.3f}, í†µí•©ì ìˆ˜: {combined_score:.3f}")

                # 3. ê·¸ë˜í”„ ê²€ìƒ‰
                print(f"\nğŸ”— 3ë‹¨ê³„: Neo4j ê·¸ë˜í”„ ê²€ìƒ‰")
                graph_start = time.perf_counter()

                graph_rows, graph_time, graph_error = await service._query_graph(query, limit=5)
                graph_elapsed = (time.perf_counter() - graph_start) * 1000

                print(f"   â±ï¸  ê·¸ë˜í”„ ê²€ìƒ‰: {graph_elapsed:.1f}ms")
                print(f"   ğŸ”— ê·¸ë˜í”„ ê²°ê³¼: {len(graph_rows)}ê°œ ë…¸ë“œ")

                if graph_rows:
                    print(f"   ğŸ“Š ê·¸ë˜í”„ ë…¸ë“œ:")
                    for j, row in enumerate(graph_rows[:3], 1):
                        node = row.get('n', {})
                        name = node.get('name', node.get('title', 'N/A'))[:30]
                        print(f"      {j}. {name}")

                # 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„
                total_time = (time.perf_counter() - start_time) * 1000
                print(f"\nâ±ï¸  ì „ì²´ íŒŒì´í”„ë¼ì¸: {total_time:.1f}ms")

                # 5. í’ˆì§ˆ ë¶„ì„
                print(f"\nğŸ“ˆ í’ˆì§ˆ ë¶„ì„:")

                # ë‹¤ì–‘ì„± ì ìˆ˜ ê³„ì‚°
                diversity_score = 0.0
                if news_hits:
                    from api.services.context_diversity import calculate_diversity_score
                    diversity_score = calculate_diversity_score(news_hits)
                    print(f"   ğŸŒˆ ë‹¤ì–‘ì„± ì ìˆ˜: {diversity_score:.3f}")
                    total_metrics["diversity_scores"].append(diversity_score)

                # ìºì‹œ íš¨ê³¼ í™•ì¸
                from api.services.context_cache import context_cache
                cache_stats = context_cache.get_stats()
                cache_hit_rate = cache_stats.get('hit_rate', 0) * 100
                print(f"   ğŸ¯ ìºì‹œ íˆíŠ¸ìœ¨: {cache_hit_rate:.1f}%")

                # ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ - ì˜ë¯¸ì  ì ìˆ˜ í™œìš©
                relevance_score = 0
                if news_hits:
                    # ì˜ë¯¸ì  ì ìˆ˜ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ë§¤ì¹­
                    semantic_scores = [hit.get('semantic_score', 0) for hit in news_hits]

                    if any(score > 0 for score in semantic_scores):
                        # ì˜ë¯¸ì  ì ìˆ˜ ì‚¬ìš© (ë” ì •í™•í•œ ê´€ë ¨ì„± ì¸¡ì •)
                        relevance_score = sum(semantic_scores) / len(semantic_scores)
                    else:
                        # í´ë°±: ì œëª©ì—ì„œ ì¿¼ë¦¬ í‚¤ì›Œë“œ ë§¤ì¹­ë„ ê³„ì‚°
                        query_words = set(query.lower().split())
                        for hit in news_hits:
                            title = hit.get('title', '').lower()
                            title_words = set(title.split())
                            overlap = len(query_words & title_words)
                            relevance_score += overlap / len(query_words) if query_words else 0
                        relevance_score /= len(news_hits)

                print(f"   ğŸ¯ ê´€ë ¨ì„± ì ìˆ˜: {relevance_score:.3f}")

                # ì‘ë‹µ ì™„ì„±ë„ í‰ê°€
                completeness = 0
                if news_hits: completeness += 0.4
                if graph_rows: completeness += 0.3
                if keywords: completeness += 0.3

                print(f"   âœ… ì™„ì„±ë„ ì ìˆ˜: {completeness:.3f}")

                # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
                quality_score = (diversity_score + relevance_score + completeness) / 3
                print(f"   ğŸ† ì¢…í•© í’ˆì§ˆ: {quality_score:.3f}")

                # ë©”íŠ¸ë¦­ ëˆ„ì 
                total_metrics["total_queries"] += 1
                total_metrics["avg_response_time"] += total_time
                total_metrics["quality_ratings"].append(quality_score)

                if cache_hit_rate > 0:
                    total_metrics["cache_hits"] += 1

                if news_hits and any(hit.get('semantic_score', 0) > 0.7 for hit in news_hits):
                    total_metrics["semantic_improvements"] += 1

            except Exception as e:
                print(f"   âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()

        # ì¢…í•© ë¶„ì„
        print(f"\n" + "=" * 70)
        print("ğŸ“Š ì¢…í•© ì„±ëŠ¥ ë¶„ì„")
        print("=" * 70)

        if total_metrics["total_queries"] > 0:
            avg_time = total_metrics["avg_response_time"] / total_metrics["total_queries"]
            avg_quality = sum(total_metrics["quality_ratings"]) / len(total_metrics["quality_ratings"]) if total_metrics["quality_ratings"] else 0
            avg_diversity = sum(total_metrics["diversity_scores"]) / len(total_metrics["diversity_scores"]) if total_metrics["diversity_scores"] else 0

            print(f"ğŸ¯ í•µì‹¬ ì§€í‘œ:")
            print(f"   â€¢ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.1f}ms")
            print(f"   â€¢ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.3f}")
            print(f"   â€¢ í‰ê·  ë‹¤ì–‘ì„±: {avg_diversity:.3f}")
            print(f"   â€¢ ìºì‹œ í™œìš©ë¥ : {total_metrics['cache_hits']}/{total_metrics['total_queries']}")
            print(f"   â€¢ ì˜ë¯¸ì  ê°œì„ : {total_metrics['semantic_improvements']}/{total_metrics['total_queries']}")

            # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
            print(f"\nğŸ… ì„±ëŠ¥ ë“±ê¸‰:")
            if avg_time < 2000: print(f"   âš¡ ì‘ë‹µ ì†ë„: Aê¸‰ (2ì´ˆ ë¯¸ë§Œ)")
            elif avg_time < 5000: print(f"   ğŸ”¶ ì‘ë‹µ ì†ë„: Bê¸‰ (5ì´ˆ ë¯¸ë§Œ)")
            else: print(f"   ğŸ”´ ì‘ë‹µ ì†ë„: Cê¸‰ (5ì´ˆ ì´ìƒ)")

            if avg_quality > 0.8: print(f"   ğŸ† ë‹µë³€ í’ˆì§ˆ: Aê¸‰ (0.8 ì´ìƒ)")
            elif avg_quality > 0.6: print(f"   ğŸ¥ˆ ë‹µë³€ í’ˆì§ˆ: Bê¸‰ (0.6 ì´ìƒ)")
            else: print(f"   ğŸ¥‰ ë‹µë³€ í’ˆì§ˆ: Cê¸‰ (0.6 ë¯¸ë§Œ)")

            if avg_diversity > 0.7: print(f"   ğŸŒˆ ì •ë³´ ë‹¤ì–‘ì„±: Aê¸‰ (0.7 ì´ìƒ)")
            elif avg_diversity > 0.5: print(f"   ğŸ¨ ì •ë³´ ë‹¤ì–‘ì„±: Bê¸‰ (0.5 ì´ìƒ)")
            else: print(f"   ğŸ“ ì •ë³´ ë‹¤ì–‘ì„±: Cê¸‰ (0.5 ë¯¸ë§Œ)")

        # ê°œì„  ì œì•ˆ
        print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ:")
        if avg_time > 3000:
            print(f"   âš¡ ì‘ë‹µ ì†ë„ ê°œì„  í•„ìš” - ìºì‹± ê°•í™” ê¶Œì¥")
        if avg_diversity < 0.6:
            print(f"   ğŸŒˆ ë‹¤ì–‘ì„± í•„í„°ë§ ê°•í™” í•„ìš”")
        if total_metrics['cache_hits'] < total_metrics['total_queries'] * 0.3:
            print(f"   ğŸ¯ ìºì‹œ íˆíŠ¸ìœ¨ ê°œì„  - TTL ì¡°ì • ê¶Œì¥")

        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
        cache_stats = context_cache.get_stats()
        print(f"\nğŸ“ˆ ë¦¬ì†ŒìŠ¤ í˜„í™©:")
        print(f"   â€¢ ìºì‹œ ì‚¬ìš©ëŸ‰: {cache_stats.get('cache_size', 0)}/{cache_stats.get('max_size', 100)}")
        print(f"   â€¢ ì´ ìºì‹œ ìš”ì²­: {cache_stats.get('total_requests', 0)}íšŒ")
        print(f"   â€¢ ìºì‹œ ì œê±°: {cache_stats.get('evictions', 0)}íšŒ")

        # ì •ë¦¬
        await service.neo.close()

    except Exception as e:
        print(f"âŒ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

async def benchmark_vs_baseline():
    """ê¸°ì¤€ì„  ëŒ€ë¹„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print(f"\n" + "=" * 70)
    print("âš–ï¸  ê¸°ì¤€ì„  ëŒ€ë¹„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 70)

    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ vs LLM í‚¤ì›Œë“œ ë¹„êµ
    test_query = "SMR ì†Œí˜•ëª¨ë“ˆì›ìë¡œ íˆ¬ì ì „ë§"

    print(f"ğŸ“‹ ë²¤ì¹˜ë§ˆí¬ ì¿¼ë¦¬: '{test_query}'")

    try:
        from api.services.chat_service import ChatService
        service = ChatService()

        # 1. ê¸°ì¡´ ë°©ì‹ (í´ë°±)
        print(f"\n1ï¸âƒ£ ê¸°ì¡´ ë°©ì‹ (í´ë°± í‚¤ì›Œë“œ):")
        start = time.perf_counter()
        fallback_keywords = service._fallback_keyword_extraction(test_query)
        fallback_time = (time.perf_counter() - start) * 1000
        print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {fallback_time:.1f}ms")
        print(f"   ğŸ“ í‚¤ì›Œë“œ: '{fallback_keywords}'")

        # 2. LLM ë°©ì‹
        print(f"\n2ï¸âƒ£ Ollama LLM ë°©ì‹:")
        start = time.perf_counter()
        llm_keywords = await service._get_context_keywords(test_query)
        llm_time = (time.perf_counter() - start) * 1000
        print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {llm_time:.1f}ms")
        print(f"   ğŸ“ í‚¤ì›Œë“œ: '{llm_keywords}'")

        # ë¹„êµ ë¶„ì„
        print(f"\nğŸ“Š ë¹„êµ ë¶„ì„:")
        speedup = fallback_time / llm_time if llm_time > 0 else 0
        if speedup < 1:
            print(f"   âš¡ LLMì´ {1/speedup:.1f}ë°° ë¹ ë¦„ (ì˜ˆìƒ ë°–)")
        else:
            print(f"   ğŸŒ LLMì´ {speedup:.1f}ë°° ëŠë¦¼ (ì •ìƒ - í’ˆì§ˆ í–¥ìƒ ëŒ€ê°€)")

        # í‚¤ì›Œë“œ í’ˆì§ˆ ë¹„êµ
        fallback_words = set(fallback_keywords.split())
        llm_words = set(llm_keywords.split()) if llm_keywords else set()

        overlap = len(fallback_words & llm_words)
        llm_unique = len(llm_words - fallback_words)

        print(f"   ğŸ”„ ê³µí†µ í‚¤ì›Œë“œ: {overlap}ê°œ")
        print(f"   âœ¨ LLM ì¶”ê°€ í‚¤ì›Œë“œ: {llm_unique}ê°œ")
        print(f"   ğŸ“ˆ í‚¤ì›Œë“œ í™•ì¥ë¥ : {llm_unique/len(fallback_words)*100:.1f}%" if fallback_words else "N/A")

        await service.neo.close()

    except Exception as e:
        print(f"   âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(test_integrated_pipeline())
    asyncio.run(benchmark_vs_baseline())