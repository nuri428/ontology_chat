#!/usr/bin/env python3
"""
ìµœì í™”ëœ LangGraph ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

Phase 1 (ì™„ë£Œ): _analyze_query í†µí•© (2íšŒ â†’ 1íšŒ)
Phase 2 (ì™„ë£Œ): _comprehensive_analysis_and_report í†µí•© (5-9íšŒ â†’ 1íšŒ)

ì˜ˆìƒ ì„±ëŠ¥: 15-20ì´ˆ â†’ 6-8ì´ˆ (50-60% ê°œì„ )
"""

import asyncio
import time
import json
import httpx
from datetime import datetime


async def test_optimized_langgraph():
    """ìµœì í™”ëœ LangGraph ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    test_queries = [
        # ë³µì¡í•œ ì§ˆë¬¸ (LangGraph ì‚¬ìš©)
        "ì‚¼ì„±ì „ìì™€ SKí•˜ì´ë‹‰ìŠ¤ì˜ HBM ê²½ìŸë ¥ ë¹„êµ",
        "AI ë°˜ë„ì²´ ì‹œì¥ì—ì„œ HBM ê¸°ìˆ  ê²½ìŸë ¥ì„ ê°€ì§„ ê¸°ì—…ì€?",
        "í˜„ëŒ€ì°¨ ì „ê¸°ì°¨ ì‚¬ì—… í˜„í™©ì€?",
    ]

    results = {
        "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
        "optimization_info": {
            "phase_1": "query analysis unified (2 â†’ 1 LLM calls)",
            "phase_2": "comprehensive analysis unified (5-9 â†’ 1 LLM calls)",
            "expected_improvement": "15-20s â†’ 6-8s (50-60% faster)"
        },
        "tests": []
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        for query in test_queries:
            print(f"\n{'='*80}")
            print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {query}")
            print(f"{'='*80}")

            start_time = time.time()

            try:
                # MCP ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°íŒ…)
                response = await client.post(
                    "http://localhost:8000/mcp/chat",
                    json={
                        "query": query,
                        "user_id": "performance_test",
                        "force_deep_analysis": True  # LangGraph ê°•ì œ ì‚¬ìš©
                    }
                )

                elapsed = time.time() - start_time

                if response.status_code == 200:
                    data = response.json()
                    result_data = data.get("result", {})

                    # ì‘ë‹µ êµ¬ì¡° í™•ì¸
                    report = result_data.get("report", {})

                    test_result = {
                        "query": query,
                        "status": "success",
                        "response_time": f"{elapsed:.2f}s",
                        "quality_score": report.get("quality_score", 0.0),
                        "quality_level": report.get("quality_level", "unknown"),
                        "contexts_count": report.get("contexts_count", 0),
                        "insights_count": report.get("insights_count", 0),
                        "relationships_count": report.get("relationships_count", 0),
                        "retry_count": report.get("retry_count", 0),
                        "processing_time": report.get("processing_time", 0.0),
                        "execution_log": report.get("execution_log", [])
                    }

                    print(f"âœ… ì„±ê³µ")
                    print(f"   ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ")
                    print(f"   í’ˆì§ˆ ì ìˆ˜: {test_result['quality_score']:.2f} ({test_result['quality_level']})")
                    print(f"   ì²˜ë¦¬ ì‹œê°„: {test_result['processing_time']:.2f}ì´ˆ")
                    print(f"   ì»¨í…ìŠ¤íŠ¸: {test_result['contexts_count']}ê°œ")
                    print(f"   ì¸ì‚¬ì´íŠ¸: {test_result['insights_count']}ê°œ")
                    print(f"   ê´€ê³„ ë¶„ì„: {test_result['relationships_count']}ê°œ")
                    print(f"   ì¬ì‹œë„: {test_result['retry_count']}íšŒ")

                    # ì‹¤í–‰ ë¡œê·¸ ì¶œë ¥
                    print(f"\n   ì‹¤í–‰ ë¡œê·¸:")
                    for log_entry in test_result['execution_log']:
                        print(f"     {log_entry}")

                    # ë³´ê³ ì„œ ìƒ˜í”Œ ì¶œë ¥ (ì²˜ìŒ 500ì)
                    markdown = report.get("markdown", "")
                    print(f"\n   ë³´ê³ ì„œ ìƒ˜í”Œ ({len(markdown)}ì):")
                    print(f"   {markdown[:500]}...")

                else:
                    test_result = {
                        "query": query,
                        "status": "error",
                        "response_time": f"{elapsed:.2f}s",
                        "error": f"HTTP {response.status_code}: {response.text[:200]}"
                    }
                    print(f"âŒ ì‹¤íŒ¨: {test_result['error']}")

            except Exception as e:
                elapsed = time.time() - start_time
                test_result = {
                    "query": query,
                    "status": "exception",
                    "response_time": f"{elapsed:.2f}s",
                    "error": str(e)
                }
                print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}")

            results["tests"].append(test_result)

            # ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì „ ì ì‹œ ëŒ€ê¸°
            await asyncio.sleep(2)

    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*80}")
    print("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")

    success_tests = [t for t in results["tests"] if t["status"] == "success"]

    if success_tests:
        avg_response_time = sum(float(t["response_time"].replace("s", "")) for t in success_tests) / len(success_tests)
        avg_quality = sum(t["quality_score"] for t in success_tests) / len(success_tests)
        avg_processing = sum(t["processing_time"] for t in success_tests) / len(success_tests)

        print(f"\nì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(success_tests)}/{len(results['tests'])}")
        print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_response_time:.2f}ì´ˆ")
        print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing:.2f}ì´ˆ")
        print(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.2f}")

        results["summary"] = {
            "success_rate": f"{len(success_tests)}/{len(results['tests'])}",
            "avg_response_time": f"{avg_response_time:.2f}s",
            "avg_processing_time": f"{avg_processing:.2f}s",
            "avg_quality_score": avg_quality,
            "improvement_achieved": avg_response_time < 10.0,
            "target_met": avg_response_time <= 8.0
        }

        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
        print(f"   10ì´ˆ ì´ë‚´: {'âœ… YES' if avg_response_time < 10.0 else 'âŒ NO'}")
        print(f"   8ì´ˆ ì´ë‚´: {'âœ… YES' if avg_response_time <= 8.0 else 'âŒ NO'}")
        print(f"   15-20ì´ˆ ëŒ€ë¹„ ê°œì„ ë¥ : {(1 - avg_response_time / 17.5) * 100:.1f}%")

    # ê²°ê³¼ ì €ì¥
    output_file = f"optimized_performance_results_{results['timestamp']}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nê²°ê³¼ ì €ì¥: {output_file}")

    return results


if __name__ == "__main__":
    print("ğŸš€ ìµœì í™”ëœ LangGraph ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    print("Phase 1: Query Analysis Unified (2 â†’ 1 LLM calls)")
    print("Phase 2: Comprehensive Analysis Unified (5-9 â†’ 1 LLM calls)")
    print("ì˜ˆìƒ ê°œì„ : 15-20ì´ˆ â†’ 6-8ì´ˆ (50-60% ê°œì„ )\n")

    results = asyncio.run(test_optimized_langgraph())
