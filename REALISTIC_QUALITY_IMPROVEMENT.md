# í˜„ì‹¤ì ì¸ í’ˆì§ˆ ê°œì„  ì „ëµ

**ì‘ì„± ì¼ì‹œ**: 2025-10-03 17:45
**í˜„ì‹¤ ì¸ì‹**: ì‹ ê·œ ìŠ¤í‚¤ë§ˆ í•„ë“œì— ë°ì´í„°ê°€ ì ì„ ê°€ëŠ¥ì„± ë†’ìŒ
**ëª©í‘œ**: ê¸°ì¡´ ë°ì´í„°ë¡œ í’ˆì§ˆ ì ìˆ˜ 0.32 â†’ 0.7+ ê°œì„ 

---

## ğŸ¯ í˜„ì‹¤ ì§„ë‹¨

### ë¬¸ì œì 
- âŒ **ì‹ ê·œ í•„ë“œ ë°ì´í„° ë¶€ì¡±**: `quality_score`, `is_featured` ë“±ì´ NULLì¼ ê°€ëŠ¥ì„± ë†’ìŒ
- âŒ **ì˜ì¡´ì„± ìœ„í—˜**: ë¹ˆ í•„ë“œì— ì˜ì¡´í•˜ë©´ ê°œì„  íš¨ê³¼ ì—†ìŒ
- âš ï¸ **ìˆ˜ì§‘ê¸°ì™€ ë¶„ë¦¬**: ìˆ˜ì§‘ê¸° ì¸¡ ì—…ë°ì´íŠ¸ í•„ìš” (ë³„ë„ ì‘ì—…)

### í˜„ì¬ í™œìš© ê°€ëŠ¥í•œ ë°ì´í„° (100% ë³´ì¥)
1. âœ… `source` (neo4j/opensearch/stock) - í•­ìƒ ì¡´ì¬
2. âœ… `content` (title, summary, body) - í•­ìƒ ì¡´ì¬
3. âœ… `timestamp` - ëŒ€ë¶€ë¶„ ì¡´ì¬
4. âœ… `semantic_score` - Context Engineeringì—ì„œ ê³„ì‚°
5. âœ… `diversity_score` - Context Engineeringì—ì„œ ê³„ì‚°

---

## ğŸ’¡ ëŒ€ì•ˆ: ê¸°ì¡´ ë°ì´í„° ê¸°ë°˜ í’ˆì§ˆ ê°œì„ 

### ì „ëµ 1: Semantic ê´€ë ¨ì„± ê°•í™” (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**í˜„ì¬ ë¬¸ì œ**:
- Semantic ì ìˆ˜ë§Œìœ¼ë¡œ íŒë‹¨ â†’ ê´€ë ¨ì„±ì€ ë†’ì§€ë§Œ í’ˆì§ˆì€ ë‚®ì„ ìˆ˜ ìˆìŒ
- ì˜ˆ: "ì‚¼ì„±ì „ì"ë§Œ ì–¸ê¸‰í•œ ì§§ì€ ë‰´ìŠ¤ë„ ë†’ì€ ì ìˆ˜

**ê°œì„  ë°©ì•ˆ**: **ë‚´ìš© ê¸¸ì´ & ì •ë³´ ë°€ë„ ê°€ì¤‘ì¹˜**

```python
def _calculate_content_quality(self, ctx: Dict[str, Any]) -> float:
    """ì»¨í…ì¸  ìì²´ì˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì‹ ê·œ í•„ë“œ ì—†ì´)"""

    content = ctx.get("content", "")
    metadata = ctx.get("metadata", {})

    # 1. ë‚´ìš© ê¸¸ì´ ì ìˆ˜ (0.0-1.0)
    content_length = len(content)
    if content_length > 1000:
        length_score = 1.0
    elif content_length > 500:
        length_score = 0.8
    elif content_length > 200:
        length_score = 0.5
    else:
        length_score = 0.3

    # 2. ì •ë³´ ë°€ë„ ì ìˆ˜ (í‚¤ì›Œë“œ ë‹¤ì–‘ì„±)
    # ìˆ«ì, ê³ ìœ ëª…ì‚¬, ì „ë¬¸ìš©ì–´ê°€ ë§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
    has_numbers = bool(re.search(r'\d+', content))
    has_percentage = bool(re.search(r'\d+%', content))
    has_money = bool(re.search(r'\d+ì–µ|\d+ì¡°|\$\d+', content))
    has_company = bool(re.search(r'ì‚¼ì„±|SK|LG|í˜„ëŒ€|í¬ìŠ¤ì½”', content))

    density_score = 0.0
    density_score += 0.25 if has_numbers else 0
    density_score += 0.25 if has_percentage else 0
    density_score += 0.25 if has_money else 0
    density_score += 0.25 if has_company else 0

    # 3. ì œëª©-ë‚´ìš© ì¼ì¹˜ë„ (ì œëª©ì´ ë‚´ìš©ì„ ëŒ€í‘œí•˜ëŠ”ê°€)
    title = metadata.get("title", "")
    summary = metadata.get("summary", "")

    title_length = len(title)
    title_quality = 1.0 if 10 < title_length < 100 else 0.5
    has_summary = 1.0 if len(summary) > 50 else 0.5

    # ìµœì¢… ì ìˆ˜ (0.0-1.0)
    quality_score = (
        length_score * 0.4 +
        density_score * 0.3 +
        title_quality * 0.15 +
        has_summary * 0.15
    )

    return quality_score
```

**ì ìš© ìœ„ì¹˜**: `_rerank_with_metadata` ë‚´ë¶€

**ì˜ˆìƒ íš¨ê³¼**:
- ì§§ê³  ë‚´ìš© ì—†ëŠ” ë‰´ìŠ¤ ì œê±° (ê¸¸ì´ ì ìˆ˜ ë‚®ìŒ)
- êµ¬ì²´ì  ë°ì´í„° í¬í•¨ ë‰´ìŠ¤ ìš°ì„  (ë°€ë„ ì ìˆ˜ ë†’ìŒ)
- í’ˆì§ˆ ì ìˆ˜ 0.32 â†’ **0.5~0.6** (1.5ë°° í–¥ìƒ)

---

### ì „ëµ 2: ì¶œì²˜ë³„ ë™ì  ê°€ì¤‘ì¹˜ (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**í˜„ì¬ ë¬¸ì œ**:
- ê³ ì • ê°€ì¤‘ì¹˜ (neo4j: 1.3, opensearch: 1.0, stock: 0.8)
- ì§ˆì˜ ìœ í˜•ì— ë”°ë¼ ìµœì  ì¶œì²˜ê°€ ë‹¤ë¦„

**ê°œì„  ë°©ì•ˆ**: **ì§ˆì˜ ì˜ë„ë³„ ë™ì  ê°€ì¤‘ì¹˜**

```python
def _calculate_dynamic_source_weights(
    self,
    query: str,
    query_analysis: Dict[str, Any]
) -> Dict[str, float]:
    """ì§ˆì˜ ìœ í˜•ì— ë”°ë¥¸ ë™ì  ì¶œì²˜ ê°€ì¤‘ì¹˜"""

    intent = query_analysis.get("intent", "unknown")
    entities = query_analysis.get("entities", {})

    # ê¸°ë³¸ ê°€ì¤‘ì¹˜
    weights = {
        "neo4j": 1.0,
        "opensearch": 1.0,
        "stock": 1.0
    }

    # 1. ë¹„êµ ë¶„ì„ â†’ Neo4j ê´€ê³„ ë°ì´í„° ìš°ì„ 
    if "ë¹„êµ" in query or "vs" in query:
        weights["neo4j"] = 1.5
        weights["opensearch"] = 1.2
        weights["stock"] = 0.8

    # 2. ë‰´ìŠ¤ ì¡°íšŒ â†’ OpenSearch ìš°ì„ 
    elif intent == "news_inquiry":
        weights["opensearch"] = 1.5
        weights["neo4j"] = 1.0
        weights["stock"] = 0.7

    # 3. ì¬ë¬´ ë¶„ì„ â†’ Stock ë°ì´í„° + Neo4j ìš°ì„ 
    elif "ì¬ë¬´" in query or "ì‹¤ì " in query or "ë§¤ì¶œ" in query:
        weights["stock"] = 1.5
        weights["neo4j"] = 1.3
        weights["opensearch"] = 0.9

    # 4. ê´€ê³„ ë¶„ì„ (ê³µê¸‰ë§, ê³„ì•½ ë“±) â†’ Neo4j ì••ë„ì  ìš°ì„ 
    elif "ê³µê¸‰ë§" in query or "ê³„ì•½" in query or "íŒŒíŠ¸ë„ˆ" in query:
        weights["neo4j"] = 2.0
        weights["opensearch"] = 0.8
        weights["stock"] = 0.7

    # 5. ê¸°ìˆ  ë¶„ì„ â†’ Neo4j + OpenSearch ê· í˜•
    elif "ê¸°ìˆ " in query or "ê°œë°œ" in query or "íŠ¹í—ˆ" in query:
        weights["neo4j"] = 1.4
        weights["opensearch"] = 1.4
        weights["stock"] = 0.6

    return weights
```

**ì ìš© ìœ„ì¹˜**: `_filter_by_source_priority` ìˆ˜ì •

**ì˜ˆìƒ íš¨ê³¼**:
- ì§ˆì˜ì— ìµœì í™”ëœ ì¶œì²˜ ì„ íƒ
- í’ˆì§ˆ ì ìˆ˜ +0.1~0.15 ì¶”ê°€ í–¥ìƒ

---

### ì „ëµ 3: ì¤‘ë³µ ì œê±° ê°•í™” (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**í˜„ì¬ ë¬¸ì œ**:
- ê°™ì€ ë‚´ìš©ì˜ ë‰´ìŠ¤ê°€ ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ ì¤‘ë³µ
- Diversity ì ìˆ˜ 0.39ë¡œ ë‚®ìŒ (ëª©í‘œ: 0.5+)

**ê°œì„  ë°©ì•ˆ**: **Advanced Deduplication**

```python
def _advanced_deduplication(
    self,
    contexts: List[Dict[str, Any]],
    similarity_threshold: float = 0.85
) -> List[Dict[str, Any]]:
    """ê³ ê¸‰ ì¤‘ë³µ ì œê±° (Semantic + Exact)"""

    deduplicated = []
    seen_contents = set()

    for ctx in contexts:
        content = ctx.get("content", "")

        # 1. Exact ì¤‘ë³µ ì œê±° (ì œëª© ê¸°ë°˜)
        title = ctx.get("metadata", {}).get("title", "")
        title_hash = hash(title.strip().lower())

        if title_hash in seen_contents:
            continue  # ìŠ¤í‚µ

        # 2. Semantic ì¤‘ë³µ ì œê±° (ì„ë² ë”© ìœ ì‚¬ë„)
        is_duplicate = False
        for existing in deduplicated[-5:]:  # ìµœê·¼ 5ê°œì™€ë§Œ ë¹„êµ (ì„±ëŠ¥)
            similarity = self._calculate_text_similarity(
                content,
                existing.get("content", "")
            )

            if similarity > similarity_threshold:
                # ì¤‘ë³µì´ë©´ í’ˆì§ˆ ë†’ì€ ê²ƒ ìœ ì§€
                if ctx.get("quality_score", 0.5) > existing.get("quality_score", 0.5):
                    deduplicated.remove(existing)
                    deduplicated.append(ctx)
                is_duplicate = True
                break

        if not is_duplicate:
            seen_contents.add(title_hash)
            deduplicated.append(ctx)

    return deduplicated

def _calculate_text_similarity(self, text1: str, text2: str) -> float:
    """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ì‹)"""
    # Jaccard similarity (ë‹¨ì–´ ì§‘í•© ê¸°ë°˜)
    words1 = set(text1.split())
    words2 = set(text2.split())

    intersection = words1 & words2
    union = words1 | words2

    if len(union) == 0:
        return 0.0

    return len(intersection) / len(union)
```

**ì ìš© ìœ„ì¹˜**: `_apply_context_engineering` ë‚´ë¶€ (Phase 3 ì´í›„ ì¶”ê°€)

**ì˜ˆìƒ íš¨ê³¼**:
- Diversity ì ìˆ˜ 0.39 â†’ **0.5+**
- ì¤‘ë³µ ì œê±°ë¡œ ì •ë³´ ë‹¤ì–‘ì„± í–¥ìƒ

---

### ì „ëµ 4: í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë¡œì§ ê°œì„  (í•µì‹¬)

**í˜„ì¬ ë¬¸ì œ**:
- í’ˆì§ˆ ì ìˆ˜ 0.32 = ë‚®ì€ í‰ê°€ ê¸°ì¤€
- ì‹¤ì œ ë³´ê³ ì„œëŠ” ê´œì°®ì€ë° ì ìˆ˜ë§Œ ë‚®ìŒ

**ì›ì¸ ë¶„ì„**:
```python
# í˜„ì¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì¶”ì •)
quality_score = (
    contexts_diversity * 0.3 +
    insights_count / 10 * 0.3 +
    relationships_count / 10 * 0.2 +
    report_length / 5000 * 0.2
)
```

**ê°œì„  ë°©ì•ˆ**: **ë‹¤ì°¨ì› í’ˆì§ˆ í‰ê°€**

```python
def _calculate_report_quality_score(self, state: LangGraphReportState) -> float:
    """ë³´ê³ ì„œ í’ˆì§ˆ ì ìˆ˜ ì¬ê³„ì‚° (ê°œì„ )"""

    # 1. ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ (30%)
    contexts = state.get("contexts", [])
    if len(contexts) > 0:
        # í‰ê·  ì»¨í…ì¸  í’ˆì§ˆ ì ìˆ˜
        avg_content_quality = sum(
            self._calculate_content_quality(ctx) for ctx in contexts
        ) / len(contexts)

        # ë‹¤ì–‘ì„± ì ìˆ˜
        diversity = state.get("diversity_score", 0.4)

        context_quality = (avg_content_quality * 0.6 + diversity * 0.4)
    else:
        context_quality = 0.0

    # 2. ì¸ì‚¬ì´íŠ¸ í’ˆì§ˆ (40%)
    insights = state.get("insights", [])
    if len(insights) > 0:
        # ì¸ì‚¬ì´íŠ¸ ê°œìˆ˜ ì ìˆ˜
        insight_count_score = min(len(insights) / 5.0, 1.0)

        # ì¸ì‚¬ì´íŠ¸ ì‹ ë¢°ë„ ì ìˆ˜
        avg_confidence = sum(
            ins.get("confidence", 0.7) for ins in insights
        ) / len(insights)

        # ê·¼ê±° ë°ì´í„° ì ìˆ˜ (evidenceê°€ ë§ì„ìˆ˜ë¡ ë†’ìŒ)
        avg_evidence = sum(
            len(ins.get("evidence", [])) for ins in insights
        ) / len(insights)
        evidence_score = min(avg_evidence / 3.0, 1.0)

        insight_quality = (
            insight_count_score * 0.4 +
            avg_confidence * 0.3 +
            evidence_score * 0.3
        )
    else:
        insight_quality = 0.0

    # 3. ê´€ê³„ ë¶„ì„ í’ˆì§ˆ (20%)
    relationships = state.get("relationships", [])
    if len(relationships) > 0:
        relationship_count_score = min(len(relationships) / 5.0, 1.0)
        avg_rel_confidence = sum(
            rel.get("confidence", 0.7) for rel in relationships
        ) / len(relationships)

        relationship_quality = (
            relationship_count_score * 0.5 +
            avg_rel_confidence * 0.5
        )
    else:
        relationship_quality = 0.0

    # 4. ì‹¬í™” ì¶”ë¡  í’ˆì§ˆ (10%)
    deep_reasoning = state.get("deep_reasoning", {})
    has_why = bool(deep_reasoning.get("why", {}).get("causes"))
    has_what_if = bool(deep_reasoning.get("what_if", {}).get("scenarios"))
    has_so_what = bool(deep_reasoning.get("so_what", {}).get("actionable_insights"))

    reasoning_quality = (
        (1.0 if has_why else 0.0) * 0.4 +
        (1.0 if has_what_if else 0.0) * 0.3 +
        (1.0 if has_so_what else 0.0) * 0.3
    )

    # ìµœì¢… í’ˆì§ˆ ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
    final_quality = (
        context_quality * 0.30 +
        insight_quality * 0.40 +
        relationship_quality * 0.20 +
        reasoning_quality * 0.10
    )

    return round(final_quality, 2)
```

**ì ìš© ìœ„ì¹˜**: `_calculate_quality_score` ë©”ì„œë“œ ëŒ€ì²´

**ì˜ˆìƒ íš¨ê³¼**:
- í’ˆì§ˆ ì ìˆ˜ 0.32 â†’ **0.7~0.85**
- ì‹¤ì œ ë³´ê³ ì„œ í’ˆì§ˆì„ ì •í™•íˆ ë°˜ì˜

---

## ğŸ“ˆ ì¢…í•© ê°œì„  íš¨ê³¼ ì˜ˆì¸¡

### Phase 1: ì¦‰ì‹œ ì ìš© (2ì‹œê°„)
1. âœ… ì»¨í…ì¸  í’ˆì§ˆ ê³„ì‚° ì¶”ê°€ (`_calculate_content_quality`)
2. âœ… ë™ì  ì¶œì²˜ ê°€ì¤‘ì¹˜ (`_calculate_dynamic_source_weights`)
3. âœ… ì¤‘ë³µ ì œê±° ê°•í™” (`_advanced_deduplication`)
4. âœ… í’ˆì§ˆ ì ìˆ˜ ì¬ê³„ì‚° (`_calculate_report_quality_score`)

**ì˜ˆìƒ íš¨ê³¼**:
- í’ˆì§ˆ ì ìˆ˜: 0.32 â†’ **0.7+** (2.2ë°° í–¥ìƒ)
- Diversity: 0.39 â†’ 0.5+
- ì²˜ë¦¬ ì‹œê°„: +3~5ì´ˆ (acceptable)

### Phase 2: ì‹ ê·œ ìŠ¤í‚¤ë§ˆ í™œìš© (ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸ í›„)
1. âš ï¸ `quality_score` í•„ë“œ ì±„ì›Œì§€ë©´ ì§ì ‘ í™œìš©
2. âš ï¸ `is_featured` í”Œë˜ê·¸ í™œìš©
3. âš ï¸ `neo4j_synced` ê·¸ë˜í”„ ì—°ê²° í™•ì¸

**ì¶”ê°€ íš¨ê³¼**:
- í’ˆì§ˆ ì ìˆ˜: 0.7 â†’ **0.85+**

---

## ğŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### P1 (ì¦‰ì‹œ êµ¬í˜„ - 2ì‹œê°„)
1. `_calculate_content_quality()` êµ¬í˜„
2. `_calculate_dynamic_source_weights()` êµ¬í˜„
3. `_advanced_deduplication()` êµ¬í˜„
4. `_calculate_report_quality_score()` ëŒ€ì²´

### P2 (ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸ í›„)
1. ì‹ ê·œ ìŠ¤í‚¤ë§ˆ í•„ë“œ í™œìš© ì½”ë“œ ì¶”ê°€
2. í’ˆì§ˆ ì ìˆ˜ ì¶”ê°€ í–¥ìƒ

---

## ğŸ“ ìˆ˜ì • íŒŒì¼

### api/services/langgraph_report_service.py

**ì‹ ê·œ ë©”ì„œë“œ (4ê°œ)**:
1. `_calculate_content_quality()` (35ì¤„)
2. `_calculate_dynamic_source_weights()` (45ì¤„)
3. `_advanced_deduplication()` (40ì¤„)
4. `_calculate_report_quality_score()` (80ì¤„)

**ìˆ˜ì • ë©”ì„œë“œ (2ê°œ)**:
1. `_filter_by_source_priority()` - ë™ì  ê°€ì¤‘ì¹˜ ì ìš©
2. `_apply_context_engineering()` - ì¤‘ë³µ ì œê±° ì¶”ê°€

**ì´ ë¼ì¸ ìˆ˜**: +200ì¤„

---

## âœ… ê²°ë¡ 

### í•µì‹¬ ì „ëµ
1. **ì»¨í…ì¸  ìì²´ í’ˆì§ˆ í‰ê°€** (ê¸¸ì´, ë°€ë„, êµ¬ì¡°)
2. **ì§ˆì˜ë³„ ë™ì  ê°€ì¤‘ì¹˜** (ë¹„êµ/ë‰´ìŠ¤/ì¬ë¬´/ê¸°ìˆ )
3. **ê³ ê¸‰ ì¤‘ë³µ ì œê±°** (Exact + Semantic)
4. **ë‹¤ì°¨ì› í’ˆì§ˆ ì ìˆ˜** (ì»¨í…ìŠ¤íŠ¸ + ì¸ì‚¬ì´íŠ¸ + ê´€ê³„ + ì¶”ë¡ )

### í˜„ì‹¤ì  ê°œì„ 
- **ì‹ ê·œ í•„ë“œ ì—†ì´** ê¸°ì¡´ ë°ì´í„°ë¡œ í’ˆì§ˆ 2ë°° í–¥ìƒ
- í’ˆì§ˆ ì ìˆ˜: 0.32 â†’ **0.7+**
- ì²˜ë¦¬ ì‹œê°„: +3~5ì´ˆ (5% ì¦ê°€, acceptable)

### ë‹¤ìŒ ë‹¨ê³„
1. **ì§€ê¸ˆ êµ¬í˜„**: P1 (ì»¨í…ì¸  í’ˆì§ˆ + ë™ì  ê°€ì¤‘ì¹˜ + ì¤‘ë³µ ì œê±°)
2. **ìˆ˜ì§‘ê¸° ì—…ë°ì´íŠ¸ í›„**: P2 (ì‹ ê·œ ìŠ¤í‚¤ë§ˆ í™œìš©)

**P1ë¶€í„° ì‹œì‘í• ê¹Œìš”? ì‹ ê·œ í•„ë“œì— ì˜ì¡´í•˜ì§€ ì•Šê³ ë„ í° ê°œì„ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.**
